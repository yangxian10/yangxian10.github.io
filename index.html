<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>杨现的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="迭代的是人，递归的是神">
<meta property="og:type" content="website">
<meta property="og:title" content="杨现的个人博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="杨现的个人博客">
<meta property="og:description" content="迭代的是人，递归的是神">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="杨现的个人博客">
<meta name="twitter:description" content="迭代的是人，递归的是神">
  
    <link rel="alternative" href="/atom.xml" title="杨现的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">杨现的个人博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">分享计算机视觉、算法、生活累积的点滴</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-face-algorithm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/18/face-algorithm/" class="article-date">
  <time datetime="2017-11-18T01:51:45.000Z" itemprop="datePublished">2017-11-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/18/face-algorithm/">人脸算法资源汇总</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="人脸检测">人脸检测</h2><h3 id="MTCNN">MTCNN</h3><p>作者原版caffe+matlab<a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment" target="_blank" rel="external">https://github.com/kpzhang93/MTCNN_face_detection_alignment</a><br>caffe+c++<a href="https://github.com/foreverYoungGitHub/MTCNN" target="_blank" rel="external">https://github.com/foreverYoungGitHub/MTCNN</a><br>mtcnn-light<a href="https://github.com/dlunion/mtcnn" target="_blank" rel="external">https://github.com/dlunion/mtcnn</a><br>MTCNN-caffe<a href="https://github.com/blankWorld/MTCNN-Accelerate-Onet" target="_blank" rel="external">https://github.com/blankWorld/MTCNN-Accelerate-Onet</a></p>
<h3 id="How_far_are_we_from_solving_the_2D_&amp;_3D_Face_Alignment_problem?">How far are we from solving the 2D &amp; 3D Face Alignment problem?</h3><p><a href="https://github.com/1adrianb/2D-and-3D-face-alignment" target="_blank" rel="external">https://github.com/1adrianb/2D-and-3D-face-alignment</a></p>
<h3 id="dlib">dlib</h3><p>dlib-android<a href="https://github.com/tzutalin/dlib-android" target="_blank" rel="external">https://github.com/tzutalin/dlib-android</a><br>dlib-android-experiment<a href="https://github.com/boyw165/my-dlib-experiment/" target="_blank" rel="external">https://github.com/boyw165/my-dlib-experiment/</a></p>
<h2 id="人脸识别">人脸识别</h2><h3 id="FaceNet">FaceNet</h3><p><a href="https://github.com/davidsandberg/facenet" target="_blank" rel="external">https://github.com/davidsandberg/facenet</a><br><a href="https://github.com/hizhangp/triplet" target="_blank" rel="external">https://github.com/hizhangp/triplet</a></p>
<h3 id="Face_Recognition_Use_A-Softmax_loss_on_light_cleaned_Ms_celeb-1M_dataset">Face Recognition Use A-Softmax_loss on light cleaned Ms_celeb-1M dataset</h3><p><a href="https://github.com/KaleidoZhouYN/Details-on-Face-Recognition" target="_blank" rel="external">https://github.com/KaleidoZhouYN/Details-on-Face-Recognition</a></p>
<h3 id="SphereFace">SphereFace</h3><p><a href="https://github.com/wy1iu/sphereface" target="_blank" rel="external">https://github.com/wy1iu/sphereface</a></p>
<h3 id="COCO_Loss">COCO Loss</h3><p><a href="https://github.com/sciencefans/coco_loss" target="_blank" rel="external">https://github.com/sciencefans/coco_loss</a></p>
<h3 id="NormFace">NormFace</h3><p><a href="https://github.com/happynear/NormFace" target="_blank" rel="external">https://github.com/happynear/NormFace</a></p>
<h3 id="A_Light_CNN_for_Deep_Face_Representation_with_Noisy_Labels">A Light CNN for Deep Face Representation with Noisy Labels</h3><p><a href="https://github.com/AlfredXiangWu/face_verification_experiment" target="_blank" rel="external">https://github.com/AlfredXiangWu/face_verification_experiment</a></p>
<h2 id="人脸活体检测">人脸活体检测</h2><p><a href="https://github.com/number9473/nn-algorithm/issues/36" target="_blank" rel="external">https://github.com/number9473/nn-algorithm/issues/36</a></p>
<h2 id="人脸朝向">人脸朝向</h2><p><a href="https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/" target="_blank" rel="external">https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/</a><br><a href="https://www.learnopencv.com/rotation-matrix-to-euler-angles/" target="_blank" rel="external">https://www.learnopencv.com/rotation-matrix-to-euler-angles/</a><br><a href="https://github.com/chili-epfl/attention-tracker" target="_blank" rel="external">https://github.com/chili-epfl/attention-tracker</a></p>
<h2 id="人脸清晰度检测">人脸清晰度检测</h2><p>Blur Detection for Digital Images Using Wavelet Transform<br><a href="https://github.com/huneng/blur-detect-use-haar-wavelet" target="_blank" rel="external">https://github.com/huneng/blur-detect-use-haar-wavelet</a></p>
<h2 id="微表情识别">微表情识别</h2><p>Micro-expression-Detection-System<br>思想：检测人眼、人鼻、人嘴位置，然后对检测的区域做光流法判断表情变化，如果有变化，判断有微表情。<br><a href="https://github.com/kamilste/Micro-expression-Detection-System" target="_blank" rel="external">https://github.com/kamilste/Micro-expression-Detection-System</a></p>
<h2 id="网纹去除">网纹去除</h2><p>数字图像处理–掩膜重建<br><a href="http://blog.csdn.net/i_chaoren/article/details/54411569" target="_blank" rel="external">http://blog.csdn.net/i_chaoren/article/details/54411569</a><br>人脸图像保护和网纹人脸识别–李志航<br><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1513759696&amp;ver=585&amp;signature=0Tbw-Jx9ffdWd86x1QChx7Pdbs3IUOBwn6xg63bjdPFsbK79M9JnX4aPOUGvVo3FISXSpgp7cSU3o4pdLEwREbrcbU0NGe1WqqPFqXWggBPPceyT4fiPQJUfey6geFxH&amp;new=1" target="_blank" rel="external">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1513759696&amp;ver=585&amp;signature=0Tbw-Jx9ffdWd86x1QChx7Pdbs3IUOBwn6xg63bjdPFsbK79M9JnX4aPOUGvVo3FISXSpgp7cSU3o4pdLEwREbrcbU0NGe1WqqPFqXWggBPPceyT4fiPQJUfey6geFxH&amp;new=1</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/18/face-algorithm/" data-id="cja4p2iac002vrofh7gajr2qw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/face/">face</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-face-resource" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/16/face-resource/" class="article-date">
  <time datetime="2017-11-16T05:40:17.000Z" itemprop="datePublished">2017-11-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/16/face-resource/">人脸资讯数据资源汇总</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="资讯">资讯</h2><p>访谈百度IDL林元庆：百度大脑如何在人脸识别上战胜人类「最强大脑」<br><a href="https://www.jiqizhixin.com/articles/2017-01-09" target="_blank" rel="external">https://www.jiqizhixin.com/articles/2017-01-09</a><br>新智元–首发：人脸识别世界杯榜单出炉，微软百万名人识别竞赛冠军分享<br><a href="https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652001114&amp;idx=1&amp;sn=decf0edb4f21dba0925c002f7c0ef0e2" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652001114&amp;idx=1&amp;sn=decf0edb4f21dba0925c002f7c0ef0e2</a><br>新智元–【世界最大人脸对齐数据集】ICCV 2017：距离解决人脸对齐已不远<br><a href="https://mp.weixin.qq.com/s/s5HL6y2P9_KqpSAQg08URw" target="_blank" rel="external">https://mp.weixin.qq.com/s/s5HL6y2P9_KqpSAQg08URw</a><br>雷锋网–详解苹果Face ID，将让深度摄像头成主流<br><a href="https://mp.weixin.qq.com/s?__biz=MTM2ODM0ODYyMQ==&amp;mid=2651429348&amp;idx=1&amp;sn=89b82730d645e2de518cf3706d6e6e40" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MTM2ODM0ODYyMQ==&amp;mid=2651429348&amp;idx=1&amp;sn=89b82730d645e2de518cf3706d6e6e40</a><br>深度学习大讲堂–韩琥：深度学习让机器给人脸“贴标签”<br><a href="https://mp.weixin.qq.com/s/CLgyaAslE4hYHi62UhzeGw" target="_blank" rel="external">https://mp.weixin.qq.com/s/CLgyaAslE4hYHi62UhzeGw</a><br>SeetaFace开源人脸识别引擎介绍<br><a href="http://blog.csdn.net/u013146742/article/details/52816640" target="_blank" rel="external">http://blog.csdn.net/u013146742/article/details/52816640</a><br>深度学习大讲堂–【Technical Review】ECCV16 Center Loss及其在人脸识别中的应用<br><a href="https://zhuanlan.zhihu.com/p/23340343" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/23340343</a><br>雷锋网–CNCC 2016 | 山世光：深度化的人脸检测与识别技术—进展与展望<br><a href="https://www.leiphone.com/news/201610/rZ2Mn9UFF3x8FaEt.html" target="_blank" rel="external">https://www.leiphone.com/news/201610/rZ2Mn9UFF3x8FaEt.html</a><br>人脸识别中的活体检测<br><a href="https://zhuanlan.zhihu.com/p/25401788" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/25401788</a><br>深度学习大讲堂–人脸检测与识别年度进展概述<br><a href="https://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650326590&amp;idx=1&amp;sn=c195e063bc4bcd60edb6b7a83a751067" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650326590&amp;idx=1&amp;sn=c195e063bc4bcd60edb6b7a83a751067</a><br>海康威视–人脸识别的两大系统方案PK，结果是<br><a href="https://mp.weixin.qq.com/s/qG8R4RMKXJizPmZyEUqyMA" target="_blank" rel="external">https://mp.weixin.qq.com/s/qG8R4RMKXJizPmZyEUqyMA</a><br>海康威视–强势解码后端人脸智能分析应用，奥秘原来在这儿<br><a href="https://mp.weixin.qq.com/s/4zOYZU20hREtiiLbfSrW2A" target="_blank" rel="external">https://mp.weixin.qq.com/s/4zOYZU20hREtiiLbfSrW2A</a><br>海康威视–人脸识别99%准确率背后的秘密<br><a href="http://www.7its.com/html/2017/anli_1207/6115.html" target="_blank" rel="external">http://www.7its.com/html/2017/anli_1207/6115.html</a><br>《人工智能强势来袭，听旷视（Face++）为你揭开智能零售的秘密》干货分享<br><a href="http://www.sohu.com/a/73894297_355045" target="_blank" rel="external">http://www.sohu.com/a/73894297_355045</a><br>人脸图像保护和网纹人脸识别–李志航<br><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1513759696&amp;ver=585&amp;signature=0Tbw-Jx9ffdWd86x1QChx7Pdbs3IUOBwn6xg63bjdPFsbK79M9JnX4aPOUGvVo3FISXSpgp7cSU3o4pdLEwREbrcbU0NGe1WqqPFqXWggBPPceyT4fiPQJUfey6geFxH&amp;new=1" target="_blank" rel="external">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1513759696&amp;ver=585&amp;signature=0Tbw-Jx9ffdWd86x1QChx7Pdbs3IUOBwn6xg63bjdPFsbK79M9JnX4aPOUGvVo3FISXSpgp7cSU3o4pdLEwREbrcbU0NGe1WqqPFqXWggBPPceyT4fiPQJUfey6geFxH&amp;new=1</a><br>机器之心–从传统方法到深度学习，人脸关键点检测方法综述<br><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734809&amp;idx=1&amp;sn=f5dd841fb56b668dbc4dc4c2a668c195&amp;chksm=871ac4a7b06d4db1befb03fb1616cea7ea158561125df55798209a2926bcfa31e131eb46d7d4#rd" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734809&amp;idx=1&amp;sn=f5dd841fb56b668dbc4dc4c2a668c195&amp;chksm=871ac4a7b06d4db1befb03fb1616cea7ea158561125df55798209a2926bcfa31e131eb46d7d4#rd</a><br>Demystifying Face Recognition(1\2\3)<br><a href="http://blcv.pl/static/2017/11/07/demystifying-face-recognition-i-introduction/" target="_blank" rel="external">http://blcv.pl/static/2017/11/07/demystifying-face-recognition-i-introduction/</a><br>【VALSE 前沿技术选介17-06期】探究最陌生的老朋友Softmax<br><a href="http://mp.weixin.qq.com/s/D4X_GMAwUu_WtC0layWZGA" target="_blank" rel="external">http://mp.weixin.qq.com/s/D4X_GMAwUu_WtC0layWZGA</a><br>新智元–【难度越大，优势越大】腾讯AI Lab刷新人脸识别与人脸检测国际记录<br><a href="https://mp.weixin.qq.com/s/FcbCA7dHEeTpbCruYd4TjA" target="_blank" rel="external">https://mp.weixin.qq.com/s/FcbCA7dHEeTpbCruYd4TjA</a><br>新智元–【深度】申省梅颜水成团队获国际非受限人脸识别竞赛IJB-A冠军，主要负责人熊霖技术分享<br><a href="https://mp.weixin.qq.com/s/s9H_OXX-CCakrTAQUFDm8g" target="_blank" rel="external">https://mp.weixin.qq.com/s/s9H_OXX-CCakrTAQUFDm8g</a><br>新智元–【微信身份证后的刷脸时代】活体识别告诉你为什么照片无法破解人脸系统<br><a href="https://mp.weixin.qq.com/s/A1pbiU5PA9Owe69lGX9afw" target="_blank" rel="external">https://mp.weixin.qq.com/s/A1pbiU5PA9Owe69lGX9afw</a><br>机器之心–AAAI 2018 | 如何高效进行大规模分类？港中文联合商汤提出新方法<br><a href="https://mp.weixin.qq.com/s/kLXJsHbBnRIFC3NLChPhzA" target="_blank" rel="external">https://mp.weixin.qq.com/s/kLXJsHbBnRIFC3NLChPhzA</a></p>
<h2 id="性能测试指标">性能测试指标</h2><p><a href="http://blog.csdn.net/blueblood7/article/details/41823593" target="_blank" rel="external">http://blog.csdn.net/blueblood7/article/details/41823593</a></p>
<ul>
<li>注册失败率 failure-to-enrol rate FTE<br>注册失败的用户在总注册用户中所占的比例</li>
<li>错误采集率 failure-to-acquire rate FTA<br>在辨识或验证的尝试中，采集不到样本或样本质量无法达到要求的比例</li>
<li>错误不匹配率 false non-match rate FNMR<br>正确的尝试样本被错误的判定微不匹配的比例</li>
<li>错误匹配率 false match rate FMR<br>零效攻击尝试样本被错误的判为匹配的比例</li>
<li>错误拒绝率 false refect rate FRR<br>验证识别过程中，真实者被错误判为拒绝的比例</li>
<li>错误接受率 false accept rate FAR<br>验证识别过程中，冒充者被错误判定为接受的比例</li>
<li>检测错误权衡曲线 detection error trade-off curve<br>DET曲线（x轴为FAR，y轴为FRR）</li>
<li>接受者操作特性曲线 receiver operating character istic curve<br>ROC曲线（x轴为FAR，y轴为TPR）</li>
</ul>
<p>FAR = FMR <em> (1 – FTA)<br>FRR = FTA + FNMR </em> (1 – FTA) </p>
<h2 id="数据">数据</h2><h3 id="MS-Celeb-1M:_Recognizing_One_Million_Celebrities_in_the_Real_World">MS-Celeb-1M: Recognizing One Million Celebrities in the Real World</h3><p><a href="http://www.msceleb.org/" target="_blank" rel="external">http://www.msceleb.org/</a><br>微软人脸识别挑战比赛，相当于人脸识别领域的imagenet，包含10万人的约1000万人脸数据，是目前为止最大规模的数据集和比赛。</p>
<h3 id="VGGFace2">VGGFace2</h3><p><a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/" target="_blank" rel="external">http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/</a><br>9131个id的331万人脸图像。<br>百度网盘: <a href="https://pan.baidu.com/s/1i4NYnuH" target="_blank" rel="external">https://pan.baidu.com/s/1i4NYnuH</a> 密码: dukf</p>
<h3 id="CelebA:_Large-scale_CelebFaces_Attributes_(CelebA)_Dataset">CelebA: Large-scale CelebFaces Attributes (CelebA) Dataset</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a><br>香港中文大学组2015年搞的一个最新的目前最大的人脸集，包含10177个人，202599张人脸图片，而且每张图片有5个关键点标注信息以及40个2值属性，属性包括是否带眼睛，是否在笑，是否带帽子，是不是卷发，是否年轻，性别等等，是非常珍贵的人脸数据。</p>
<h3 id="WIDER_FACE:_A_Face_Detection_Benchmark">WIDER FACE: A Face Detection Benchmark</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/</a><br>香港中文大学再放大招，2015年11月又推出人脸检测标注数据库，包含32203张图片，393703张人脸。其中50%的测试数据集并没有公开标注信息。</p>
<h3 id="IMDB-WIKI">IMDB-WIKI</h3><p><a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/" target="_blank" rel="external">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/</a><br>有人脸位置、性别、年龄的标注信息，共52万的标注图片</p>
<h3 id="CASIA_WebFace_Database">CASIA WebFace Database</h3><p><a href="http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html" target="_blank" rel="external">http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html</a><br>10,575 subjects and 494,414 images<br>CASIA clean-list:<br><a href="https://github.com/happynear/FaceVerification" target="_blank" rel="external">https://github.com/happynear/FaceVerification</a><br><a href="http://zhengyingbin.cc/ActiveAnnotationLearning/" target="_blank" rel="external">http://zhengyingbin.cc/ActiveAnnotationLearning/</a></p>
<h3 id="Labeled_Faces_in_the_Wild">Labeled Faces in the Wild</h3><p><a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="external">http://vis-www.cs.umass.edu/lfw/</a><br>13,000 images and 5749 subjects</p>
<h3 id="MSRA-CFW">MSRA-CFW</h3><p><a href="http://research.microsoft.com/en-us/projects/msra-cfw/" target="_blank" rel="external">http://research.microsoft.com/en-us/projects/msra-cfw/</a><br>202,792 images and 1,583 subjects.</p>
<h3 id="MegaFace_Dataset">MegaFace Dataset</h3><p><a href="http://megaface.cs.washington.edu" target="_blank" rel="external">http://megaface.cs.washington.edu</a><br>passwd:<strong>bRx!XOx%of</strong><br>1 Million Faces for Recognition at Scale 690,572 unique people</p>
<h3 id="FaceScrub">FaceScrub</h3><p><a href="http://vintage.winklerbros.net/facescrub.html" target="_blank" rel="external">http://vintage.winklerbros.net/facescrub.html</a><br>A Dataset With Over 100,000 Face Images of 530 People.</p>
<h3 id="FDDB">FDDB</h3><p><a href="http://vis-www.cs.umass.edu/fddb" target="_blank" rel="external">http://vis-www.cs.umass.edu/fddb</a><br>Face Detection and Data Set Benchmark. 5k images.</p>
<h3 id="AFLW">AFLW</h3><p><a href="https://lrs.icg.tugraz.at/research/aflw/" target="_blank" rel="external">https://lrs.icg.tugraz.at/research/aflw/</a><br>Annotated Facial Landmarks in the Wild: A Large-scale, Real-world Database for Facial Landmark Localization. 25k images.</p>
<h3 id="AFW">AFW</h3><p><a href="http://www.ics.uci.edu/~xzhu/face/" target="_blank" rel="external">http://www.ics.uci.edu/~xzhu/face/</a><br>Annotated Faces in the Wild. ~1k images.</p>
<h3 id="3D_Mask_Attack_Dataset]">3D Mask Attack Dataset]</h3><p><a href="https://www.idiap.ch/dataset/3dmad" target="_blank" rel="external">https://www.idiap.ch/dataset/3dmad</a><br>76500 frames of 17 persons using Kinect RGBD with eye positions (Sebastien Marcel)</p>
<h3 id="Audio-visual_database_for_face_and_speaker_recognition">Audio-visual database for face and speaker recognition</h3><p><a href="https://www.idiap.ch/dataset/mobio" target="_blank" rel="external">https://www.idiap.ch/dataset/mobio</a><br>Mobile Biometry MOBIO <a href="http://www.mobioproject.org/" target="_blank" rel="external">http://www.mobioproject.org/</a></p>
<h3 id="BANCA_face_and_voice_database">BANCA face and voice database</h3><p><a href="http://www.ee.surrey.ac.uk/CVSSP/banca/" target="_blank" rel="external">http://www.ee.surrey.ac.uk/CVSSP/banca/</a><br>Univ of Surrey</p>
<h3 id="Binghampton_Univ_3D_static_and_dynamic_facial_expression_database">Binghampton Univ 3D static and dynamic facial expression database</h3><p><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html" target="_blank" rel="external">http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html</a><br>(Lijun Yin, Peter Gerhardstein and teammates)</p>
<h3 id="The_BioID_Face_Database">The BioID Face Database</h3><p><a href="https://www.bioid.com/About/BioID-Face-Database" target="_blank" rel="external">https://www.bioid.com/About/BioID-Face-Database</a><br>BioID group</p>
<h3 id="Biwi_3D_Audiovisual_Corpus_of_Affective_Communication">Biwi 3D Audiovisual Corpus of Affective Communication</h3><p><a href="http://www.vision.ee.ethz.ch/datasets/b3dac2.en.html" target="_blank" rel="external">http://www.vision.ee.ethz.ch/datasets/b3dac2.en.html</a><br>1000 high quality, dynamic 3D scans of faces, recorded while pronouncing a set of English sentences.</p>
<h3 id="Cohn-Kanade_AU-Coded_Expression_Database">Cohn-Kanade AU-Coded Expression Database</h3><p><a href="http://www.pitt.edu/~emotion/ck-spread.htm" target="_blank" rel="external">http://www.pitt.edu/~emotion/ck-spread.htm</a><br>500+ expression sequences of 100+ subjects, coded by activated Action Units (Affect Analysis Group, Univ. of Pittsburgh.</p>
<h3 id="CMU/MIT_Frontal_Faces">CMU/MIT Frontal Faces</h3><p><a href="http://cbcl.mit.edu/software-datasets/FaceData2.html" target="_blank" rel="external">http://cbcl.mit.edu/software-datasets/FaceData2.html</a><br>Training set:  2,429 faces, 4,548 non-faces; Test set: 472 faces, 23,573 non-faces.</p>
<h3 id="kaggle表情数据">kaggle表情数据</h3><p><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" target="_blank" rel="external">https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data</a><br>人脸表情数据集，7种表情(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)，训练集28709张图片，测试集3589张，像素48*48</p>
<h3 id="人脸素描数据集">人脸素描数据集</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html</a><br>606张人脸的素描和证件照的一一对应图像</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/16/face-resource/" data-id="cja4p2iac002qrofhmdo4rndq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/face/">face</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe2-abc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/07/caffe2-abc/" class="article-date">
  <time datetime="2017-10-07T06:13:10.000Z" itemprop="datePublished">2017-10-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/07/caffe2-abc/">caffe2学习（二）基础</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="写在前面">写在前面</h2><p>最近开始尝试了caffe2，主要是因为tensorflow的发展越来越奇怪，一种网络实现在tensorflow中有多种对应的实现方式，臃肿的函数表达，每月一次大更新没有向下兼容，越来越高昂的学习成本，加之最近其他几大深度学习框架对tensorflow有合围之势…太多的槽点了，让我有点想放弃tensorflow这个坑了。还是怀念caffe的简洁，于是还是捡起贾扬清大神的续集填坑吧。废话不多说了，还是看看caffe2的亮点吧</p>
<h2 id="caffe2亮点">caffe2亮点</h2><ul>
<li>支持分布式训练</li>
<li>对移动端的deployment的支持</li>
<li>基础计算单元改为Operators，相对于caffe的layers单元有很多改进</li>
</ul>
<h3 id="caffe模型导入caffe2">caffe模型导入caffe2</h3><pre><code>python -m caffe2<span class="class">.python</span><span class="class">.caffe_translator</span> deploy<span class="class">.prototxt</span> pretrained.caffemodel
</code></pre><h3 id="torch模型导入caffe2">torch模型导入caffe2</h3><p>使用torch2caffe的工具，将caffe作为桥梁，不展开讨论了</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/10/07/caffe2-abc/" data-id="cja4p2iar003krofhn7cjx89a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe2/">caffe2</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffefe2-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/07/caffefe2-install/" class="article-date">
  <time datetime="2017-10-07T06:10:51.000Z" itemprop="datePublished">2017-10-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/10/07/caffefe2-install/">caffe2学习（一）安装配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="相关依赖">相关依赖</h2><p>caffe2的依赖比caffe要干净很多，必要的库比较少</p>
<ul>
<li>cmake</li>
<li>git</li>
<li>glog</li>
<li>protobuf</li>
<li>CUDA (optional)</li>
<li>cudnn (optional)</li>
</ul>
<h2 id="caffe2安装">caffe2安装</h2><pre><code>git <span class="built_in">clone</span> --recursive https://github.com/caffe2/caffe2.git
<span class="built_in">cd</span> caffe2
make -j8
<span class="built_in">cd</span> build
sudo make install

<span class="comment"># test</span>
python -c <span class="string">'from caffe2.python import core'</span> <span class="number">2</span>&gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">"Success"</span> || <span class="built_in">echo</span> <span class="string">"Failure"</span>
python -m caffe2.python.operator_test.relu_op_<span class="built_in">test</span>

<span class="comment"># Environment Variables</span>
<span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:/home/<span class="number">15072585</span>/caffe2/build  <span class="comment">#(add to ~/.bashrc)</span>
</code></pre><h2 id="tips">tips</h2><ul>
<li>gpu版本报错，已经在github issue上提问了<a href="https://github.com/caffe2/caffe2/issues/1297" target="_blank" rel="external">https://github.com/caffe2/caffe2/issues/1297</a>，解决方案安装gcc 4.9.4</li>
</ul>
<pre><code>tar jxf gcc-<span class="number">4.9</span>.<span class="number">4</span>.tar.bz2
cd gcc-<span class="number">4.9</span>.<span class="number">4</span>
./configure --enable-checking=release --enable-languages=c,c++ --disable-multilib --prefix=/home/yang/gcc
make -j8
make install
export PATH=/home/yang/gcc/bin:<span class="variable">$PATH</span>
export LD_LIBRARY_PATH=/home/yang/gcc/lib64:<span class="variable">$LD</span>_LIBRARY_PATH
</code></pre><ul>
<li><code>from caffe2.python import core</code>报错<code>No module named past.builtins</code>，解决方案<code>pip install future</code></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/10/07/caffefe2-install/" data-id="cja4p2iar003grofhe6s0qmnu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe2/">caffe2</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-forward" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/03/caffe-forward/" class="article-date">
  <time datetime="2017-06-03T13:15:54.000Z" itemprop="datePublished">2017-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/03/caffe-forward/">caffe学习（九）inference代码优化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="多线程inference问题">多线程inference问题</h2><p>对于caffe前向算法的使用，通常会遇到一种情况：一次初始化，多次进行predict方法，按照caffe的设计，shared_ptr是线程不安全的，如果同时起多个线程同时进行predict，会导致数据参数共享，进而出错。为此需要修改caffe教程中的实现，在每次predict的时候在内存中复制一份网络。</p>
<pre><code><span class="comment">// old init</span>
shared_ptr&lt;Net&lt;<span class="keyword">float</span>&gt; &gt; net_;
net_.reset(<span class="keyword">new</span> Net&lt;<span class="keyword">float</span>&gt;(deploy_file, TEST));
net_-&gt;CopyTrainedLayersFrom(trained_file);

<span class="comment">// new init</span>
shared_ptr&lt;Net&lt;<span class="keyword">float</span>&gt; &gt; net_;
NetParameter param_;
ReadNetParamsFromTextFileOrDie(deploy_file, &amp;param_);
param_.mutable_state()-&gt;set_phase(TEST);
net_.reset(<span class="keyword">new</span> Net&lt;<span class="keyword">float</span>&gt;(param_));
net_-&gt;CopyTrainedLayersFrom(trained_file);

<span class="comment">// old predict</span>
net_-&gt;Forward();

<span class="comment">// new predict</span>
shared_ptr&lt;Net&lt;<span class="keyword">float</span>&gt; &gt; net_tmp;
net_tmp.reset(<span class="keyword">new</span> Net&lt;<span class="keyword">float</span>&gt;(param_));
net_tmp-&gt;ShareTrainedLayersWith(net_.get());
net_-&gt;Forward();
</code></pre><h2 id="网络复制优化">网络复制优化</h2><p>上面这段代码基本可以解决问题，由于<code>ShareTrainedLayersWith</code>是从内存中将网络参数复制过来，效率很高。但<code>new Net&lt;float&gt;(param_)</code>这个方法由于要基于param_重新构建一个网络并初始化参数，这个性能是很低的，而且对于predict来说也是没有意义的，因为后面还会用ShareTrainedLayersWith方法再次重新赋值。通常<code>weight_filler</code>还使用<code>xavier</code>或者<code>gauss</code>初始化，更加重了初始化的计算量，即使忽略这个参数，也还是会用<code>constant</code>进行初始化。为此，我们只能更改caffe的源码来屏蔽weight和bias初始化的动作。</p>
<pre><code>vim src/caffe/layers/inner_product_layer.cpp
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span>
<span class="regexp">//</span>weight_filler-&gt;Fill(<span class="keyword">this</span>-&gt;blobs_[<span class="number">0</span>].get());
<span class="regexp">//</span>bias_filler-&gt;Fill(<span class="keyword">this</span>-&gt;blobs_[<span class="number">1</span>].get());
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span>
vim src/caffe/layers/base_conv_layer.cpp
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span>
<span class="regexp">//</span>weight_filler-&gt;Fill(<span class="keyword">this</span>-&gt;blobs_[<span class="number">0</span>].get());
<span class="regexp">//</span>bias_filler-&gt;Fill(<span class="keyword">this</span>-&gt;blobs_[<span class="number">1</span>].get());
</code></pre><p>而且predict的过程，由于没有backward方法，也不需要使用net中的diff参数。所以在初始化的过程中也可以屏蔽。</p>
<pre><code>vim src/caffe/blob.cpp
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span>
<span class="regexp">//</span>diff_.reset(<span class="keyword">new</span> SyncedMemory(capacity_ * sizeof(Dtype)));
</code></pre><h2 id="vtune使用">vtune使用</h2><p>上述这种优化都是通过vtune工具分析代码的运行时间分析了程序初始化过程中的耗时的点，从而进行的优化。vtune大法好，vtune是intel的代码性能优化工具。</p>
<pre><code>vtune_amplifier_xe<span class="regexp">/bin64/</span>amplxe-gui
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/03/caffe-forward/" data-id="cja4p2ibm0040rofhao5399y1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-interview" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/03/interview/" class="article-date">
  <time datetime="2017-06-03T13:12:48.000Z" itemprop="datePublished">2017-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/03/interview/">试题整理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="mAP指标的含义">mAP指标的含义</h2><p>平均准确率均值mAP(Mean Average Precision)<br>对于每类事件根据每个样本得到的预测分值绘制准确率-召回率(precision-recall)曲线<br>计算曲线下区域面积即AP(Average precision)<br>对所有事件类别计算AP的均值，即mAP</p>
<h2 id="caffe实现中使用了大量的虚函数、类模板，请介绍一下虚函数、类模板以及虚基类的使用场景">caffe实现中使用了大量的虚函数、类模板，请介绍一下虚函数、类模板以及虚基类的使用场景</h2><p>虚函数：是使基类指针指向派生类，用来方便通过基类调用不同派生类的函数实现，例如caffe中各种layer的forward方法。<br>类模板：多个类有共同操作，只是数据类型不同时候使用类模板。<br>虚基类：主要用在多重继承的派生类中，使派生类只保留间接基类的一份成员，多重继承较为复杂容易出错，不推荐这种用法</p>
<h2 id="softmaxloss在深度学习中为何最为流行，有哪些优势；为何将softmax和交叉熵损失放在一起，有什么好处">softmaxloss在深度学习中为何最为流行，有哪些优势；为何将softmax和交叉熵损失放在一起，有什么好处</h2><p><a href="https://zhuanlan.zhihu.com/p/25723112" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/25723112</a><br><a href="http://freemind.pluskid.org/machine-learning/softmax-vs-softmax-loss-numerical-stability/" target="_blank" rel="external">http://freemind.pluskid.org/machine-learning/softmax-vs-softmax-loss-numerical-stability/</a><br>这两篇文章对于softmax解释的非常好，在深度学习中使用最为广泛，有两个原因，一是其输出为类别的概率值，二是因为其梯度求导特别简单。交叉熵的函数形式为</p>
<pre><code>Loss = -<span class="function"><span class="title">sum</span><span class="params">(y_i*ln(z_i)</span></span>) <span class="comment">// z_i为softmax输出，y_i为ground_truth</span>
</code></pre><p>由于softmax的特点，其导数特别友好，非常方便计算。如果将softmax和交叉熵分成两部分，就会多计算一个乘z_j再除z_j的过程，由于z_j为softmax输出，很可能非常小，会有可能导致float数据类型溢出，从而结果错误。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/03/interview/" data-id="cja4p2i9p002grofhfrq4m5j1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-gpu" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/22/tensorflow-gpu/" class="article-date">
  <time datetime="2017-04-22T08:29:36.000Z" itemprop="datePublished">2017-04-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/04/22/tensorflow-gpu/">tensorflow学习（十三）GPU使用技巧整理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="显存使用控制">显存使用控制</h2><p>如果不设置，tensorflow会默认占用所有的GPU显存。解决方法如下，GPU会根据使用的情况根据需求增加GPU显存的使用</p>
<pre><code>config = tf.<span class="function"><span class="title">ConfigProto</span><span class="params">()</span></span>  
config<span class="class">.gpu_options</span><span class="class">.allow_growth</span>=True
sess = tf.<span class="function"><span class="title">Session</span><span class="params">(config=config)</span></span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/22/tensorflow-gpu/" data-id="cja4p2i8f0015rofhxe45f77a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-mydata" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/29/tensorflow-mydata/" class="article-date">
  <time datetime="2017-03-29T13:47:50.000Z" itemprop="datePublished">2017-03-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/29/tensorflow-mydata/">tensorflow学习（十二）加载自定义图像数据集</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前介绍了一种官方的TFRecords序列化方法，感觉过于复杂，这次实践一次自定义数据集的数据加载方案。介绍几个关键的步骤。</p>
<h2 id="数据读取">数据读取</h2><ul>
<li>获取数据集的图像文件以及对应标签文件的文件名列表</li>
<li>讲文件名列表转换为tensor格式</li>
<li>根据文件名列表读取图像并转换为tensor，并进行预处理</li>
<li>产生一个batch的数据</li>
</ul>
<p>其中前3个方法在<code>ImageReader</code>初始化过程中实现，最后一个步骤在<code>dequeue</code>方法中实现，实例如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">read_labeled_image_list</span><span class="params">(data_dir, data_list)</span>:</span>
    f = open(data_list, <span class="string">'r'</span>)
    images = []
    labels = []
    <span class="keyword">for</span> line <span class="keyword">in</span> f:
        image, label = line.strip(<span class="string">"\n"</span>).split(<span class="string">' '</span>)
        images.append(data_dir + image)
        labels.append(int(label))
    <span class="keyword">return</span> images, labels

<span class="function"><span class="keyword">def</span> <span class="title">read_images_from_disk</span><span class="params">(input_queue, input_size, random_scale)</span>:</span> 
    img_contents = tf.read_file(input_queue[<span class="number">0</span>])
    img = tf.image.decode_jpeg(img_contents, channels=<span class="number">3</span>)
    <span class="keyword">if</span> input_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:
        h = input_size
        w = input_size
        <span class="keyword">if</span> random_scale:
            scale = tf.random_uniform([<span class="number">1</span>], minval=<span class="number">0.75</span>, maxval=<span class="number">1.25</span>, dtype=tf.float32, seed=<span class="keyword">None</span>)
            h_new = tf.to_int32(tf.mul(tf.to_float(tf.shape(img)[<span class="number">0</span>]), scale))
            w_new = tf.to_int32(tf.mul(tf.to_float(tf.shape(img)[<span class="number">1</span>]), scale))
            new_shape = tf.squeeze(tf.pack([h_new, w_new]), squeeze_dims=[<span class="number">1</span>])
            img = tf.image.resize_images(img, new_shape)
        img = tf.image.resize_image_with_crop_or_pad(img, h, w)
    <span class="comment"># RGB -&gt; BGR.</span>
    img_r, img_g, img_b = tf.split(split_dim=<span class="number">2</span>, num_split=<span class="number">3</span>, value=img)
    img = tf.cast(tf.concat(<span class="number">2</span>, [img_b, img_g, img_r]), dtype=tf.float32)
    <span class="comment"># Extract mean.</span>
    img -= np.array((<span class="number">104.008</span>,<span class="number">116.669</span>,<span class="number">122.675</span>), dtype=np.float32)

    label = tf.cast(input_queue[<span class="number">1</span>], tf.int32)
    <span class="keyword">return</span> img, label

<span class="class"><span class="keyword">class</span> <span class="title">ImageReader</span><span class="params">(object)</span>:</span>
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_dir, data_list, input_size, random_scale)</span>:</span>
        self.data_dir = data_dir
        self.data_list = data_list
        self.input_size = input_size

        self.image_list, self.label_list = read_labeled_image_list(self.data_dir, self.data_list)
        self.images = tf.convert_to_tensor(self.image_list, dtype=tf.string)
        self.labels = tf.convert_to_tensor(self.label_list, dtype=tf.string)
        self.queue = tf.train.slice_input_producer([self.images, self.labels],
                                                   shuffle=input_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>) <span class="comment"># Not shuffling if it is val.</span>
        self.image, self.label = read_images_from_disk(self.queue, self.input_size, random_scale) 

    <span class="function"><span class="keyword">def</span> <span class="title">dequeue</span><span class="params">(self, num_elements)</span>:</span>
        image_batch, label_batch = tf.train.batch([self.image, self.label], num_elements)
        <span class="keyword">return</span> image_batch, label_batch
</code></pre><h2 id="线程和队列">线程和队列</h2><p><code>Coordinator</code>类负责多个线程的同步工作和同步终止，<code>tf.train.start_queue_runners</code>负责创建一组线程。推荐的使用模版</p>
<pre><code>init_op = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init_op)

# <span class="operator"><span class="keyword">Start</span> <span class="keyword">input</span> <span class="keyword">enqueue</span> threads.
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

try:
    <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():
        sess.run(train_op)
<span class="keyword">except</span> tf.<span class="keyword">errors</span>.OutOfRangeError:
    print <span class="string">'Done training -- epoch limit reached'</span>
finally:
    coord.request_stop()

coord.<span class="keyword">join</span>(threads)
sess.<span class="keyword">close</span>()</span>
</code></pre><h2 id="调用实例">调用实例</h2><pre><code><span class="comment"># image_batch, label_batch = tf.train.batch([image, label], 32)</span>
<span class="constant">reader</span> = ImageReader()
image_batch, label_batch = reader.dequeue(32)
<span class="constant">loss</span> = loss = tf.nn.softmax_cross_entropy_with_logits(prediction, label_batch)

<span class="constant">init_op</span> = tf.global_variables_initializer()
<span class="constant">sess</span> = tf.Session()
sess.run(init_op)

<span class="constant">coord</span> = tf.train.Coordinator()
<span class="constant">threads</span> = tf.train.start_queue_runners(sess=sess, coord=coord)

<span class="title">try:</span>
    for step in range(args.num_steps):
        loss_value = sess.run(loss)
except tf.errors.OutOfRangeError:
    print 'Done training -- epoch limit reached'
<span class="title">finally:</span>
    coord.request_stop()

coord.join(threads)
sess.close()
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/29/tensorflow-mydata/" data-id="cja4p2i7z000trofhj9qa5jxd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-saver" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/26/tensorflow-saver/" class="article-date">
  <time datetime="2017-03-26T02:04:50.000Z" itemprop="datePublished">2017-03-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/26/tensorflow-saver/">tensorflow学习（十一）保存和恢复模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="保存/恢复对象">保存/恢复对象</h2><p>tf.train.Saver这个类负责保存和恢复模型。实际使用中，可以在模型训练的不同阶段保存多个checkpoints。为了防止硬盘被写满，保存模型过大，实际中保存n个最近的checkpoints。</p>
<pre><code><span class="preprocessor"># save</span>
v1 = tf.Variable(<span class="number">1.0</span>, name=<span class="string">"v1"</span>)
saver = tf.train.Saver()  <span class="preprocessor"># global</span>
saver_local = tf.train.Saver({<span class="string">'v1'</span>: v1})  <span class="preprocessor"># local</span>
sess = tf.Session()
<span class="keyword">for</span> <span class="keyword">step</span> <span class="keyword">in</span> xrange(<span class="number">1000000</span>):
    sess.<span class="built_in">run</span>(..training_op..)
    <span class="keyword">if</span> <span class="keyword">step</span> % <span class="number">1000</span> == <span class="number">0</span>:
        saver.save(sess, <span class="string">'my-model'</span>, global_step=<span class="keyword">step</span>)  ==&gt; filename: <span class="string">'my-model-1000'</span>

<span class="preprocessor"># restore</span>
saver.restore(sess, <span class="string">'my-model-1000'</span>)
saver.restore(sess, saver.latest_checkpoint())  <span class="preprocessor"># 可以自动传入参数路径</span>
</code></pre><p>执行save方法之后，会生成一系列的文件，最好是单独放在一个路径中。</p>
<h2 id="利用模型fine-tune">利用模型fine-tune</h2><pre><code>vgg_saver = <span class="keyword">tf</span>.train.import_meta_graph(<span class="string">'vgg16.meta'</span>)
vgg_graph = <span class="keyword">tf</span>.get_default_graph()

self.x_plh = vgg_grah.get_tensor_by_name(<span class="string">'input:0'</span>)

# 选择想要保留的层
output_conv =vgg_graph.get_tensor_by_name(<span class="string">'conv1_2:0'</span>)
# output_conv =vgg_graph.get_tensor_by_name(<span class="string">'conv2_2:0'</span>)
# output_conv =vgg_graph.get_tensor_by_name(<span class="string">'conv3_3:0'</span>)

output_conv_sg = <span class="keyword">tf</span>.stop_gradient(output_conv)

# 添加自己的网络结构
output_conv_shape = output_conv_sg.get_shape().as_list()
W1 = <span class="keyword">tf</span>.get_variable(<span class="string">'W1'</span>, shape=[<span class="number">1</span>, <span class="number">1</span>, output_conv_shape[<span class="number">3</span>], <span class="number">32</span>], initializer=<span class="keyword">tf</span>.random_normal_initializer(stddev=<span class="number">1</span><span class="keyword">e</span>-<span class="number">1</span>))
b1 = <span class="keyword">tf</span>.get_variable(<span class="string">'b1'</span>, shape=[<span class="number">32</span>], initializer=<span class="keyword">tf</span>.constant_initializer(<span class="number">0.1</span>))
z1 = <span class="keyword">tf</span>.<span class="keyword">nn</span>.conv2d(output_conv_sg, W1, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) + b1
<span class="keyword">a</span> = <span class="keyword">tf</span>.<span class="keyword">nn</span>.relu(z1)
</code></pre><h2 id="从caffe模型加载参数">从caffe模型加载参数</h2><p>tensorflow其实可以从任意算法，我们这里用caffe的模型参数为例</p>
<pre><code>from six<span class="class">.moves</span> import cPickle

net = caffe.<span class="function"><span class="title">Net</span><span class="params">(args.prototxt, args.caffemodel, caffe.TEST)</span></span>

net_skeleton = <span class="function"><span class="title">list</span><span class="params">()</span></span> 
<span class="keyword">for</span> name, item <span class="keyword">in</span> net<span class="class">.params</span><span class="class">.iteritems</span>():
    net_skeleton.<span class="function"><span class="title">append</span><span class="params">([name + <span class="string">'/w'</span>, item[<span class="number">0</span>].data.shape[::-<span class="number">1</span>]])</span></span>
    net_skeleton.<span class="function"><span class="title">append</span><span class="params">([name + <span class="string">'/b'</span>, item[<span class="number">1</span>].data.shape])</span></span>
with <span class="function"><span class="title">open</span><span class="params">(os.path.join(args.output_dir, <span class="string">'net_skeleton.ckpt'</span>)</span></span>, <span class="string">'wb'</span>) as f:
    cPickle.<span class="function"><span class="title">dump</span><span class="params">(net_skeleton, f, protocol=cPickle.HIGHEST_PROTOCOL)</span></span>

net_weights = <span class="function"><span class="title">dict</span><span class="params">()</span></span>
<span class="keyword">for</span> name, item <span class="keyword">in</span> net<span class="class">.params</span><span class="class">.iteritems</span>():
    net_weights[name + <span class="string">'/w'</span>] = item[<span class="number">0</span>]<span class="class">.data</span><span class="class">.transpose</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>)
    net_weights[name + <span class="string">'/b'</span>] = item[<span class="number">1</span>]<span class="class">.data</span>
with <span class="function"><span class="title">open</span><span class="params">(os.path.join(args.output_dir,<span class="string">'net_weights.ckpt'</span>)</span></span>, <span class="string">'wb'</span>) as f:
    cPickle.<span class="function"><span class="title">dump</span><span class="params">(net_weights, f, protocol=cPickle.HIGHEST_PROTOCOL)</span></span>
<span class="tag">del</span> net, net_skeleton, net_weights
</code></pre><p>保存好上述模型后，通过下面的方法加载即可</p>
<pre><code>saver = tf<span class="class">.train</span><span class="class">.Saver</span>(var_list=trainable)
saver.<span class="function"><span class="title">restore</span><span class="params">(sess, os.path.join(args.output_dir,<span class="string">'net_weights.ckpt'</span>)</span></span>)
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/26/tensorflow-saver/" data-id="cja4p2i7z000qrofheu567ujy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-update" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/27/tensorflow-update/" class="article-date">
  <time datetime="2017-02-27T13:56:03.000Z" itemprop="datePublished">2017-02-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/27/tensorflow-update/">tensorflow学习（十）实用工具介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="compatibility升级代码到兼容1-0版本">compatibility升级代码到兼容1.0版本</h2><h3 id="更新脚本">更新脚本</h3><pre><code><span class="comment"># file</span>
tf_upgrade.py --infile <span class="variable">&lt;input_code&gt;</span> --outfile <span class="variable">&lt;output_code&gt;</span>
<span class="comment"># dir</span>
tf_upgrade.py --intree <span class="variable">&lt;input_dir&gt;</span> -outtree <span class="variable">&lt;output_dir&gt;</span>
</code></pre><p>执行过程中的新旧函数改动详见<code>report.txt</code>。</p>
<h3 id="tips">tips</h3><ul>
<li><p>注意升级代码之前不要手工更改代码</p>
</li>
<li><p>升级后的部分函数无法更新，需要根据日志再手工更新部分函数</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/02/27/tensorflow-update/" data-id="cja4p2i7j000krofhhb6chr73" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow1-0-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/19/tensorflow1-0-install/" class="article-date">
  <time datetime="2017-02-19T12:52:10.000Z" itemprop="datePublished">2017-02-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/19/tensorflow1-0-install/">tensorflow学习（九）1.0正式版安装配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>近期tensorflow发布了正式版，我们也赶快更新起来。</p>
<h2 id="安装环境">安装环境</h2><p>操作系统centOS 7.0， k80四卡。注意tensorflow1.0.0只支持CUDA8，所以需要将<strong>CUDA升级到8.0，cudnn升级到v5.1</strong>。</p>
<h2 id="安装OpenCV">安装OpenCV</h2><p>注意之前选择的OpenCV2.4.11版本对CUDA8.0是不兼容的，要升级到<strong>OpenCV2.4.13</strong>。</p>
<pre><code>cd ~/opencv
mkdir <span class="operator"><span class="keyword">release</span>
cd <span class="keyword">release</span>
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=<span class="keyword">RELEASE</span> -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> -<span class="keyword">D</span> CUDA_GENERATION=Kepler ..
make -j8
sudo make <span class="keyword">install</span></span>
</code></pre><p>因为OpenCV在cmake的时候找不到anaconda的python路径，所以需要手动将cv2.so和cv.py复制到anaconda对应的lib下。注意安装完之后再编译与OpenCV相关程序会出现报错<code>cannot find -lopencv_dep_cudart</code>。解决办法是要控制CMake的一个开关，在cmake的时候注意</p>
<pre><code>cmake -D CUD<span class="built_in">A_USE</span>_STATIC_CUD<span class="built_in">A_RUNTIME</span>=OFF ..
</code></pre><p>或者在CMakeLists.txt中在<code>find_package(OpenCV REQUIRED)</code>前添加</p>
<pre><code><span class="function"><span class="title">set</span><span class="params">(CUDA_USE_STATIC_CUDA_RUNTIME OFF)</span></span>
</code></pre><p>但这样还是需要更改每个工程的配置，还是有些麻烦，我采用了大杀器，更改了cmake安装包里的默认配置。使用的是cmake3.7.0这个安装包。</p>
<pre><code>vim ./Modules/FindCUDA.cmake
# line 793, ON <span class="comment">--&gt; OFF</span>
option(CUDA_USE_STATIC_CUDA_RUNTIME "<span class="operator"><span class="keyword">Use</span> the <span class="keyword">static</span> <span class="keyword">version</span> <span class="keyword">of</span> the CUDA runtime <span class="keyword">library</span> <span class="keyword">if</span> available<span class="string">" OFF)</span></span>
</code></pre><p>注意官网日志说明<strong>OpenCV3.2版本支持CUDA8</strong>，如果硬着头皮上OpenCV3.2，安装也没啥多说的。注意k80的GPU是kepler架构，如果是pascal架构的也要相应选择。在安装的时候还会遇到<code>Downloading ippicv_linux_20151201.tgz...</code>的问题，要确保服务器能访问<code>raw.githubusercontent.com</code>。还有一个bug是mkl也要更新到1.13新版本，不然会报错缺少<code>mkl_version.h</code>文件。</p>
<h2 id="安装tensorflow">安装tensorflow</h2><p>新版本tensorflow安装已经非常简单了，只需要直接pip安装即可。相应的依赖包都会自动更新到匹配版本，非常方便</p>
<pre><code>pip <span class="keyword">install</span> tensorflow-gpu    <span class="comment"># gpu version</span>
pip <span class="keyword">install</span> tensorflow    <span class="comment"># cpu version</span>
</code></pre><h2 id="tips">tips</h2><p>安装好之后可能会遇到can’t find libmkl_avx.so的问题，应该是anaconda和tensorflow的安装顺序导致的，可以通过下面的办法暂时解决</p>
<pre><code><span class="built_in">export</span> LD_PRELOAD=libmkl_rt.so
</code></pre><h2 id="安装bazel">安装bazel</h2><h3 id="安装jdk8">安装jdk8</h3><p>bazel需要java8的支持，由于系统本身有一套jdk7的环境，我这套jdk8的环境只想对我生效，配置如下：</p>
<pre><code>download jdk-<span class="number">8</span>u131-linux-x64.tar.gz
tar xzvf jdk-<span class="number">8</span>u131-linux-x64.tar.gz
vim ~/.bashrc
    export JAVA_HOME=<span class="variable">$HOME</span>/software_bak/jdk1.<span class="number">8.0_131</span>
    export PATH=<span class="variable">$JAVA</span>_HOME/bin:<span class="variable">$PATH</span>
    export CLASSPATH=.:<span class="variable">$JAVA</span>_HOME/lib/dt.jar:<span class="variable">$JAVA</span>_HOME/lib/tools.jar
source ~/.bashrc
java -version
</code></pre><h3 id="安装bazel-1">安装bazel</h3><pre><code>wget https:<span class="comment">//github.com/bazelbuild/bazel/releases/download/0.5.1/bazel-0.5.1-installer-linux-x86_64.sh</span>
chmod +x bazel-<span class="number">0.5</span>.<span class="number">1</span>-installer-linux-x86_64<span class="class">.sh</span>
./bazel-<span class="number">0.5</span>.<span class="number">1</span>-installer-linux-x86_64<span class="class">.sh</span> --user
vim ~/<span class="class">.bashrc</span>
    export PATH=<span class="variable">$PATH</span>:<span class="variable">$HOME</span>/bin
source ~/<span class="class">.bashrc</span>
bazel version
</code></pre><h2 id="源码安装tensorflow">源码安装tensorflow</h2><pre><code>git    clone --recurse-submodules <span class="string">https:</span><span class="comment">//github.com/tensorflow/tensorflow</span>
cd tensorflow
.<span class="regexp">/configure /</span>/ 大部分都使用默认选项，注意GPU选项要打开
bazel build -c opt --config=cuda <span class="comment">//tensorflow/tools/pip_package:build_pip_package</span>
bazel-bin<span class="regexp">/tensorflow/</span>tools<span class="regexp">/pip_package/</span>build_pip_package <span class="regexp">/tmp/</span>tensorflow_pkg
pip install <span class="regexp">/tmp/</span>tensorflow_pkg/tensorflow-<span class="number">0.10</span><span class="number">.0</span>-py2-none-any.whl
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/02/19/tensorflow1-0-install/" data-id="cja4p2i7j000grofh3u73ncu1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-cmake-learn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/30/cmake-learn/" class="article-date">
  <time datetime="2016-12-30T02:20:10.000Z" itemprop="datePublished">2016-12-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/30/cmake-learn/">用CMake搭建一个高质量的C/C++工程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="准备工作">准备工作</h2><ul>
<li>将工程c源码放入子文件夹<code>src</code>中</li>
<li>将工程头文件放入子文件夹<code>include</code>中</li>
<li>将说明文档放入子文件夹<code>doc</code>中</li>
<li>在根目录创建<code>COPYRIGHT、README、sh启动脚本</code></li>
</ul>
<h2 id="常用关键命令">常用关键命令</h2><p>定义工程名称，定义好会预定义两个工程变量<code>PROJECT_BINARY_DIR</code>，<code>PROJECT_SOURCE_DIR</code>。</p>
<pre><code><span class="function">PROJECT</span>(projectname <span class="attr_selector">[CXX]</span> <span class="attr_selector">[C]</span>)
</code></pre><p>显式定义变量</p>
<pre><code><span class="operator"><span class="keyword">SET</span>(<span class="keyword">VAR</span> [<span class="keyword">VALUE</span>])
<span class="keyword">SET</span>(SRC_LIST <span class="keyword">main</span>.<span class="keyword">c</span> func1.<span class="keyword">c</span>)     # eg.</span>
</code></pre><p>终端输出，printf功能，其中SEND_ERROR表示出错信息，生成过程跳过，STATUS输出前缀为-的信息，FATAL_ERROR会终止程序</p>
<pre><code><span class="function"><span class="title">MESSAGE</span><span class="params">([SEND_ERROR |STATUS | FATAL_ERROR] <span class="string">"message to display"</span> ...)</span></span>
</code></pre><p>定义工程生成可执行文件</p>
<pre><code><span class="function"><span class="title">ADD_EXECUTABLE</span><span class="params">(hello ${SRC_LIST})</span></span>
</code></pre><p>定义工程生成库文件</p>
<pre><code>ADD_LIBRARY<span class="list">(<span class="keyword">libname</span> [SHARED|STATIC|MODULE] ${SRC_LIST})</span>
</code></pre><p>将src子目录加入工程</p>
<pre><code><span class="function"><span class="title">ADD_SUBDIRECTORY</span><span class="params">(source_dir [binary_dir])</span></span>
</code></pre><p>定义工程头文件目录</p>
<pre><code><span class="function">INCLUDE_DIRECTORIES</span>(<span class="attr_selector">[AFTER|BEFORE]</span><span class="attr_selector">[SYSTEM]</span> ${INC_DIR})
</code></pre><h2 id="链接动态库">链接动态库</h2><p>链接动态库名称（gcc中的-l）</p>
<pre><code><span class="function"><span class="title">TARGET_LINK_LIBRARIES</span><span class="params">(target library1 &lt;debug | optimized&gt; library2 ...)</span></span>
</code></pre><p>链接时路径ling-time path（gcc中的-L）</p>
<pre><code><span class="function"><span class="title">LINK_DIRECTORIES</span><span class="params">(${LIB_DIR})</span></span>
</code></pre><p>运行时路径run-time path（gcc中的-rpath）</p>
<pre><code><span class="keyword">set</span>(CMAKE_SKIP_BUILD_RPATH <span class="keyword">FALSE</span>)    <span class="comment"># 决定编译时是否添加rpath信息</span>
<span class="keyword">set</span>(CMAKE_BUILD_WITH_INSTALL_RPATH <span class="keyword">TRUE</span>)    <span class="comment"># 使编译安装使用同一rpath</span>
<span class="keyword">set</span>(CMAKE_INSTALL_RPATH $ORIGIN) <span class="comment"># ORIGIN为当前目录，很有用的一个宏</span>
<span class="keyword">set</span>(CMAKE_INSTALL_RPATH_USE_LINK_PATH <span class="keyword">FALSE</span>) <span class="comment"># 设为FALSE可以将编译和运行时的路径分开</span>
</code></pre><h3 id="查看链接库信息命令">查看链接库信息命令</h3><ul>
<li><strong>ldd</strong>列出动态库依赖信息</li>
<li><strong>readelf -d</strong>查看动态库的信息</li>
<li><strong>file</strong>查看文件信息</li>
</ul>
<h2 id="常用环境变量">常用环境变量</h2><pre><code><span class="constant">PROJECT_BINARY_DIR</span>  <span class="comment"># 工程生成目录（通常是当前目录）</span>
<span class="constant">PROJECT_SOURCE_DIR</span>  <span class="comment"># 工程根目录</span>
<span class="constant">SET</span>(<span class="constant">EXECUTABLE_OUTPUT_PATH</span> <span class="variable">${</span><span class="constant">PROJECT_BINARY_DIR</span>}/bin)
<span class="constant">SET</span>(<span class="constant">LIBRARY_OUTPUT_PATH</span> <span class="variable">${</span><span class="constant">PROJECT_BINARY_DIR</span>}/<span class="class"><span class="keyword">lib</span>)</span>
<span class="constant">CMAKE_INSTALL_PREFIX</span>  <span class="comment"># 配置安装路径，默认定义是/usr/local</span>
</code></pre><h2 id="OpenCV相关技巧">OpenCV相关技巧</h2><pre><code><span class="function"><span class="title">find_package</span><span class="params">(OpenCV REQUIRED)</span></span>
<span class="function"><span class="title">target_link_libraries</span><span class="params">(target ${OpenCV_LIBS})</span></span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/30/cmake-learn/" data-id="cja4p2iar003drofhws995to9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c-c/">c/c++</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-add-jni-example" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/08/28/caffe-add-jni-example/" class="article-date">
  <time datetime="2016-08-28T04:08:31.000Z" itemprop="datePublished">2016-08-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/28/caffe-add-jni-example/">caffe学习（八）添加模块并JNI移植</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="添加识别代码">添加识别代码</h2><p>examples文件夹下面新建文件夹<code>porno_recognition</code>，并添加cpp源码。这里从<code>caffe/examples/cpp_classification/classification.cpp</code>中复制了一段识别的代码，并修改classify函数以及添加load函数。由于要生成动态链接库，所以把main函数屏蔽掉。</p>
<h2 id="修改Makefile">修改Makefile</h2><p>找到<code>$(EXAMPLE_BINS): %.bin : %.o | $(DYNAMIC_NAME)</code>部分，添加<code>-fPIC -shared</code>，重新<code>make all</code>，编译生成 build/examples/porno_recognition/porno_recognition.bin，可以看到这个新生成的bin比之前的小，确认其为动态链接库的模型，执行<code>mv porno_recognition.bin libSuningPore.so</code></p>
<h2 id="JNI">JNI</h2><h3 id="添加java接口函数">添加java接口函数</h3><p>创建文件夹<code>com\suning\pore</code>并在其目录下面添加<code>SuningPore.java</code>，代码如下：</p>
<pre><code><span class="keyword">package</span> com.suning.pore;

<span class="keyword">public</span> class SuningPore
{
    <span class="keyword">static</span>
    {        
        System.loadLibrary(<span class="string">"SuningPore"</span>);
        System.out.<span class="built_in">println</span>(<span class="string">"***载入libSuningPore.so完成***"</span>);
    }

    <span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">static</span> <span class="built_in">int</span> load(<span class="keyword">String</span> ocrDataPath, <span class="keyword">String</span> libPath, <span class="keyword">String</span> logPath);
    <span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">static</span> <span class="keyword">String</span> start(<span class="keyword">String</span> imgUrl, <span class="built_in">byte</span>[] pic);
}
</code></pre><p>这其中的<code>loadLibrary</code>函数用来加载<code>libSuningPore.so</code>动态链接库。load和start两个函数是这个动态链接库提供的两个接口函数。</p>
<h3 id="创建-h文件">创建.h文件</h3><p>在com的上一级目录下，执行</p>
<pre><code>javah com<span class="class">.suning</span><span class="class">.pore</span><span class="class">.SuningPore</span>
</code></pre><p>生成文件<code>com_suning_pore_SuningPore.h</code></p>
<h3 id="创建cpp接口实现代码">创建cpp接口实现代码</h3><p>创建<code>com_suning_pore_SuningPore.cpp</code>，并实现对应头文件中定义的两个接口函数的实现。并将之前实现的<code>porno_recognition.cpp</code>与该文件整合为一个文件</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> <span class="string">"com_suning_pore_SuningPore.h"</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span>

<span class="function"><span class="keyword">int</span> <span class="title">jni_load</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *model_path, <span class="keyword">const</span> <span class="keyword">char</span>* lib_path, <span class="keyword">const</span> <span class="keyword">char</span> *log_path)</span></span>;

<span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">jni_start</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* imgUrl, <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> *p_imgdata, <span class="keyword">int</span> data_size)</span></span>;

<span class="function">JNIEXPORT jint JNICALL <span class="title">Java_com_suning_pore_SuningPore_load</span>
<span class="params">(JNIEnv *env, jclass obj, jstring model_path, jstring lib_path, jstring log_path)</span>
</span>{
    <span class="keyword">const</span> <span class="keyword">char</span> *model_string = (env)-&gt;GetStringUTFChars(model_path, <span class="number">0</span>);
    <span class="keyword">const</span> <span class="keyword">char</span> *lib_string = (env)-&gt;GetStringUTFChars(lib_path, <span class="number">0</span>);
    <span class="keyword">const</span> <span class="keyword">char</span> *log_string = (env)-&gt;GetStringUTFChars(log_path, <span class="number">0</span>);

    jint ret = jni_load(model_string, lib_string, log_string);

    (env)-&gt;ReleaseStringUTFChars(model_path, model_string);
    (env)-&gt;ReleaseStringUTFChars(log_path, log_string);
    (env)-&gt;ReleaseStringUTFChars(lib_path, lib_string);

    <span class="keyword">return</span> ret;
}

<span class="function">JNIEXPORT jstring JNICALL <span class="title">Java_com_suning_pore_SuningPore_start</span>
<span class="params">(JNIEnv *env, jclass obj, jstring img_url, jbyteArray in_buf)</span>
</span>{
    <span class="keyword">const</span> <span class="keyword">char</span> *url_string = (env)-&gt;GetStringUTFChars(img_url, <span class="number">0</span>);

    jbyte *cbuf;
    cbuf = (env)-&gt;GetByteArrayElements(in_buf, <span class="number">0</span>);
    jsize in_len = (env)-&gt;GetArrayLength(in_buf);

    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> *p_imgdata = (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)cbuf;
    <span class="keyword">int</span> data_size = in_len;

    jstring ret = <span class="number">0</span>;
    <span class="keyword">if</span> (p_imgdata == <span class="literal">NULL</span> || data_size &lt;= <span class="number">0</span>)
    {
        <span class="keyword">return</span> ret;
    }

    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> out_str = jni_start(p_imgdata, data_size);

    (env)-&gt;ReleaseStringUTFChars(img_url, url_string);
    (env)-&gt;ReleaseByteArrayElements(in_buf, cbuf, <span class="number">0</span>);

    <span class="keyword">if</span> (!out_str.empty()) {
        ret = (env)-&gt;NewStringUTF(out_str.c_str());
    }
    <span class="keyword">return</span> ret;
}
</code></pre><p>然后将<code>com_suning_pore_SuningPore.cpp</code>和<code>com_suning_pore_SuningPore.h</code>放入<code>caffe/examples/porno_recognition</code>文件夹中，修改<code>Makefile.config</code>的中加入java的include，重新编译生成<code>com_suning_pore_SuningPore.bin</code>（注意：该文件实际上是一个动态链接库，不可直接执行）。</p>
<pre><code><span class="comment">### Makefile.config ###</span>
<span class="comment"># INCLUDE_DIRS := ...</span>
    /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">include</span> \</span>
    /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">include</span>/<span class="title">linux</span> \</span>
</code></pre><h3 id="添加java测试程序">添加java测试程序</h3><p>在<code>com/suning/pore</code>下添加<code>TestSuningPore.java</code>并添加如下代码：</p>
<pre><code><span class="keyword">package</span> com.suning.pore;

<span class="keyword">import</span> java.io.File;
<span class="keyword">import</span> java.io.FileInputStream;
<span class="keyword">import</span> java.io.FileNotFoundException;

<span class="keyword">public</span> class TestSuningPore
{
    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(<span class="keyword">String</span>[] args) <span class="keyword">throws</span> Exception
    {
        <span class="comment">// TODO Auto-generated method stub</span>

        TestSuningPore test = <span class="keyword">new</span> TestSuningPore(); 

        <span class="keyword">if</span> (args.length == <span class="number">0</span>)
        {
            System.out.<span class="built_in">println</span>(<span class="string">"image file missing"</span>);
            <span class="keyword">return</span>;
        }
        test.porno_recognize(test.readImage(args[<span class="number">0</span>])); 
    }

    <span class="keyword">public</span> TestSuningPore(){}

    <span class="keyword">private</span> <span class="built_in">byte</span>[] readImage(<span class="keyword">String</span> path) <span class="keyword">throws</span> Exception
    {
        File <span class="built_in">image</span> = <span class="keyword">new</span> File(path);
        FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="built_in">image</span>);

        <span class="built_in">byte</span>[] b = <span class="keyword">new</span> <span class="built_in">byte</span>[(<span class="built_in">int</span>)<span class="built_in">image</span>.length()];
        fis.read(b);
        fis.close();

        <span class="keyword">return</span> b;
    }

    <span class="keyword">public</span> <span class="keyword">String</span> porno_recognize(<span class="built_in">byte</span>[] imageByte)
    {
        <span class="keyword">if</span>(<span class="keyword">null</span> != imageByte)
        {
            SuningPore suning_pore = <span class="keyword">new</span> SuningPore();
            <span class="built_in">boolean</span> status = <span class="keyword">false</span>;
            System.out.<span class="built_in">println</span>(<span class="string">"check status: "</span> + status);

            <span class="keyword">if</span>(!status)
            {    
                <span class="built_in">int</span> load = suning_pore.load(<span class="string">"/opt/pore/module/"</span>, <span class="string">"/opt/pore/lib/"</span>, <span class="string">"/opt/pore/log/"</span>);
                <span class="keyword">if</span>(load != <span class="number">1</span>)
                {
                    System.out.<span class="built_in">println</span>(<span class="string">"Error: load failed!"</span>);
                    <span class="keyword">return</span> <span class="string">"Error: load failed!"</span>;
                }
            }

            <span class="keyword">try</span>
            {

                <span class="keyword">String</span> words = suning_pore.start(imageByte);
                <span class="comment">//String words = SuningPore.start("http://abc.efg.cn/hij.jpg", imageByte);  // this also works</span>

                System.out.<span class="built_in">println</span>(<span class="string">"\nresulting words:\n"</span> + words);

                <span class="keyword">return</span> words;
            } <span class="keyword">catch</span> (Exception e) {
                <span class="comment">// TODO Auto-generated catch block</span>
                e.printStackTrace();
            }
        }
        <span class="keyword">return</span> <span class="keyword">null</span>;
    }
}
</code></pre><h2 id="测试jni接口">测试jni接口</h2><p>进入com上一级目录，并添加<code>run.sh</code>，添加如下代码：</p>
<pre><code>cp ~<span class="regexp">/caffe/</span>build<span class="regexp">/examples/</span>porno_recognition<span class="regexp">/com_suning_pore_SuningPore.bin ./</span>libSuningPore.so
cp ~<span class="regexp">/caffe/</span>build<span class="regexp">/lib/</span>libcaffe.so.<span class="number">1.0</span>.<span class="number">0</span>-rc3 .
javac -encoding UTF8 com<span class="regexp">/suning/</span>pore<span class="comment">/*.java
java -Djava.library.path=.  com.suning.pore.TestSuningPore $1</span>
</code></pre><p>通过<code>./run.sh xxx.jpg</code>命令测试该接口</p>
<h2 id="tips">tips</h2><h3 id="依赖动态链接库问题">依赖动态链接库问题</h3><p>由于<code>libSuningPore.so</code>和<code>libcaffe.so.1.0.0-rc3</code>依赖较多的动态链接库，可能需要指定动态链接库的路径，这时候把相关的动态链接库放到指定路径中，通过<code>/etc/profile</code>和source命令使该路径生效，并通过<code>/etc/ld.so.conf</code>文件设置<code>include /opt/xxx/xxx</code>并<code>ldconfig</code>来使系统更新相关路径的动态链接库。然后再重新编译caffe，通过<code>ldd</code>命令就可以查看这两个用到的动态库确实在新路径下找到了相关依赖。<br>需要注意的一点是，如果使用了mkl，注意可能需要一个<code>libiomp5.so</code>的文件，添加到相关动态链接库里就可以了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/08/28/caffe-add-jni-example/" data-id="cja4p2ibm004crofhlkwrvml2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-modelresource" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/22/tensorflow-modelresource/" class="article-date">
  <time datetime="2016-07-22T15:59:03.000Z" itemprop="datePublished">2016-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/22/tensorflow-modelresource/">tensorflow学习（八）模型资源</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>网上有众多基于tensorflow实现的各种网络，这里整理梳理一下</p>
<h2 id="VGG-16">VGG-16</h2><p><a href="https://github.com/ry/tensorflow-vgg16" target="_blank" rel="external">https://github.com/ry/tensorflow-vgg16</a><br>这是一个基于caffe转换过来的预训练好的vgg16的模型，参数文件可以通过torrent下载，模型的结构详见<code>vgg16.py</code>，这个网络没有训练的代码，不够nice</p>
<h2 id="ResNet">ResNet</h2><p><a href="https://github.com/ry/tensorflow-resnet" target="_blank" rel="external">https://github.com/ry/tensorflow-resnet</a><br>这也是一个从caffe转换过来的模型，训练好的模型文件可以通过torrent下载，其模型所需要的模块函数在<code>resnet.py</code>中，其<code>inference</code>和<code>inference_small</code>函数是完整网络。在<code>train_imagenet.py</code>中将模型声明logits传入<code>resnet_train.py</code>进行训练。</p>
<h2 id="fcn_(Fully_Convolutional_Networks)">fcn (Fully Convolutional Networks)</h2><p><a href="https://github.com/MarvinTeichmann/tensorflow-fcn" target="_blank" rel="external">https://github.com/MarvinTeichmann/tensorflow-fcn</a><br>将caffe的VGG-16模型转换成npy格式后，<code>fcnxx_vgg.py</code>定义了模型，并加载vgg.npy的数据参数。通过<code>test_fcn_vgg.py</code>参数测试图片的分割结果。该网络没有提供训练代码。</p>
<h2 id="YOLO">YOLO</h2><p><a href="https://github.com/gliese581gg/YOLO_tensorflow" target="_blank" rel="external">https://github.com/gliese581gg/YOLO_tensorflow</a><br>实现的一个YOLO的图像测试代码，比较简单，使用之前要下载对应的ckpt模型参数文件。没有训练代码，无法重现训练。</p>
<h2 id="Inception-V3">Inception-V3</h2><p><a href="https://github.com/tensorflow/models/tree/master/inception" target="_blank" rel="external">https://github.com/tensorflow/models/tree/master/inception</a><br>tensorflow官方提供的一个inception-v3的实现，有较为详细的数据加载，训练，测试的代码。值得仔细研究。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/22/tensorflow-modelresource/" data-id="cja4p2i7z000wrofhfebtz3bv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-yolo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/13/caffe-yolo/" class="article-date">
  <time datetime="2016-07-13T14:29:26.000Z" itemprop="datePublished">2016-07-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/13/caffe-yolo/">caffe学习（七）caffe-YOLO模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原本YOLO是一个darknet的独立代码，网上有些大神把其网络用caffe实现了。贴一个传送门<a href="https://github.com/xingwangsfu/caffe-yolo" target="_blank" rel="external">https://github.com/xingwangsfu/caffe-yolo</a>。这里参考这个代码实现一下，没有训练代码，需要将darknet训练好的参数转换成caffe格式。</p>
<h2 id="修改deploy">修改deploy</h2><p>要把<code>yolo_deploy.prototxt</code>里的<code>fc26</code>层中的<code>num_output</code>参数改为实际需要的。</p>
<h2 id="参数模型格式转换">参数模型格式转换</h2><p>用darknet训练好的网络参数通过<code>create_yolo_caffemodel.py</code>用caffe读进来。darknet的权重保存格式很简单，前4个数是int型，分别表示major、minor、revision和net.seen，第五个参数开始就是一个一维浮点数组，存成二进制文件。读入之后，根据网络结构得到net的各层weights和bias的size大小，并按顺序传入。调用格式如下：</p>
<pre><code>python create_yolo_caffemodel<span class="class">.py</span> -m ./prototxt/yolo_deploy<span class="class">.prototxt</span> -w yolo_final<span class="class">.weights</span> -o yolo.caffemodel
</code></pre><h2 id="YOLO检测">YOLO检测</h2><pre><code>python yolo_main<span class="class">.py</span> -m ./prototxt/yolo_deploy<span class="class">.prototxt</span> -w yolo<span class="class">.caffemodel</span> -<span class="tag">i</span> xxx.jpg
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/13/caffe-yolo/" data-id="cja4p2ib7003nrofhgxe26fs1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-guides-japan" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/06/guides-japan/" class="article-date">
  <time datetime="2016-07-06T11:54:34.000Z" itemprop="datePublished">2016-07-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/06/guides-japan/">日本攻略</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="调研">调研</h2><p>日本旅游局官网<a href="http://www.welcome2japan.cn/" target="_blank" rel="external">http://www.welcome2japan.cn/</a>，介绍的还挺好的，比天朝的官方网站做的高到不知道哪里去了</p>
<h2 id="出国准备注意事项">出国准备注意事项</h2><ul>
<li>签证：注意单次签证虽然给15天，建议不要排的太满，10天以内即可。</li>
<li>签证申请：<strong>必须通过旅行社</strong>，单次签，年收入10万以上，按旅行社的要求即可。签证搞到后，会给一份<strong>归国报告书</strong>，回国办理登记手续的时候给柜台盖章，寄给旅行社。</li>
<li>免费wifi，下载Japan Connected-Free Wifi的app</li>
</ul>
<h2 id="景点关键词">景点关键词</h2><ul>
<li>京都：寺庙</li>
<li>大阪：环球影城</li>
<li>东京：迪斯尼</li>
</ul>
<h2 id="现金">现金</h2><p>按每日每人1万日元准备吧~</p>
<h2 id="购物">购物</h2><p>超过1万日元消费可以在店内退税，带一张银联卡，便宜，好用</p>
<h1 id="东京攻略">东京攻略</h1><ul>
<li>公交卡：PASMO或者西瓜卡（SUICA）</li>
<li>皇家御所<a href="http://sankan.kunaicho.go.jp/" target="_blank" rel="external">http://sankan.kunaicho.go.jp/</a></li>
<li>宫崎骏吉卜力美术馆<a href="http://www.lawson.co.jp/ghibli/museum/ticket/" target="_blank" rel="external">http://www.lawson.co.jp/ghibli/museum/ticket/</a></li>
<li>公园：新宿御苑、浅草寺、上野公园</li>
<li>周边小镇：镰仓、箱根</li>
<li>地标：东京铁塔、东京天空树</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/06/guides-japan/" data-id="cja4p2iab002krofhbn73cwi0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/生活/">生活</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-spider" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/22/python-spider/" class="article-date">
  <time datetime="2016-06-22T13:02:36.000Z" itemprop="datePublished">2016-06-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/22/python-spider/">python爬虫入门笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="写在前面">写在前面</h1><p>爬虫其实内容的爬取不是最为困难的地方，真正难点在于如何混在群众之中不被发现。由于我在爬虫界还处于幼儿园水平，所以简单写几个脚本爬点美女图片还勉强，想跟亚一爬谈笑风生就不指望了。</p>
<h1 id="urllib基础">urllib基础</h1><h3 id="html抓取">html抓取</h3><pre><code>import urllib2

request = urllib2.<span class="function"><span class="title">Request</span><span class="params">(<span class="string">"http://www.baidu.com"</span>)</span></span>
response = urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(request)</span></span>
data = response.<span class="function"><span class="title">read</span><span class="params">()</span></span>
</code></pre><p>data就得到了百度主页的html信息。</p>
<h3 id="html解析">html解析</h3><p>主要就是用<code>re</code>模块来正则匹配</p>
<pre><code>import re

#返回pattern对象
re.<span class="function"><span class="title">compile</span><span class="params">(string[,flag])</span></span>  
#以下为匹配所用函数
re.<span class="function"><span class="title">match</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">search</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">split</span><span class="params">(pattern, string[, maxsplit])</span></span>
re.<span class="function"><span class="title">findall</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">finditer</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">sub</span><span class="params">(pattern, repl, string[, count])</span></span>
re.<span class="function"><span class="title">subn</span><span class="params">(pattern, repl, string[, count])</span></span>
</code></pre><p>比较常用的findall，用列表的形式返回全部能匹配的子串。</p>
<h1 id="反爬伪装">反爬伪装</h1><p>现在主流的反爬策略基本基于三个层面：</p>
<ul>
<li>IP层，同一ip访问过多会被封杀</li>
<li>HTTP协议层，判断是否真实的浏览器行为</li>
<li>行为层，判断是否真实用户行为<br>上述的程序通常在<code>response.read()</code>的时候会报错10054、10060之类的错误。</li>
</ul>
<h3 id="伪装浏览器Header">伪装浏览器Header</h3><p>用chrome打开浏览器，调试模式，然后打开Network模块，选择其中一个页面，打开Headers页面，其中最后的agent就是请求的身份，不填写身份的话，很容易被反爬策略封杀掉。</p>
<pre><code>user_agent = <span class="comment">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36'</span>
headers = {<span class="comment">'User-Agent' : user_agent}</span>
#    <span class="built_in">request</span> = urllib2.<span class="built_in">Request</span>(url, headers)
<span class="built_in">request</span> = urllib2.<span class="built_in">Request</span>(url)
<span class="built_in">request</span>.add_header(<span class="comment">'User-Agent', user_agent)</span>
<span class="built_in">response</span> = urllib2.urlopen(<span class="built_in">request</span>)
page = <span class="built_in">response</span>.read()
</code></pre><p>除此之外，有些反爬策略还有反盗链的设计，需要在headers中传入referer</p>
<pre><code>request.<span class="function"><span class="title">add_header</span><span class="params">(<span class="string">'Referer'</span>, <span class="string">'http://www.taobao.com'</span>)</span></span>
</code></pre><h3 id="proxy代理设置">proxy代理设置</h3><p>如果ip访问次数过多也会被封杀，采用代理服务器的方法来定期更换代理。</p>
<pre><code>enable_proxy = True
proxy_handler = urllib2.<span class="function"><span class="title">ProxyHandler</span><span class="params">({<span class="string">"http"</span> : <span class="string">'http://192.168.0.1:8080'</span>})</span></span>
null_proxy_handler = urllib2.<span class="function"><span class="title">ProxyHandler</span><span class="params">({})</span></span>
<span class="keyword">if</span> enable_proxy:
    opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(proxy_handler)</span></span>
<span class="keyword">else</span>:
    opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(null_proxy_handler)</span></span>
urllib2.<span class="function"><span class="title">install_opener</span><span class="params">(opener)</span></span>
</code></pre><h3 id="超时设置Timeout">超时设置Timeout</h3><p>在urlopen的时候可以通过设置timeout参数解决网站相应过慢造成的影响。</p>
<pre><code>response = urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(<span class="string">'http://www.baidu.com'</span>, timeout=<span class="number">10</span>)</span></span>
</code></pre><h3 id="发送数据">发送数据</h3><p>用来实现和浏览器之间的行为交互</p>
<pre><code><span class="keyword">data</span> = urllib.parse.urlencode({<span class="string">"act"</span>: <span class="string">"login"</span>, <span class="string">"email"</span>: <span class="string">"xxxxx@qq.com"</span>, <span class="string">"password"</span>: <span class="string">"123456"</span>}).encode(<span class="string">'utf-8'</span>)
request1 = urllib2.Request(url, <span class="keyword">data</span>=<span class="keyword">data</span>)           <span class="comment"># POST方法</span>
request2 = urllib2.Request(url+<span class="string">"?%s"</span> % <span class="keyword">data</span>)         <span class="comment"># GET方法</span>
response = urllib2.urlopen(request1)
</code></pre><h3 id="常用超时异常">常用超时异常</h3><pre><code>try:
    urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(request)</span></span>
except urllib2<span class="class">.HTTPError</span> as e:
    <span class="function"><span class="title">print</span><span class="params">(e.code, e.reason)</span></span>
except urllib2<span class="class">.URLError</span> as e:
    <span class="function"><span class="title">print</span><span class="params">(e.errno, e.reason)</span></span>
</code></pre><h3 id="服务器cookie检查">服务器cookie检查</h3><pre><code>import <span class="keyword">http</span>.cookiejar
cookie_jar = <span class="keyword">http</span>.cookiejar.CookieJar()
cookie_jar_handler = urllib.request.HTTPCookieProcessor(cookiejar=cookie_jar)
opener = urllib2.build_opener(cookie_jar_handler)        <span class="comment"># add_handler</span>
response = opener.<span class="built_in">open</span>(url)
</code></pre><h3 id="获取cookie">获取cookie</h3><p>两种方式，1）直接贴到headers中</p>
<pre><code>request = urllib2.<span class="function"><span class="title">Request</span><span class="params">(url)</span></span>
request.<span class="function"><span class="title">add_header</span><span class="params">(<span class="string">'Cookie'</span>, <span class="string">"PHPSESSID=btqkg9amjrtoeev8coq0m78396; USERINFO=n6nxTHTY%2BJA39z6CpNB4eKN8f0KsYLjAQTwPe%2BhLHLruEbjaeh4ulhWAS5RysUM%2B; "</span>)</span></span>
</code></pre><p>2）构建cookie</p>
<pre><code>import http<span class="class">.cookiejar</span>
cookie = http<span class="class">.cookiejar</span><span class="class">.Cookie</span>(name=<span class="string">"xx"</span>, value=<span class="string">"xx"</span>, domain=<span class="string">"xx"</span>, ...)
cookie_jar = http<span class="class">.cookiejar</span><span class="class">.CookieJar</span>()
cookie_jar.<span class="function"><span class="title">set_cookie</span><span class="params">(cookie)</span></span>
cookie_jar_handler = urllib<span class="class">.request</span><span class="class">.HTTPCookieProcessor</span>(cookiejar=cookie_jar)
opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(cookie_jar_handler)</span></span>
response = opener.<span class="function"><span class="title">open</span><span class="params">(url)</span></span>
</code></pre><h3 id="HTTP身份认证">HTTP身份认证</h3><pre><code>password_mgr = urllib2.<span class="function"><span class="title">HTTPPasswordMgrWithDefaultRealm</span><span class="params">()</span></span>
password_mgr.<span class="function"><span class="title">add_password</span><span class="params">(realm=None, uri=url, user=<span class="string">'username'</span>, passwd=<span class="string">'password'</span>)</span></span>
handler = urllib2.<span class="function"><span class="title">HTTPBasicAuthHandler</span><span class="params">(password_mgr)</span></span>
opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(handler)</span></span>
response = opener.<span class="function"><span class="title">open</span><span class="params">(url)</span></span>
</code></pre><h1 id="简易图片爬虫">简易图片爬虫</h1><p>关键的就是解析的时候匹配图片内容，得到了图片链接的话，用wget或者其他模块都能保存图片</p>
<pre><code>patternImg = re.<span class="function"><span class="title">compile</span><span class="params">(<span class="string">'&lt;img.*?src="(.*?)"'</span>,re.S)</span></span>
images = re.<span class="function"><span class="title">findall</span><span class="params">(patternImg, url_data)</span></span>
</code></pre><h1 id="参考资料与推荐文章">参考资料与推荐文章</h1><p><a href="http://cuiqingcai.com/" target="_blank" rel="external">http://cuiqingcai.com/</a><br><a href="http://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=402180172&amp;idx=1&amp;sn=1db24327a15cea8fab6907069fbaabbf&amp;scene=0#wechat_redirect" target="_blank" rel="external">数据时代的反爬虫绝技</a><br><a href="https://zhuanlan.zhihu.com/p/22982208" target="_blank" rel="external">一个很“水”的Python爬虫入门代码文件</a><br><a href="https://zhuanlan.zhihu.com/p/23064000" target="_blank" rel="external">“史上最详细”的Python模拟登录新浪微博流程</a><br><a href="https://luzhijun.github.io/2016/10/29/%E5%BE%AE%E5%8D%9A%E8%AF%9D%E9%A2%98%E7%88%AC%E5%8F%96%E4%B8%8E%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/" target="_blank" rel="external">微博话题爬取与存储分析</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/22/python-spider/" data-id="cja4p2i9a001profhmds2888y" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-caffe2tensorflow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/14/tensorflow-caffe2tensorflow/" class="article-date">
  <time datetime="2016-06-14T13:28:21.000Z" itemprop="datePublished">2016-06-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/14/tensorflow-caffe2tensorflow/">tensorflow学习（七）caffe模型训练结果转换为tensorflow格式</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>tensorflow官方认定的转换工具为<a href="https://github.com/ethereon/caffe-tensorflow" target="_blank" rel="external">https://github.com/ethereon/caffe-tensorflow</a>。我们尝试一下转换一个caffe训练的图像识别模型</p>
<h2 id="caffe-tensorflow安装">caffe-tensorflow安装</h2><pre><code>git clone <span class="string">https:</span><span class="comment">//github.com/ethereon/caffe-tensorflow</span>
</code></pre><h2 id="生成模型训练代码">生成模型训练代码</h2><p>利用<code>convert.py</code>可以将caffe网络定义的deploy.prototxt文件转换为tensorflow的python实现，不过这种转换之后的模型代码还需要import kaffe模块，虽然<code>kaffe.tensorflow.Network</code>没有其他依赖，可以单独加载到新代码中即可使用，方便移植，我还是更倾向于转换之后参考这个代码重新写一份。调用方式如下：</p>
<pre><code>./convert<span class="class">.py</span> ./deploy<span class="class">.prototxt</span> --code-output-path=./myNetTensorflow.py
</code></pre><h2 id="转换训练好的模型">转换训练好的模型</h2><p>也可以将caffemodel的weights和biases参数读取出来转换为npy的格式，并通过<code>numpy.load()</code>读取数据。转换数据的脚本如下：</p>
<pre><code>./convert<span class="class">.py</span> ./deploy<span class="class">.prototxt</span> --caffemodel=./mynet<span class="class">.caffemodel</span> --data-output-path=./myNetTensorflow.npy
</code></pre><p>由于转换过来的npy数据的类型比奇怪，是0-d array，要将其取出来需要如下读取方式</p>
<pre><code>params = np.<span class="function"><span class="title">load</span><span class="params">()</span></span>
params = params.<span class="function"><span class="title">item</span><span class="params">()</span></span>
</code></pre><h2 id="注意事项">注意事项</h2><ul>
<li><p>caffe的模型应该是较新的版本，才能转换</p>
</li>
<li><p>并不是所有的caffe模型都能转换为tensorflow，比如caffe的padding支持很多方式，tensorflow目前只支持<code>SAME</code>和<code>VALID</code></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/14/tensorflow-caffe2tensorflow/" data-id="cja4p2i8u001hrofh5gqtvr48" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-inception" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/13/tensorflow-inception/" class="article-date">
  <time datetime="2016-06-13T11:57:11.000Z" itemprop="datePublished">2016-06-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/13/tensorflow-inception/">tensorflow学习（六）CNN网络Inception</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次我们来上手一个大型网络,googLeNet。这篇讲一下Inception v3网络的训练和测试以及数据集的加载。</p>
<h2 id="数据准备">数据准备</h2><p>将图片按照类别放入不同的文件夹下。格式如下：</p>
<pre><code>data_dir/train/label_0/<span class="tag">a</span><span class="class">.jpg</span>
data_dir/train/label_0/<span class="tag">b</span><span class="class">.jpg</span>
...
data_dir/train/label_1/f<span class="class">.jpg</span>
...
data_dir/validation/label_0/c<span class="class">.jpg</span>
data_dir/validation/label_0/d<span class="class">.jpg</span>
...
data_dir/labels.txt
</code></pre><p>同时将所有label的类别整理成一个txt放在data_dir/labels.txt文件中，行数代表该类别对应的整数值，从0开始计数，其文本内容如下：</p>
<pre><code>label_0
label_1
label_2
...
label_n
</code></pre><h3 id="转化成为TFRecord格式">转化成为TFRecord格式</h3><p>首先通过<code>_find_iamge_files</code>函数得到全量图片的文件名、标签、标签文本信息的对应关系，并打乱排序。然后按线程数将全量文件分块，分别执行<code>_process_image_files_batch</code>。将数据按分块分别写入对应的TFRecordWriter。这个操作的代码我整理保存在了<a href="https://github.com/yangxian10/tensorflow_code/blob/master/build_image_tfrecord_data.py" target="_blank" rel="external">build_image_tfrecord_data.py</a>。其中两个重要的参数，一个是进程数量的控制参数<code>num_threads</code>和Record数据分块的参数<code>num_shards</code>。我这里有个不同，原来代码是读文件之后直接压入Record，我是用OpenCV解码之后，将解码后数据变成string压入Record。代码调用格式如下：</p>
<pre><code>python build_image_tfrecord_data.py \
  -<span class="ruby">-train_directory=mydata/train \
</span>  -<span class="ruby">-validation_directory=mydata/validation \
</span>  -<span class="ruby">-output_directory=mydata/tf_record \
</span>  -<span class="ruby">-labels_file=mydata/labels.txt</span>
</code></pre><h2 id="网络模型">网络模型</h2><h2 id="单机训练">单机训练</h2><h2 id="分布式训练">分布式训练</h2><h2 id="测试评估">测试评估</h2><h3 id="参考文献">参考文献</h3><p><a href="https://github.com/tensorflow/models/tree/master/inception" target="_blank" rel="external">https://github.com/tensorflow/models/tree/master/inception</a><br><a href="http://arxiv.org/abs/1512.00567" target="_blank" rel="external">http://arxiv.org/abs/1512.00567</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/13/tensorflow-inception/" data-id="cja4p2i8f0012rofhgdfaczxb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-captcha" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/13/tensorflow-captcha/" class="article-date">
  <time datetime="2016-06-13T11:52:35.000Z" itemprop="datePublished">2016-06-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/13/tensorflow-captcha/">tensorflow学习（五）基于CNN的验证码识别</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>验证码的识别是OCR中的一个重要内容，特别是对于爬虫系统意义重大，传统方法都是单个字符识别，包括二值化处理、字符分割、字符识别的过程。由于现在深度学习的火爆，end-to-end的方法流行起来。这里就用tensorflow实现一个端到端的CNN验证码识别功能。</p>
<p>本文的想法是把验证码看成一个多标签学习的问题，相当于几个有标签的图像识别。这里没有考虑使用LSTM对验证码序列进行学习，因为我个人觉得验证码字符之间的相关性不强，没必要用这种大杀器。</p>
<h2 id="验证码数据集">验证码数据集</h2><p>用<a href="https://pypi.python.org/pypi/captcha/0.1.1" target="_blank" rel="external">python-captcha</a>生成验证码数据集，这个库可以生成声音和图像的验证码，安装过程非常简单</p>
<pre><code>pip <span class="keyword">install</span> captcha
</code></pre><p>使用示例如下：</p>
<pre><code>from captcha<span class="class">.image</span> import ImageCaptcha

image = <span class="function"><span class="title">ImageCaptcha</span><span class="params">(fonts=[<span class="string">'/path/A.ttf'</span>, <span class="string">'/path/B.ttf'</span>])</span></span>
image.<span class="function"><span class="title">write</span><span class="params">(<span class="string">'1234'</span>, <span class="string">'out.png'</span>)</span></span>
</code></pre><h2 id="数据输入">数据输入</h2><p>验证码图片生成后是通过字节流生成的，可以随机生成，所以训练样本量可以无穷大。我们这里使用定长的4位验证码，包含0~9、a~z、A~Z。图像大小缩放到(30, 80, 3)。代码如下：</p>
<pre><code><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> cv2
<span class="keyword">import</span> random
<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="keyword">from</span> captcha.image <span class="keyword">import</span> ImageCaptcha

<span class="class"><span class="keyword">class</span> <span class="title">OCR_data</span><span class="params">(object)</span>:</span>
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num, data_dir, batch_size=<span class="number">50</span>, len_code=<span class="number">4</span>, height=<span class="number">30</span>, width=<span class="number">80</span>)</span>:</span>
        self.num = num
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.len_code = len_code
        self.height = height
        self.width = width
        self.captcha = ImageCaptcha()
        self.index_in_epoch = <span class="number">0</span>
        self._imgs = []
        self._labels = []
        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num):
            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:
                <span class="keyword">print</span> <span class="string">'%s images have been created.'</span> % i
            img, label = self.create_captcha()
            self._imgs.append(img)
            self._labels.append(label)
        self._imgs = np.array(self._imgs)
        self._labels = np.array(self._labels)


    <span class="function"><span class="keyword">def</span> <span class="title">create_captcha</span><span class="params">(self)</span>:</span>
        code, label = self.gen_rand()
        img = self.captcha.generate(code)
        img = np.fromstring(img.getvalue(), dtype=<span class="string">'uint8'</span>)
        img = cv2.imdecode(img, cv2.IMREAD_COLOR)
        img = cv2.resize(img, (self.width, self.height))
        <span class="keyword">return</span> (img, label)

    <span class="function"><span class="keyword">def</span> <span class="title">gen_rand</span><span class="params">(self)</span>:</span>
        buf = <span class="string">''</span>
        label = []
        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.len_code):
            rnd = random.randint(<span class="number">0</span>, <span class="number">61</span>)
            label.append(rnd)
            <span class="keyword">if</span> rnd &lt; <span class="number">10</span>:
                ascii_code = chr(rnd+<span class="number">48</span>)
            <span class="keyword">elif</span> rnd &lt; <span class="number">36</span>:
                ascii_code = chr(rnd+<span class="number">65</span>)
            <span class="keyword">else</span>:
                ascii_code = chr(rnd+<span class="number">97</span>)
            buf += ascii_code
        label_one_hot = self.dense_to_one_hot(label, <span class="number">62</span>)
        <span class="keyword">return</span> buf, label_one_hot

    <span class="function"><span class="keyword">def</span> <span class="title">dense_to_one_hot</span><span class="params">(self, labels_dense, num_classes)</span>:</span>
        num_labels = len(labels_dense)
        index_offest = np.arange(num_labels) * num_classes
        labels_one_hot = np.zeros((num_labels, num_classes))
        labels_one_hot.flat[index_offest + labels_dense] = <span class="number">1</span>
        labels_one_hot = labels_one_hot.reshape(num_labels*num_classes)
        <span class="keyword">return</span> labels_one_hot

    <span class="function"><span class="keyword">def</span> <span class="title">next_batch</span><span class="params">(self, batch_size)</span>:</span>
        start = self.index_in_epoch
        self.index_in_epoch += batch_size
        <span class="keyword">if</span> self.index_in_epoch &gt; self.num:
            perm = np.arange(self.num)
            np.random.shuffle(perm)
            self._imgs = self._imgs[perm]
            self._labels = self._labels[perm]
            start = <span class="number">0</span>
            self.index_in_epoch = batch_size
            <span class="keyword">assert</span> batch_size &lt;= self.num
        end = self.index_in_epoch
        <span class="keyword">return</span> self._imgs[start:end], self._labels[start:end]
</code></pre><h2 id="训练">训练</h2><pre><code><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="keyword">from</span> captcha_data <span class="keyword">import</span> OCR_data
<span class="comment"># Parameters</span>
learning_rate = <span class="number">0.001</span>
training_iters = <span class="number">200000</span>
batch_size = <span class="number">64</span>
display_step = <span class="number">20</span>

<span class="comment"># Network Parameters</span>
<span class="comment"># n_input = 7200  # 30*80*3</span>
n_classes = <span class="number">62</span>  <span class="comment"># 10+26+26</span>

data_train = OCR_data(<span class="number">1000</span>, <span class="string">'/data/captcha_data'</span>)
data_test = OCR_data(<span class="number">500</span>, <span class="string">'/data/captcha_data'</span>)

<span class="comment"># tf Graph input</span>
x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">30</span>, <span class="number">80</span>, <span class="number">3</span>])
y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">4</span>*n_classes])

<span class="function"><span class="keyword">def</span> <span class="title">print_activations</span><span class="params">(t)</span>:</span>
    print(t.op.name, t.get_shape().as_list())

<span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.truncated_normal(shape, dtype=tf.float32, stddev=<span class="number">0.1</span>)
    <span class="keyword">return</span> tf.Variable(initial)

<span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.constant(<span class="number">0.0</span>, shape=shape)
    <span class="keyword">return</span> tf.Variable(initial, trainable=<span class="keyword">True</span>)

<span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W, B, name)</span>:</span>
    <span class="keyword">with</span> tf.name_scope(name) <span class="keyword">as</span> scope:
        conv = tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)
        bias = tf.nn.bias_add(conv, B)
        conv = tf.nn.relu(bias, name=scope)
        <span class="keyword">return</span> conv

<span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">avg_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.avg_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">norm</span><span class="params">(x, lsize, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.lrn(x, lsize, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>, name=name)

weights = {
    <span class="string">'wc1'</span>: weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">32</span>]),
    <span class="string">'wc2'</span>: weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">32</span>]),
    <span class="string">'wc3'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>]),
    <span class="string">'wd1'</span>: weight_variable([<span class="number">4</span>*<span class="number">10</span>*<span class="number">32</span>, <span class="number">512</span>]),
    <span class="string">'out1'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out2'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out3'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out4'</span>: weight_variable([<span class="number">512</span>, n_classes])
}
biases = {
    <span class="string">'bc1'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bc2'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bc3'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bd1'</span>: bias_variable([<span class="number">512</span>]),
    <span class="string">'out1'</span>: bias_variable([n_classes]),
    <span class="string">'out2'</span>: bias_variable([n_classes]),
    <span class="string">'out3'</span>: bias_variable([n_classes]),
    <span class="string">'out4'</span>: bias_variable([n_classes]),
}

<span class="function"><span class="keyword">def</span> <span class="title">ocr_net</span><span class="params">(_x, _weights, _biases)</span>:</span>
    _x = tf.reshape(_x, shape=[-<span class="number">1</span>, <span class="number">30</span>, <span class="number">80</span>, <span class="number">3</span>])

    conv1 = conv2d(_x, _weights[<span class="string">'wc1'</span>], _biases[<span class="string">'bc1'</span>], <span class="string">'conv1'</span>)
    print_activations(conv1)
    pool1 = max_pool(conv1, k=<span class="number">2</span>, name=<span class="string">'pool1'</span>)
    print_activations(pool1)

    conv2 = conv2d(pool1, _weights[<span class="string">'wc2'</span>], _biases[<span class="string">'bc2'</span>], <span class="string">'conv2'</span>)
    print_activations(conv2)
    pool2 = avg_pool(conv2, k=<span class="number">2</span>, name=<span class="string">'pool2'</span>)
    print_activations(pool2)

    conv3 = conv2d(pool2, _weights[<span class="string">'wc3'</span>], _biases[<span class="string">'bc3'</span>], <span class="string">'conv3'</span>)
    print_activations(conv3)
    pool3 = avg_pool(conv3, k=<span class="number">2</span>, name=<span class="string">'pool3'</span>)
    print_activations(pool3)

    pool3_flat = tf.reshape(pool3, [-<span class="number">1</span>, _weights[<span class="string">'wd1'</span>].get_shape().as_list()[<span class="number">0</span>]])
    fc1 = tf.nn.relu(tf.matmul(pool3_flat, _weights[<span class="string">'wd1'</span>]) + _biases[<span class="string">'bd1'</span>], name=<span class="string">'fc1'</span>)
    print_activations(fc1)

    fc21 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out1'</span>]) + _biases[<span class="string">'out1'</span>], name=<span class="string">'fc21'</span>)
    print_activations(fc21)

    fc22 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out2'</span>]) + _biases[<span class="string">'out2'</span>], name=<span class="string">'fc22'</span>)
    print_activations(fc22)

    fc23 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out3'</span>]) + _biases[<span class="string">'out3'</span>], name=<span class="string">'fc23'</span>)
    print_activations(fc23)

    fc24 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out4'</span>]) + _biases[<span class="string">'out4'</span>], name=<span class="string">'fc24'</span>)
    print_activations(fc24)

    out = tf.concat(axis=<span class="number">1</span>, values=[fc21, fc22, fc23, fc24], name=<span class="string">'out'</span>)
    print_activations(out)
    <span class="keyword">return</span> out

<span class="function"><span class="keyword">def</span> <span class="title">accuracy_func</span><span class="params">(_pred, _y)</span>:</span>
    y = tf.reshape(_y, shape=[-<span class="number">1</span>, <span class="number">4</span>, <span class="number">62</span>])
    pred = tf.reshape(_pred, shape=[-<span class="number">1</span>, <span class="number">4</span>, <span class="number">62</span>])
    correct_pred = tf.equal(tf.argmax(pred,<span class="number">2</span>), tf.argmax(y,<span class="number">2</span>))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    <span class="keyword">return</span> accuracy

pred = ocr_net(x, weights, biases)

cost = -tf.reduce_mean(y*tf.log(pred))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

<span class="comment">#correct_pred = tf.equal(tf.argmax(pred,2), tf.argmax(y,2))</span>
<span class="comment">#accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span>
accuracy = accuracy_func(pred, y)

init = tf.global_variables_initializer()

config = tf.ConfigProto()
config.gpu_options.allow_growth = <span class="keyword">True</span>

<span class="keyword">with</span> tf.Session(config=config) <span class="keyword">as</span> sess:
    sess.run(init)
    step = <span class="number">1</span><span class="comment"># Keep training until reach max iterations</span>
    <span class="keyword">while</span> step * batch_size &lt; training_iters:
        batch = data_train.next_batch(batch_size)
        <span class="comment"># Fit training using batch data</span>
        sess.run(optimizer, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
        <span class="keyword">if</span> step % display_step == <span class="number">0</span>:
            <span class="comment"># Calculate batch accuracy</span>
            acc = sess.run(accuracy, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
            <span class="comment"># Calculate batch loss</span>
            loss = sess.run(cost, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
            <span class="keyword">print</span> <span class="string">"Iter "</span> + str(step*batch_size) + <span class="string">", Minibatch Loss= "</span> + <span class="string">"{:.6f}"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + <span class="string">"{:.5f}"</span>.format(acc)
        step += <span class="number">1</span>
    <span class="keyword">print</span> <span class="string">"Optimization Finished!"</span>

    test_batch = data_test.next_batch(<span class="number">500</span>)
    <span class="keyword">print</span> <span class="string">"Testing Accuracy:"</span>, sess.run(accuracy, feed_dict={x: test_batch[<span class="number">0</span>], y: test_batch[<span class="number">1</span>]})
</code></pre><h2 id="预测">预测</h2><p>tbd</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/13/tensorflow-captcha/" data-id="cja4p2i8u001erofhbsg3egy6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">life</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/study/">study</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">27</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-c/">c/c++</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe2/">caffe2</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/darknet/">darknet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dataset/">dataset</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face/">face</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mxnet/">mxnet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nnsearch/">nnsearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/source/">source</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tricks/">tricks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visualization/">visualization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/c-c/" style="font-size: 12px;">c/c++</a> <a href="/tags/caffe/" style="font-size: 18px;">caffe</a> <a href="/tags/caffe2/" style="font-size: 12px;">caffe2</a> <a href="/tags/darknet/" style="font-size: 10px;">darknet</a> <a href="/tags/dataset/" style="font-size: 10px;">dataset</a> <a href="/tags/face/" style="font-size: 14px;">face</a> <a href="/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/tags/mxnet/" style="font-size: 10px;">mxnet</a> <a href="/tags/nnsearch/" style="font-size: 10px;">nnsearch</a> <a href="/tags/python/" style="font-size: 12px;">python</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/source/" style="font-size: 10px;">source</a> <a href="/tags/tensorflow/" style="font-size: 20px;">tensorflow</a> <a href="/tags/tricks/" style="font-size: 10px;">tricks</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/生活/" style="font-size: 16px;">生活</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/11/18/face-algorithm/">人脸算法资源汇总</a>
          </li>
        
          <li>
            <a href="/2017/11/16/face-resource/">人脸资讯数据资源汇总</a>
          </li>
        
          <li>
            <a href="/2017/10/07/caffe2-abc/">caffe2学习（二）基础</a>
          </li>
        
          <li>
            <a href="/2017/10/07/caffefe2-install/">caffe2学习（一）安装配置</a>
          </li>
        
          <li>
            <a href="/2017/06/03/caffe-forward/">caffe学习（九）inference代码优化</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget tag">
   <h3 class="title">常用链接</h3>
   <ul class="entry">
    <li><a href="http://blog.csdn.net/yang_xian521" title="my CSDN blog">我的CSDN博客</a></li>
    <li><a href="http://www.pythondoc.com/pythontutorial27/index.html" title="pythondoc">Python教程</a></li>
    <li><a href="http://vbird.dic.ksu.edu.tw/linux_basic/linux_basic.php" title="Linuxdoc">Linux教程</a></li> 
   </ul>
</div>
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Xian Yang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>