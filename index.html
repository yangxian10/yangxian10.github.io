<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>杨现的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="迭代的是人，递归的是神">
<meta property="og:type" content="website">
<meta property="og:title" content="杨现的个人博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="杨现的个人博客">
<meta property="og:description" content="迭代的是人，递归的是神">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="杨现的个人博客">
<meta name="twitter:description" content="迭代的是人，递归的是神">
  
    <link rel="alternative" href="/atom.xml" title="杨现的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">杨现的个人博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">分享计算机视觉、算法、生活累积的点滴</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-adusting-parameter" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/06/adusting-parameter/" class="article-date">
  <time datetime="2015-12-06T02:17:08.000Z" itemprop="datePublished">2015-12-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/06/adusting-parameter/">深度学习调参技巧笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="cnn技巧">cnn技巧</h2><p>南大有个哥们写了一个技巧集合，很不错，推荐给大家<a href="http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html" target="_blank" rel="external">http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/12/06/adusting-parameter/" data-id="cihtworks00002gfh7q1e07r8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tricks/">tricks</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-dataset-cv" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/05/dataset-cv/" class="article-date">
  <time datetime="2015-11-05T14:23:30.000Z" itemprop="datePublished">2015-11-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/05/dataset-cv/">Computer Vision DataSet资源列表</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>俗话说，“算法为王，数据为后”。巧妇难为无米之炊，可见再优秀的算法也得有数据支持。这篇就用来记录我用过的数据集，以备不时之需。</p>
<h1 id="LOGO图">LOGO图</h1><h3 id="Dataset:_FlickrLogos-32">Dataset: FlickrLogos-32</h3><p><a href="http://www.multimedia-computing.de/flickrlogos/" target="_blank" rel="external">http://www.multimedia-computing.de/flickrlogos/</a><br>2011年公布的一个数据集，包含32类知名商标品牌的logo。</p>
<h1 id="动植物图像">动植物图像</h1><h3 id="水果FIDS30:_Fruit_Image_Data_set">水果FIDS30: Fruit Image Data set</h3><p><a href="http://www.vicos.si/Downloads/FIDS30" target="_blank" rel="external">http://www.vicos.si/Downloads/FIDS30</a><br>2014年公布的水果图片集，包含971张图片，覆盖30种不同的水果</p>
<h3 id="鲜花102_Category_Flower_Dataset">鲜花102 Category Flower Dataset</h3><p><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html" target="_blank" rel="external">http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html</a><br>牛津大学vgg组2009年搞的花卉图片，包含102类花卉8189张图片，对应标签<code>imagelabels.mat</code></p>
<h1 id="人脸">人脸</h1><h3 id="CelebA:_Large-scale_CelebFaces_Attributes_(CelebA)_Dataset">CelebA: Large-scale CelebFaces Attributes (CelebA) Dataset</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a><br>香港中文大学组2015年搞的一个最新的目前最大的人脸集，包含10177个人，202599张人脸图片，而且每张图片有5个关键点标注信息以及40个2值属性，属性包括是否带眼睛，是否在笑，是否带帽子，是不是卷发，是否年轻，性别等等，是非常珍贵的人脸数据。</p>
<h3 id="WIDER_FACE:_A_Face_Detection_Benchmark">WIDER FACE: A Face Detection Benchmark</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/</a><br>香港中文大学再放大招，2015年11月又推出人脸检测标注数据库，包含32203张图片，393703张人脸。其中50%的测试数据集并没有公开标注信息。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/11/05/dataset-cv/" data-id="cihtworra000q2gfh0hayzpuo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dataset/">dataset</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-dlib-face-detect" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/04/dlib-face-detect/" class="article-date">
  <time datetime="2015-11-04T13:53:46.000Z" itemprop="datePublished">2015-11-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/04/dlib-face-detect/">基于dlib的人脸检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>dlib的人脸检测模块要比OpenCV的效果好一些，归功于其使用的是HOG特征。</p>
<h2 id="dlib安装">dlib安装</h2><p>在windows下我的环境是vs2013和cmake3.2，cmake版本低了会导致编译失败。下载dlib的zip包，然后解压，然后执行如下，就把c++和python的配置好了。注意其中的CMakeLists.txt文件中的OpenCV宏与新版本的OpenCV不相配，需要改成OpenCV REQUIRED，否则<code>webcam_face_pose_ex</code>这个与摄像头有关的模块不会执行成功。</p>
<pre><code>cd examples
vim CMakeLists.txt
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">####[open CMakeList.txt]
# find_package(OpenCV) --&gt;
find_package(OpenCV REQUIRED)
###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">#[close CMakeList.txt]</span>
mkdir build
cd build
cmake .. -DUSE_AVX_INSTRUCTIONS=ON
cmake --build . --config Release
cd ..<span class="regexp">/../</span>
python setup.py install --<span class="literal">yes</span> USE_AVX_INSTRUCTIONS <span class="comment"># AVX为object detector的加速开关</span>
</code></pre><h2 id="人脸检测demo">人脸检测demo</h2><p>在<code>exmaples/faces</code>文件夹下面新建文件<code>face_detector.py</code>，根据官网例程添加代码：</p>
<pre><code>import sys

import dlib
from skimage import io

detector = dlib.get_frontal_face_detector()
<span class="keyword">win</span> = dlib.image_window()

<span class="keyword">for</span> f <span class="keyword">in</span> sys.argv[1:]:
    <span class="keyword">print</span>(<span class="string">"Processing file: {}"</span>.<span class="keyword">format</span>(f))
    img = io.imread(f)
    # The 1 <span class="keyword">in</span> the second argument indicates that we should upsample the image
    # 1 time.  This will make everything bigger and allow <span class="keyword">us</span> to detect <span class="keyword">more</span>
    # faces.
    dets = detector(img, 1)
    <span class="keyword">print</span>(<span class="string">"Number of faces detected: {}"</span>.<span class="keyword">format</span>(len(dets)))
    <span class="keyword">for</span> i, <span class="keyword">d</span> <span class="keyword">in</span> enumerate(dets):
        <span class="keyword">print</span>(<span class="string">"Detection {}: Left: {} Top: {} Right: {} Bottom: {}"</span>.<span class="keyword">format</span>(
            i, <span class="keyword">d</span>.left(), <span class="keyword">d</span>.top(), <span class="keyword">d</span>.right(), <span class="keyword">d</span>.bottom()))

    <span class="keyword">win</span>.clear_overlay()
    <span class="keyword">win</span>.set_image(img)
    <span class="keyword">win</span>.add_overlay(dets)
    dlib.hit_enter_to_continue()


# Finally, <span class="keyword">if</span> you really want to you can ask the detector to tell you the <span class="keyword">score</span>
# <span class="keyword">for</span> each detection.  The <span class="keyword">score</span> is bigger <span class="keyword">for</span> <span class="keyword">more</span> confident detections.
# Also, the idx tells you <span class="keyword">which</span> of the face sub-detectors matched.  This can be
# used to broadly identify faces <span class="keyword">in</span> different orientations.
<span class="keyword">if</span> (len(sys.argv[1:]) &gt; 0):
    img = io.imread(sys.argv[1])
    dets, scores, idx = detector.<span class="keyword">run</span>(img, 1)
    <span class="keyword">for</span> i, <span class="keyword">d</span> <span class="keyword">in</span> enumerate(dets):
        <span class="keyword">print</span>(<span class="string">"Detection {}, score: {}, face_type:{}"</span>.<span class="keyword">format</span>(
            <span class="keyword">d</span>, scores[i], idx[i]))
</code></pre><p>然后执行如下命令即可看到人脸检测效果：</p>
<pre><code><span class="tag">python</span> <span class="tag">face_detector</span><span class="class">.py</span> *<span class="class">.jpg</span>
</code></pre><h2 id="补充">补充</h2><p>C++环境也是一样的，执行<code>cmake build</code>后在<code>examples/build</code>目录下生成可执行文件<code>face_detection_ex</code>，执行</p>
<pre><code><span class="title">face_detection_ex</span> ../faces/<span class="regexp">*.jpg</span>
</code></pre><p>注意<strong>C++接口要想得到矩形框对应的置信度的话也是可以的，也可以根据置信度设置矩形框筛选的阈值，默认阈值为0</strong>，下面为两种接口的函数声明：</p>
<pre><code><span class="keyword">template</span> &lt;
    <span class="keyword">typename</span> image_type
    &gt;
<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;rectangle&gt; <span class="keyword">operator</span>() (
    <span class="keyword">const</span> image_type&amp; img,
    <span class="keyword">double</span> adjust_threshold = <span class="number">0</span>
);

<span class="keyword">template</span> &lt;
    <span class="keyword">typename</span> image_type
    &gt;
<span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(
    <span class="keyword">const</span> image_type&amp; img,
    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">double</span>, rectangle&gt; &gt;&amp; final_dets,
    <span class="keyword">double</span> adjust_threshold = <span class="number">0</span>
)</span></span>;
</code></pre><h2 id="dlib的人脸关键点检测">dlib的人脸关键点检测</h2><p>下载文件<a href="http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" target="_blank" rel="external">http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2</a>解压后将<code>shape_predictor_68_face_landmarks.dat</code>放到<code>examples/build</code>目录，执行</p>
<pre><code><span class="tag">webcam_face_pose_ex</span> <span class="tag">shape_predictor_68_face_landmarks</span><span class="class">.dat</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/11/04/dlib-face-detect/" data-id="cihtworra000l2gfhkbgdes0y" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/face/">face</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-mxnet-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/10/09/mxnet-install/" class="article-date">
  <time datetime="2015-10-09T13:13:36.000Z" itemprop="datePublished">2015-10-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/10/09/mxnet-install/">mxnet学习（一） mxnet + CentOS 7安装配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>mxnet是最近DMLC那群牛人搞的一个开源的深度学习库，可以看作是cxxnet的升级版本，其中到底的美妙还是慢慢专研感受，话不多说，先跑起来看看。整个学习系列都是参考<a href="http://mxnet.readthedocs.org/en/latest/index.html" target="_blank" rel="external">http://mxnet.readthedocs.org/en/latest/index.html</a>学习完成的。</p>
<h2 id="相关开发环境的配置">相关开发环境的配置</h2><p>系统的检测以及python的安装都是基本的，主要依赖软件是CUDA、intel mkl以及OpenCV的安装配置，具体可以参考之前写的<a href="http://yangxian10.github.io/2015/08/18/caffe-setup2/" target="_blank" rel="external">caffe学习（三）caffe + centOS 7 + CUDA 7配置</a>，已经写的很详细了，这里就不再多言。mxnet不像caffe那样依赖众多的google的工具库，这一点还是必须点赞的（caffe安装坑太多了）</p>
<h2 id="安装mxnet">安装mxnet</h2><pre><code>git clone --recursive http<span class="variable">s:</span>//github.<span class="keyword">com</span>/dmlc/mxnet
<span class="keyword">cd</span> mxnet/<span class="keyword">make</span>
<span class="keyword">cp</span> config.<span class="keyword">mk</span> config.<span class="keyword">mk</span>.bak
<span class="keyword">vim</span> config.<span class="keyword">mk</span>
################# <span class="keyword">open</span>[config.<span class="keyword">mk</span>]
USE_CUDA = <span class="number">1</span>
USE_CUDA_PATH = /usr/local/cuda
USE_BLAS = mkl
USE_INTEL_PATH = /<span class="keyword">opt</span>/intel/
################# <span class="keyword">close</span>[config.<span class="keyword">mk</span>]
<span class="keyword">cd</span> ..
<span class="keyword">make</span> -j4
<span class="keyword">cd</span> <span class="keyword">python</span>
<span class="keyword">python</span> setup.<span class="keyword">py</span> install
<span class="keyword">cd</span> ..
</code></pre><p>测试mxnet是否安装ok</p>
<pre><code><span class="keyword">python</span> example/mnist/mlp.<span class="keyword">py</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/10/09/mxnet-install/" data-id="cihtworqv000g2gfhkjhtiv8e" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mxnet/">mxnet</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-fine-tuning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/15/caffe-fine-tuning/" class="article-date">
  <time datetime="2015-09-15T14:10:22.000Z" itemprop="datePublished">2015-09-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/15/caffe-fine-tuning/">caffe学习（五）fine-tuning已有模型到新数据</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="概述">概述</h2><p>最近试了一个新的数据集，由于每一类别训练数据较少，算法无法收敛。于是尝试使用fine-tuning，利用已有训练模型权重参数适应到新的数据集。</p>
<p>由于我们新的分类器与之前的分类器都采用googLeNet的框架，只是在最后一层由3000个类别增加到60000类，所以需要更改最后一层的参数，把原来的<code>loss3/classifier</code>层改成新名字<code>loss3/classifier/fn</code>，这样由于在原来的模型中找不到这层的名字，这层在训练的时候会用随机变量赋初始值重新训练。</p>
<p>由于原来模型已经收敛，在fine-tuning时候要把<code>base_lr</code>更新学习率降低，同时增加<code>blobs_lr</code>在新的层上，让其他层的参数在新数据来的时候慢点更新，同时让新的层快速学习。同时<code>stepsize</code>参数也适当减少，从而让学习率下降的更快一些。</p>
<h2 id="具体步骤">具体步骤</h2><h3 id="数据准备">数据准备</h3><p>这个没啥好说的，将新的训练数据分为train和valuation集，然后转换成lmdb格式，然后得到其均值文件，准备完毕。</p>
<h3 id="train_val-prototxt">train_val.prototxt</h3><ul>
<li>data-layer里的train和test均值文件和训练数据源要设置正确</li>
<li>loss1/classifier-layer层的name改为<code>loss1/classifier/fn</code>，top参数<code>loss1/classifier/fn</code>，lr_mult参数乘10倍，由原来的1和2改为10和20，num_output改为60000</li>
<li>loss1/loss的softmax层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>loss1/top-1的accuracy层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>loss1/top-5的accuracy层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>上述4个步骤的参数修改同时也要应用到loss2和loss3层中</li>
</ul>
<h3 id="solver-prototxt">solver.prototxt</h3><ul>
<li>将<code>test_initialization</code>这句屏蔽掉</li>
<li>gamma改为0.1</li>
<li>weight_decay改为0.0005</li>
<li>base_lr参数降低10倍，改为0.001，这个改动最为重要</li>
</ul>
<h3 id="deploy-prototxt">deploy.prototxt</h3><ul>
<li>loss3/classifier-layer层的name改为<code>loss1/classifier/fn</code>，top参数<code>loss1/classifier/fn</code>，lr_mult参数乘10倍，由原来的1和2改为10和20，num_output改为60000</li>
<li>prob的softmax层的bottom参数改为<code>loss1/classifier/fn</code></li>
</ul>
<h3 id="调用接口">调用接口</h3><pre><code>../../build/tools/caffe train --solver=solver<span class="class">.prototxt</span> -weights sku3081_googlenet_quick_iter_900000<span class="class">.caffemodel</span> -gpu <span class="number">2</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/09/15/caffe-fine-tuning/" data-id="cihtwors500142gfhz9a9j2g3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-interface" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/23/caffe-interface/" class="article-date">
  <time datetime="2015-08-23T12:28:12.000Z" itemprop="datePublished">2015-08-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/23/caffe-interface/">caffe学习（四）caffe的接口参数说明</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>caffe接口参数</p>
<h2 id="C接口">C接口</h2><h3 id="train相关参数">train相关参数</h3><ul>
<li>-solver参数（必须有），与<code>solver.prototxt</code>文件一起使用</li>
<li>-snapshot参数（可选），通常用来从之前训练一半的模型<code>xxx.solverstate</code>继续训练使用</li>
<li>-weights参数（选填），与训练好的<code>model.caffemodel</code>一起使用，用来在fine-tuning的时候初始化参数</li>
<li>-gpu参数，用来选择使用GPU，根据<code>nvidia-smi</code>的GPU的ID选择，比如选择第三块GPU就使用<code>-gpu 2</code>的参数，如果想使用所有的GPU一起跑一个程序，就使用<code>-gpu all</code></li>
</ul>
<p>举个例子<br><!-- lang:bash--></p>
<pre><code># train LeNet
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt
# train on GPU <span class="number">2</span>
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt -gpu <span class="number">2</span>
# resume training <span class="keyword">from</span> the half-way point snapshot
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt -snapshot examples<span class="regexp">/mnist/</span>lenet_iter_5000.solverstate
# fine-tune CaffeNet model weights <span class="keyword">for</span> style recognition
caffe train -solver examples<span class="regexp">/finetuning_on_flickr_style/</span>solver.prototxt -weights models<span class="regexp">/bvlc_reference_caffenet/</span>bvlc_reference_caffenet.caffemodel
</code></pre><h3 id="test、time相关参数">test、time相关参数</h3><ul>
<li>-iterations迭代次数，time的时候测试的次数，默认为50次</li>
<li>-model测试时候选择加载的模型，对应<code>train_val.prototxt</code>或者<code>deploy.prototxt</code>一起使用</li>
</ul>
<p>举个例子<br><!-- lang:bash--></p>
<pre><code># score the learned LeNet model on the validation <span class="operator"><span class="keyword">set</span> <span class="keyword">as</span> defined <span class="keyword">in</span> the
# <span class="keyword">model</span> architeture lenet_train_test.prototxt
caffe <span class="keyword">test</span> -<span class="keyword">model</span> examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu <span class="number">0</span> -iterations <span class="number">100</span>
# <span class="keyword">time</span> a <span class="keyword">model</span> architecture <span class="keyword">with</span> the given weights <span class="keyword">on</span> the <span class="keyword">first</span> GPU <span class="keyword">for</span> <span class="number">10</span> iterations
caffe <span class="keyword">time</span> -<span class="keyword">model</span> examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu <span class="number">0</span> -iterations <span class="number">10</span></span>
</code></pre><h3 id="device_query相关参数">device_query相关参数</h3><p>这个模块用来查看多GPU时候的一些显卡相关信息。举例<br><!-- lang:bash--></p>
<pre><code><span class="comment"># query the first device</span>
<span class="title">caffe</span> device_query -gpu <span class="number">0</span>
</code></pre><h2 id="python接口">python接口</h2><p>通过<code>import caffe</code>来加载caffe模块，几个比较重要的模块caffe.Net, caffe.SDGSolver, caffe.io, caffe.draw</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/23/caffe-interface/" data-id="cihtworrq00112gfhswsqpxoh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-setup2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/18/caffe-setup2/" class="article-date">
  <time datetime="2015-08-18T15:22:33.000Z" itemprop="datePublished">2015-08-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/18/caffe-setup2/">caffe学习（三）caffe + centOS 7 + CUDA 7配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次全程记录centOS 7 的配置安装过程</p>
<h2 id="开发环境">开发环境</h2><p>虽然它这么好用，安装它可不是一个省心的事，最好的参考资料还是官网安装资料<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">http://caffe.berkeleyvision.org/installation.html</a>，配置之前先查看一下自己的软硬件环境</p>
<h3 id="dns配置">dns配置</h3><p>google之，不多介绍，注意centos 7的dns设置与之前的版本不同</p>
<h3 id="查看显卡">查看显卡</h3><p>我们的显卡是K40（没显卡也能玩caffe）,可以看到是4个k40m显卡。。。。我口水直流(<em>@ο@</em>) </p>
<pre><code>lspci <span class="string">|grep -i nvidia</span>
</code></pre><h3 id="查看linux版本">查看linux版本</h3><p>Linux服务器版本是centOS 7，查看服务器系统版本命令</p>
<pre><code>cat <span class="regexp">/etc/</span>redhat-release
</code></pre><h3 id="安装python">安装python</h3><p>python2.7升级到Anaconda版本<a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda-2.3.0-Linux-x86_64.sh" target="_blank" rel="external">Anaconda-2.3.0-Linux-x86_64.sh</a>下载后直接运行即可，numpy,scipy,scikit-learn等相关软件就都配置好了。记得生效一下环境变量<code>source ~/.bashrc</code>。Anaconda直接把python升级到2.7版本，同时安装好了所有相关依赖包，简直完美啊，解决了python多版本共存的问题，同时一键安装python和相关插件，并且配置好了相关环境变量，同时还是64位版本的python，强烈推荐。</p>
<h3 id="安装cmake">安装cmake</h3><p>再把cmake升级到2.8.12版本，centos 7 的yum只能升级到2.8.11版本</p>
<pre><code><span class="preprocessor"># 先安装依赖</span>
yum install gcc
yum install gcc-g++
<span class="preprocessor"># 下载安装包</span>
tar xvf cmake-<span class="number">2.8</span><span class="number">.12</span><span class="number">.1</span>.tar.gz
cd cmake-<span class="number">2.8</span><span class="number">.12</span><span class="number">.1</span>/
./configure
make
make install
vim /etc/profile
<span class="preprocessor">###########[profile末尾添加]</span>
PATH=/usr/local/cmake/bin:$PATH
<span class="keyword">export</span> PATH
<span class="preprocessor">#############关闭文件</span>
source /etc/profile
<span class="preprocessor">########查看是否安装好</span>
cmake --version
</code></pre><h2 id="安装CUDA和MKL">安装CUDA和MKL</h2><p>这两个商用软件安装相对容易</p>
<h3 id="CUDA_7">CUDA 7</h3><p>下载CUDA 7<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">https://developer.nvidia.com/cuda-downloads</a></p>
<pre><code>yum install kernel-devel
init <span class="number">3</span>         <span class="comment"># 关闭GUI</span>
./cuda_7.<span class="number">0.28_</span>linux.run
init <span class="number">5</span>         <span class="comment"># 开启GUI</span>
vim /etc/profile
<span class="comment">#############[profile]</span>
export <span class="constant">PATH</span>=<span class="variable">$PATH</span><span class="symbol">:/usr/local/cuda-</span><span class="number">7.0</span>/bin
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="variable">$LD_LIBRARY_PATH</span><span class="symbol">:/usr/local/cuda-</span><span class="number">7.0</span>/lib64
<span class="comment">#############[close profile]</span>
source /etc/profile
</code></pre><p>验证CUDA是否安装好</p>
<pre><code>nvcc -V     <span class="comment"># 验证nvidia-CUDA-Toolkit是否安装好</span>
<span class="built_in">cd</span> ~/NVIDIA_CUDA-<span class="number">7.0</span>_Samples
make
<span class="built_in">cd</span> bin/x86_64/linux/release
./deviceQuery
</code></pre><p>从输出的信息就可以判断是否安装好CUDA</p>
<h3 id="intel_MKL">intel MKL</h3><p>下载intel MKL，解压后执行</p>
<pre><code>tar xzvf parallel_studio_xe_2015.tgz
cd parallel_studio_xe_2015
./install.sh
<span class="comment"># 偷偷记录一下自己的序列号SGZG-6NRGK57H</span>
vim /etc/ld.so.conf.d/intel_mkl.conf
<span class="comment">###############[intel_mkl.conf]</span>
/mkl/<span class="class"><span class="keyword">lib</span>/<span class="title">intel64</span></span>
/mkl/mkl/<span class="class"><span class="keyword">lib</span>/<span class="title">intel64</span></span>
<span class="comment">###############[close intel_mkl.conf]</span>
ldconfig
vim /etc/profile
<span class="comment">############[profile]</span>
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="variable">$LD_LIBRARY_PATH</span><span class="symbol">:/opt/intel/mkl/lib</span> 
<span class="comment"># 或者直接把/opt/intel/mkl/lib copy到/usr/local/lib</span>
<span class="comment">############[close profile]</span>
source /etc/profile
</code></pre><h2 id="依赖库安装">依赖库安装</h2><h3 id="Install_protobuf">Install protobuf</h3><p>protobuf是谷歌开发的一种实现内存外存交换的协议接口，在这个统一的通讯协议下不同开发者可以使用自己喜欢的方式进行模型参数的管理。<br>上网下载protobuf2.6.1版本, anaconda的python对应的依赖包要求protobuf是2.6.1版本，弄错了是不行的。解压后，</p>
<pre><code>yum install autoconf automake libtool
tar xzvf protobuf-2.6.1.tar.gz
cd protobuf-2.6.1
<span class="keyword">.</span>/autogen.sh
<span class="keyword">.</span>/configure
make
make<span class="instruction"> check
</span>make install
</code></pre><p>或者直接<code>pip install protobuf</code>，发现版本刚好也是2.6.1</p>
<h3 id="Install_boost">Install boost</h3><p>anaconda没有包含boost，anaconda要求的boost版本为1.57</p>
<pre><code># download <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">tar</span> xvf <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">cd</span> <span class="keyword">boost_1_57_0
</span>./<span class="keyword">bootstrap.sh
</span>./<span class="keyword">b2
</span>./<span class="keyword">b2 </span>install
</code></pre><h3 id="Install_leveldb">Install leveldb</h3><pre><code>pip install leveldb
<span class="preprocessor"># git clone https://github.com/google/leveldb.git</span>
<span class="preprocessor"># cd leveldb/</span>
<span class="preprocessor"># make</span>
<span class="preprocessor"># cp libleveldb* /usr/lib/.</span>
<span class="preprocessor"># cp -r include/leveldb/ /usr/local/include</span>
</code></pre><h3 id="Install_snappy">Install snappy</h3><p><code>yum install snappy</code>发现centos7 已经给安装好了</p>
<h3 id="Install_lmdb">Install lmdb</h3><pre><code>pip <span class="keyword">install</span> lmdb
</code></pre><h3 id="Install_hdf5">Install hdf5</h3><p>下载hdf5</p>
<pre><code>tar xvf hdf5-1.8.5-patch1.tar
cd hdf5-1.8.5-patch.tar
<span class="keyword">.</span>/configure --prefix=/opt/hdf5
make
make<span class="instruction"> check
</span>make install
make<span class="instruction"> check-install
</span>vim /etc/profile
<span class="comment">############[profile]</span>
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/hdf5/lib
<span class="comment"># 或者直接把/opt/hdf5/lib copy到/usr/local/lib</span>
<span class="comment">############[close profile]</span>
source /etc/profile
</code></pre><h3 id="其他依赖库">其他依赖库</h3><p>其他依赖库按照官网说法，先试了一遍</p>
<pre><code>yum <span class="keyword">install</span> snappy-devel opencv-devel boost-devel
yum <span class="keyword">install</span> python-devel
yum <span class="keyword">install</span> protobuf-devel leveldb-devel hdf5-devel <span class="comment"># 这几个包不行</span>
yum <span class="keyword">install</span> gflags-devel glog-devel lmdb-devel <span class="comment"># 这几个包也不行</span>
</code></pre><p>关于gflags, glog, lmdb的解决方案，官网给出了</p>
<pre><code># glog
wget http<span class="variable">s:</span>//google-glog.googlecode.<span class="keyword">com</span>/<span class="keyword">files</span>/glog-<span class="number">0.3</span>.<span class="number">3</span>.tar.gz
tar zxvf glog-<span class="number">0.3</span>.<span class="number">3</span>.tar.gz
<span class="keyword">cd</span> glog-<span class="number">0.3</span>.<span class="number">3</span>
./configure
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
# gflags
wget http<span class="variable">s:</span>//github.<span class="keyword">com</span>/schuhschuh/gflags/archive/master.zip
unzip master.zip
<span class="keyword">cd</span> gflags-master
<span class="built_in">mkdir</span> build &amp;&amp; <span class="keyword">cd</span> build
export CXXFLAGS=<span class="string">"-fPIC"</span> &amp;&amp; cmake .. &amp;&amp; <span class="keyword">make</span> VERBOSE=<span class="number">1</span>
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
# lmdb
git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/LMDB/lmdb
<span class="keyword">cd</span> lmdb/libraries/liblmdb
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
</code></pre><p>但是有几个包是不行的，<code>protobuf-devel</code>, <code>leveldb-devel</code>, <code>hdf5-devel</code>找不到<br>刚才已经下载protobuf, leveldb, hdf5, 暂时先不管这几个devel了</p>
<h2 id="安装OpenCV">安装OpenCV</h2><p>安装了这么多年OpenCV，头一次遇到这么大坑，先尝试了大家推荐的shell一键安装</p>
<pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/jayrambhia/Install-OpenCV
<span class="keyword">cd</span> Install-OpenCV-master/RedHat
./opencv_latest.<span class="keyword">sh</span>
</code></pre><p>要注意downloading ippicv_linux_20140513.tgz的时候耗时很久，要耐心等待。<br>但是在编译caffe的时候还是报错，回来重新安装opencv2.4.11</p>
<pre><code>cd ~/opencv
mkdir <span class="operator"><span class="keyword">release</span>
cd <span class="keyword">release</span>
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=<span class="keyword">RELEASE</span> -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> -<span class="keyword">D</span> CUDA_GENERATION=Kepler ..
make
sudo make <span class="keyword">install</span></span>
</code></pre><p>执行python模块</p>
<pre><code>yum <span class="keyword">install</span> opencv-python
</code></pre><p>测试python下import cv2检测是否安装成功（自带的python已经配置好opencv，anaconda不能import cv2）,解决办法如下:</p>
<pre><code>cp /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv2</span>.<span class="title">so</span> /<span class="title">root</span>/<span class="title">anaconda</span>/<span class="title">lib</span></span>
cp /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv</span>.<span class="title">py</span> /<span class="title">root</span>/<span class="title">anaconda</span>/<span class="title">lib</span>/<span class="title">python2</span>.7/</span>
</code></pre><h2 id="安装caffe">安装caffe</h2><p>进入到caffe的工作目录</p>
<pre><code>git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/</span><span class="constant">BVLC</span>/caffe
cd caffe
cp <span class="constant">Makefile</span>.config.example <span class="constant">Makefile</span>.config
vim <span class="constant">Makefile</span>.config
<span class="comment">###############[Makefile.config]</span>
<span class="constant">BLAS</span> <span class="symbol">:</span>= mkl

<span class="constant">PYTHON_INCLUDE</span> <span class="symbol">:</span>= <span class="regexp">/root/anaconda</span><span class="regexp">/include/python</span>2.<span class="number">7</span> \
    /root/anaconda/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">numpy</span>/<span class="title">core</span>/<span class="title">include</span>/ \</span>
<span class="constant">PYTHON_LIB</span> <span class="symbol">:</span>= <span class="regexp">/root/anaconda</span><span class="regexp">/pkgs/python</span>-<span class="number">2.7</span>.<span class="number">10</span>-<span class="number">0</span>/<span class="class"><span class="keyword">lib</span></span>
<span class="constant">INCLUDE_DIRS</span> <span class="symbol">:</span>= <span class="variable">$(</span><span class="constant">PYTHON_INCLUDE</span>) /usr/local/<span class="keyword">include</span> \
        /opt/hdf5/<span class="keyword">include</span> \
        /opt/intel/mkl/<span class="keyword">include</span> \
<span class="constant">LIBRARY_DIRS</span> <span class="symbol">:</span>= <span class="variable">$(</span><span class="constant">PYTHON_LIB</span>) /usr/local/<span class="class"><span class="keyword">lib</span> /<span class="title">usr</span>/<span class="title">lib</span> \</span>
        /opt/hdf5/<span class="class"><span class="keyword">lib</span> \</span>
        /opt/intel/mkl/<span class="class"><span class="keyword">lib</span> \</span>
<span class="comment">###############[close Makefile.config]</span>
make all -j8
make test -j8
make runtest -j8
</code></pre><p>-j8选项可以提高编译速度，不是必须的，如果在runtest时候一片绿色，没报错，恭喜，说明caffe已经配置好了，可以愉快的使用了。<br>实测solverTest会fail，由于是Test模块，先不理会，估计是caffe的代码版本没统一，不影响使用</p>
<h2 id="测试MNIST">测试MNIST</h2><p>进入到caffe根目录下，执行如下操作</p>
<pre><code>./<span class="keyword">data</span>/mnist/get_mnist.sh               <span class="comment"># 下载minst数据库</span>
./examples/mnist/create_mnist.sh        <span class="comment"># 把数据转成lmdb格式</span>
./examples/mnist/train_lenet.sh         <span class="comment"># 训练mnist</span>
</code></pre><p>从输出结果看到，test集上得到99.2%的正确率，还是很不错的。</p>
<h2 id="其他说明">其他说明</h2><h3 id="pycaffe配置">pycaffe配置</h3><pre><code><span class="built_in">make</span> pycaffe
</code></pre><p>编译成功了，简直酸爽。<br>最后配置一下环境变量,~/.bashrc添加</p>
<pre><code>export PYTHONPATH=/xxxxxxxxx/caffe/python:<span class="variable">$PYTHONPATH</span>
</code></pre><p>python环境下</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> caffe</span>
</code></pre><p>检测caffe-python是否配置好</p>
<h3 id="cuDNN">cuDNN</h3><pre><code>tar xzvf cudnn-<span class="number">7.0</span>-linux-x64-v3.<span class="number">0</span>-rc.tgz
cd cuda
cp <span class="keyword">include</span>/* <span class="regexp">/usr/local</span><span class="regexp">/cuda/include</span>
cp -d lib64/* <span class="regexp">/usr/local</span><span class="regexp">/cuda/lib</span>64        <span class="comment"># -d 保留link file的属性</span>
</code></pre><p>在caffe根目录的<code>Makefile.config</code>中把<code>USE_CUDNN := 1</code>的屏蔽取消，然后<code>make all</code>即可。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/18/caffe-setup2/" data-id="cihtworrq000u2gfhtdbw0hou" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-dataprepare" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/15/caffe-dataprepare/" class="article-date">
  <time datetime="2015-08-15T00:12:16.000Z" itemprop="datePublished">2015-08-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/15/caffe-dataprepare/">caffe学习（二）用自己的数据训练模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="数据准备">数据准备</h2><h3 id="整理、去重">整理、去重</h3><p>将图片文件按照类别放入不同的文件夹下面，同时去掉相同文件夹下的相同图片</p>
<h3 id="打tag">打tag</h3><p>将图片数据按8:1:1的比例分成train，val，test三个子集，并产生“文件路径 标签”的标签数据，如下</p>
<pre><code>../data/train_img/<span class="number">104166241</span>/<span class="number">143088862023832744.</span>jpg <span class="number">0</span>
../data/train_img/<span class="number">104166241</span>/<span class="number">143088862023832435.</span>jpg <span class="number">0</span>
../data/train_img/<span class="number">121391188</span>/<span class="number">142096822616212389.</span>jpg <span class="number">1</span>
</code></pre><h3 id="生成lmdb数据库文件">生成lmdb数据库文件</h3><p>copy一份<code>examples/imagenet/create_imagenet.sh</code>文件并修改其中EXAMPLE、DATA、TOOLS、TRAIN_DATA_ROOT、VAL_DATA_ROOT的对应路径，并且修改<code>RESIZE=true</code>，因为我们的训练图片要归一化到256*256，我的修改如下</p>
<pre><code><span class="setting">EXAMPLE=<span class="value">.</span></span>
<span class="setting">DATA=<span class="value">.</span></span>
<span class="setting">TOOLS=<span class="value">../build/tools</span></span>

<span class="setting">TRAIN_DATA_ROOT=<span class="value">./</span></span>
<span class="setting">VAL_DATA_ROOT=<span class="value">./</span></span>

<span class="setting">RESIZE=<span class="value"><span class="keyword">true</span></span></span>
</code></pre><p>最后把其中的脚本语句中的convert_imageset命令中的标签文件改为自己的文件名(train.txt、val.txt)，然后执行</p>
<pre><code>./create_db.<span class="keyword">sh</span>
</code></pre><h3 id="生成均值文件">生成均值文件</h3><p>copy一份<code>examples/imagenet/make_imagenet_mean.sh</code>文件并修改其中的EXAMPLE、DATA、TOOLS路径位置，以及命令compute_image_mean中的训练数据集的路径和保存的均值文件的路径文件名，然后执行</p>
<pre><code>./make_db_mean.<span class="keyword">sh</span>
</code></pre><h2 id="模型参数调整">模型参数调整</h2><p>选择一个模型，这里选择GoogleNet，将models/bvlc_googlenet中的<code>solver.prototxt</code>和<code>train_val.prototxt</code>复制到新文件夹下。</p>
<h3 id="train_val-prototxt文件">train_val.prototxt文件</h3><ul>
<li>修改输入layer中的TRAIN source和TEST中的source到自己的数据库路径</li>
<li>同时注意一下其中的<code>batch_size</code>参数，决定每次迭代送多少图片去训练</li>
<li>googleNet有3个弱分类器，修改3个最终的loss1/classifier层中的<code>num_output</code>为我们样本的实际类别数，imageNet类别为1000</li>
</ul>
<h3 id="solver-prototxt文件">solver.prototxt文件</h3><ul>
<li>test_iter按照caffe官方的推荐，应该满足<strong>batch_size * test_iter = val子集的数据数</strong>，比如有1万张验证集图片，batch_size是50，那么test_iter应该设置为200左右。</li>
<li>test_interval决定多次训练迭代后测试一次，由于googleNet每次迭代较快，设置为2000比较合适，大概半个小时test一次</li>
<li>display参数决定多少次迭代显示一次，由于googleNet每次迭代较快，这里我设置为100</li>
<li>stepsize决定多次次迭代后减少学习率，应该和max_iter最大迭代次数综合考虑</li>
<li>snapshot决定多次次迭代后保存一次模型</li>
<li>snapshot_prefix是保存的模型文件名</li>
<li>solver_mode是用GPU还是CPU<br>其他参数都是模型参数学习的相关参数，决定了模型的初始值和收敛速度，暂时先不调节</li>
</ul>
<h2 id="训练">训练</h2><p>简单，执行</p>
<pre><code>../build/tools/caffe train --<span class="keyword">solver</span><span class="built_in">=</span><span class="keyword">solver</span>.prototxt
</code></pre><p>看到了terminal不停的喷log了，那酸爽，记得看一下log中的test结果，可以看到top-1/top-5的验证结果。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/15/caffe-dataprepare/" data-id="cihtwors500172gfh7y173los" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-setup" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/01/caffe-setup/" class="article-date">
  <time datetime="2015-08-01T10:56:27.000Z" itemprop="datePublished">2015-08-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/01/caffe-setup/">caffe学习（一）caffe + centOS 6.5 + CUDA 6.5配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>caffe应该是当下最火的深度学习开源框架了，其性能强大，每天可以处理60M的图片（K40显卡），测试一张图片只要1ms，而且其模块都已经定义好，不需要写什么代码就能轻松调用，虽然是c++开发的却能很好的支持python，简直不能更赞。</p>
<h2 id="开发环境">开发环境</h2><p>虽然它这么好用，安装它可不是一个省心的事，最好的参考资料还是官网安装资料<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">http://caffe.berkeleyvision.org/installation.html</a>，配置之前先介绍一下自己的软硬件环境</p>
<ul>
<li><strong>显卡K20c</strong>（没显卡也能玩caffe）</li>
<li><strong>Linux服务器版本centOS6.5</strong>（版本有点低，这有点坑，系统自带的python是2.6版本，cmake是2.6版本，这都给安装带来了不便，由于是服务器没得选，只能硬着头皮上了，而且网上多是基于Ubuntu系统的配置，所以更要把安装过程记录一下）</li>
<li><p><strong>python升级到2.7版本，再把cmake升级到2.8版本</strong>，我都是下载的源代码安装的，要注意的是安装好之后还要将原来版本移除掉并<strong>链接到新版本</strong>，如下</p>
<p>  mv /usr/bin/python /usr/bin/python_old<br>  ln -s  /usr/local/bin/python2.7 /usr/bin/python</p>
</li>
<li><p><strong>安装numpy1.9.2版本</strong>，也是官网源代码</p>
</li>
</ul>
<h2 id="安装CUDA和MKL">安装CUDA和MKL</h2><p>我使用的是CUDA 6.5版本，并且通过edu邮箱申请了一个MKL的student版本。这两个都是商业软件，问题比较少，安照网上的资料很容易就配置好了。</p>
<h2 id="依赖库安装">依赖库安装</h2><p>按照官网说法，先试了一遍</p>
<pre><code><span class="label">sudo</span> yum install protobuf-devel leveldb-devel snappy-devel opencv-devel <span class="keyword">boost-devel </span>hdf5-devel
</code></pre><p>但是有几个包是不行的，protobuf-devel, leveldb-devel, hdf5-devel找不到，由于我服务器版本比较低，boost和boost-devel都只有1.41版本，注意要把boost也升级一下。protobuf是谷歌开发的一种实现内存外存交换的协议接口，再这个统一的通讯协议下不同开发者可以使用自己喜欢的方式进行模型参数的管理。</p>
<p>首先先把protobuf, leveldb, hdf5, boost高级版本的tar包下载下来解压并用make和make install安装起来，然后下载其分别对应的devel的rpm安装，并通过rpm命令安装：</p>
<pre><code>rpm -<span class="tag">i</span> xxx.rpm
</code></pre><h2 id="安装OpenCV">安装OpenCV</h2><p>安装了这么多年OpenCV，头一次遇到这么大坑，先尝试了大家推荐的shell一键安装</p>
<pre><code>git https://github.com/ouxinyu/<span class="operator"><span class="keyword">Install</span>-OpenCV-<span class="keyword">master</span>
cd <span class="keyword">Install</span>-OpenCV-<span class="keyword">master</span>/RedHat
./opencv_latest.sh</span>
</code></pre><p>看上去一切很美，但是执行downloading ippicv_linux_20140513.tgz这个文件的时候就怎么都过不去了，没能解决，于是还是乖乖的安装官网的教程去下载了一个OpenCV 2.4.9的tar解压安装，安装过程也是安装OpenCV官方的教程来的，但是由于要使用其中的GPU模块，原本预想很顺利的安装过程出了error，查了资料发现是OpenCV的bug<a href="http://code.opencv.org/issues/3814" target="_blank" rel="external">http://code.opencv.org/issues/3814</a>，拷贝文件<a href="http://code.opencv.org/projects/opencv/repository/revisions/feb74b125d7923c0bc11054b66863e1e9f753141/raw/modules/gpu/src/nvidia/core/NCVPixelOperations.hpp" target="_blank" rel="external">NCVPixelOperations.hpp</a>替换掉源文件，重新build make，搞定</p>
<pre><code>cd ~/opencv
mkdir <span class="operator"><span class="keyword">release</span>
cd <span class="keyword">release</span>
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=<span class="keyword">RELEASE</span> -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> ..

cd ..
make
sudo make <span class="keyword">install</span></span>
</code></pre><h2 id="安装caffe">安装caffe</h2><p>复制一个配置文件先</p>
<pre><code><span class="tag">cp</span> <span class="tag">Makefile</span><span class="class">.config</span><span class="class">.example</span> <span class="tag">Makefile</span><span class="class">.config</span>
</code></pre><p>把里面的CPU_ONLY，BLAS，PYTHON_DIR目录都按照情况配置好，然后执行</p>
<pre><code><span class="keyword">make</span> <span class="keyword">all</span> -j8
<span class="keyword">make</span> test -j8
<span class="keyword">make</span> runtest -j8
</code></pre><p>-j8选项可以提高编译速度，不是必须的，如果在runtest时候一片绿色，没报错，恭喜，说明caffe已经配置好了，可以愉快的使用了。</p>
<h2 id="测试MNIST">测试MNIST</h2><p>进入到caffe根目录下，执行如下操作</p>
<pre><code>./<span class="keyword">data</span>/mnist/get_mnist.sh               <span class="comment"># 下载minst数据库</span>
./examples/mnist/create_mnist.sh        <span class="comment"># 把数据转成lmdb格式</span>
./examples/mnist/train_lenet.sh         <span class="comment"># 训练mnist</span>
</code></pre><p>从输出结果看到，test集上得到99.2%的正确率，还是很不错的。</p>
<h2 id="其他说明">其他说明</h2><h3 id="pycaffe配置">pycaffe配置</h3><ul>
<li><p>由于我这里python没配置好，所以make pycaffe没能通过，有待解决。<br>解决方案，下载<a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda-2.3.0-Linux-x86_64.sh" target="_blank" rel="external">Anaconda-2.3.0-Linux-x86_64.sh</a>，下载后运行，<br>直接把python升级到2.7版本，同时安装好了所有相关依赖包，简直完美啊，，解决了python2.6和2.7共存的问题，同时一键安装python和相关插件，并且配置好了相关环境变量，同时还是64位版本的python，强烈推荐。<br>修改Makefile.config中和python相关内容</p>
<p>  PYTHON_INCLUDE := /root/anaconda/include/python2.7 /root/anaconda/lib/python2.7/site-packages/numpy/core/include/<br>  PYTHON_LIB := /root/anaconda/pkgs/python-2.7.10-0/lib<br>  INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include<br>  LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib</p>
</li>
</ul>
<p>执行</p>
<pre><code><span class="built_in">make</span> pycaffe
</code></pre><p>编译成功了，简直酸爽。<br>最后配置一下环境变量</p>
<pre><code>export PYTHONPATH=/root/caffe_test/caffe/python:<span class="variable">$PYTHONPATH</span>
</code></pre><p>python环境下</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> caffe</span>
</code></pre><p>报错信息</p>
<pre><code>from ._caffe import <span class="constant">Net</span>, <span class="constant">SGDSolver</span>
<span class="constant">ImportError</span><span class="symbol">:</span> /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">libboost_python</span>.<span class="title">so</span>.1.58.0: <span class="title">undefined</span> <span class="title">symbol</span>: <span class="title">PyUnicodeUCS2_FromEncodedObject</span></span>
</code></pre><p>anaconda只差boost没有包含，而是我安装的boost版本1.58跟anaconda要求的1.57版本，重新安装一遍boost 1.57</p>
<pre><code># download <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">tar</span> xvf <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">cd</span> <span class="keyword">boost_1_57_0
</span>./<span class="keyword">bootstrap.sh
</span>./<span class="keyword">b2
</span>./<span class="keyword">b2 </span>install /usr
</code></pre><p>记得安装完boost一定要<code>yum install boost-devel</code>一下（血和泪的教训）<br>出现新的错误，说no module name google.portobuf，重新安装protobuf和protobuf-devel并没有解决这个问题，上网上重新下载protobuf2.6.1版本，弄错了是不行的。解压后，</p>
<pre><code><span class="keyword">.</span>/autogen.sh
<span class="keyword">.</span>/configure
make
make<span class="instruction"> check
</span>make install
</code></pre><p>出错loading shared libraries: libprotobuf.so.8: cannot open shared object file: No such file or directory，此时应该是连接出错<br>locate libprotobuf.so.9 看下libprotobuf.so.9的确存在/opt/protobuf/lib下面</p>
<pre><code><span class="keyword">cd</span> /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/
<span class="keyword">vi</span> protobuf.<span class="keyword">conf</span>   # protobuf.<span class="keyword">conf</span>中只要加入一行： /<span class="keyword">opt</span>/protobuf/lib
ldconfig
</code></pre><p>安装protobuf的python模块</p>
<pre><code><span class="keyword">cd</span> <span class="keyword">python</span>
<span class="keyword">python</span> setup.<span class="keyword">py</span> build
<span class="keyword">python</span> setup.<span class="keyword">py</span> test
<span class="keyword">python</span> setup.<span class="keyword">py</span> install
</code></pre><p>python setup.py build的过程中可能报几个错，然而没关系，我们并不需要所有的protobuf的模块，配置pycaffe最重要的就是注意anaconda和依赖包版本的对应，boost要求1.57版本，protobuf是2.6.1版本，弄错了是不行的。</p>
<ul>
<li>cuDNN的加速模块也没有安装测试一下，有空再配置一下。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/01/caffe-setup/" data-id="cihtworrq000y2gfhh1jop48i" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-单反拍摄入门" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/04/12/单反拍摄入门/" class="article-date">
  <time datetime="2015-04-12T13:06:30.000Z" itemprop="datePublished">2015-04-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/04/12/单反拍摄入门/">单反拍摄入门</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>单反相机拍摄入门技巧，各种环境拍摄参数设置</strong><br>大部分人之所以踏上摄影之路，几乎部是被单反相机及其附件的魅力所吸引。它完美神奇，使我们如获至宝，珍爱之极。我们通过它观察、取景、测光、测距、调焦，然后一按快门，“咔嗒”一声——瞬间的艺术就诞生了！ 甚至，不管单反相机多么昂贵，我们总是心甘情愿地增加投入。因此，经常留意各种广告，研究哪家商店出售什么产品，价格如何。我们凝视着照相器材商店的橱窗，宛如一个孩子驻足于玩具商店门前。我们还常常和摄影同伴们比镜头等等，体验着“我的比你的大”那种自我满足的心情。摄影家们常有这样一句话 “开始我们不过迷上了单反相机这个尤物， 而结果却爱上了摄影这门艺术。”</p>
<h1 id="方法/步骤">方法/步骤</h1><h2 id="1-光圈优先大多用在拍人像以及风景时。">1.光圈优先大多用在拍人像以及风景时。</h2><p><strong>光圈优先就是手动定义光圈的大小，相机会根据这个光圈值确定快门速度。由于光圈的大小直接影响着景深，因此在平常的拍摄中此模式使用最为广泛。在拍摄人像时，我一般采用大光圈长焦距而达到虚化背景获取较浅景深的作用，这样可以突出主体。同时较大的光圈，也能得到较快的快门值，从而提高手持拍摄的稳定。在拍摄风景这一类的照片时，我往往采用较小的光圈，这样景深的范围比较广，可以使远处和近处的景物都清晰，同样这一点在拍摄夜景时也适用。</strong></p>
<h2 id="2-快门优先多用于拍摄运动的物体上">2.快门优先多用于拍摄运动的物体上</h2><p>例如体育运动、行使中的车辆、瀑布、飞行中的物体、烟花、水滴等等。与光圈优先相反，快门优先是在手动定义快门的情况下通过相机测光而获取光圈值。快门优先多用于拍摄运动的物体上，特别是在体育运动拍摄中最常用。很多朋友在拍摄运动物体时发现，往往拍摄出来的主体是模糊的，这多半就是因为快门的速度不够快。在这种情况下你可以使用快门优先模式，大概确定一个快门值，然后进行拍摄。并且物体的运行一般都是有规律的，那么快门的数值也可以大概估计，例如拍摄行人，快门速度只需要1/125秒就差不多了，而拍摄下落的水滴则需要1/1000秒。</p>
<h2 id="3-人像拍摄。">3.人像拍摄。</h2><p>首先，<strong>要用到长焦，3――4倍的长焦非常适合拍人像</strong>，广角端会使得人像有些变形，不好看，超过4倍甚至更长焦会使得人脸过于扁平，不够生动。<br>其次，<strong>光圈优先，选择大光圈，大光圈可以使得快门变快，减少晃动，并且使得背景尽可能的虚化。最好选择点测光，对人脸点测光，并使用曝光锁定</strong>。因为其他测光方式容易受到衣服颜色的影响，使得人脸曝光不正常。<br>最后，构图。<strong>人像最好占到1/3-1/2，并且脸部在上方1/3处（从下看是处）</strong>。这样拍出的人像片就会生动，有视觉的冲击力，让人看着好看。</p>
<h2 id="4-怎样拍好微距。">4.怎样拍好微距。</h2><p>拍好微距，需要用光、构图讲究技巧。我们要掌握的是怎么把微距拍清楚，不要拍糊呢？注意以下两点就行了。首先，用三角架。手持不稳，放大之后总看到片糊，所以第一条，用三角架。其次，用自拍机。我们发现，即使用架，在按动快门时仍然带入了晃动，最好的办法，启动自拍机</p>
<h2 id="5-曝光补偿的使用。">5.曝光补偿的使用。</h2><p>按动+ -键，就会出现曝光补偿调节条，左右键调整正负补偿及大小，一次1/3级。调整好后再按一次+ -键确定。那么，曝光补偿怎么应用呢？总起来讲，是白加黑减，白的环境下，测光有偏低的状况，需要增加，反之亦然。</p>
<ol>
<li>拍摄环境比较昏暗，需要增加亮度，而闪光灯无法起作用时，可对曝光进行补偿，适当增加曝光量。</li>
<li><strong>被拍摄的白色物体在照片里看起来是灰色或不够白的时候，要增加曝光量，简单的说就是“越白越加”</strong>，这似乎与曝光的基本原则和习惯是背道而驰的，其实不然，这是因为相机的测光往往以中心的主体为偏重，白色的主体会让相机误以为很环境很明亮，因而曝光不足，这也是多数初学者易犯的通病.</li>
<li>当你在一个很亮的背景前拍摄的时候，比如向阳的窗户前，逆光的景物等要增加曝光量或使用闪光灯。</li>
<li>当你在海滩、雪地、阳光充足或一个白色背景前，拍摄人物的时候，要增加曝光量并使用闪光灯，否则主体反而偏暗。</li>
<li>拍摄雪景的时候，背景光线被雪反射得特别强，相机的测光偏差特别大，此时要增加曝光量，否则白雪将变成灰色。</li>
<li>拍摄黑色的物体，在照片里看和色变色发灰的时候，应该减小曝光量，使黑色更纯。</li>
<li>当你在一个黑色背景前拍摄的时候，也需要降低一点曝光量以免主体曝光过度。</li>
<li><strong>夜景拍摄，应该关闭闪光灯，提高曝光值，靠延长相机的曝光时间来取得灯火辉煌的效果，很多人感觉夜景拍摄能力很差，其实没有正确使用相机的曝光方法是重要原因之一。</strong></li>
<li>阴天和大雾的时候，环境仍然是明亮的，但是实际物体的照度明显不足，如果不加曝光补偿则可能造成照片昏暗，适当的曝光补偿，加0.3到0.7可以使得景物亮度更加自然。<br>善于应用、合理使用曝光补偿，可以大大改善你的摄影作品的成功率，拍出画面清晰，亮度合适，观看舒适的照片，提高拍摄质量。</li>
</ol>
<h2 id="6-巧用屏幕上的网格线构图。">6.巧用屏幕上的网格线构图。</h2><p>我们知道，的黄金分割比例能给人美感。所以安排片中的兴趣点在4个焦点上，或在分割线上，就会给人视觉的美感。网格线就方便的给我们提供了这样的参照。除了以上注意黄金点构图外，还应注意以下几点：</p>
<ol>
<li>避免贯穿两边的直线，尤其要避免将照片分割成两部分的贯穿横线或竖线。</li>
<li>地平线的处理。在风光作品里，地平线是经常出现的，为避免上下分割的效果，应设法打破地平线的平直，如利用云彩、远山、日出、日落或其它建筑物。此外，地平线的位置也应安排在趣味中心的分割线上，并且CX1应保持水平（有特殊创意另当别论）。</li>
<li>拍摄运动的物体要给运动的前方留有一定的空间。当被摄体是运动的，观赏者的目光会习惯性地沿被摄体运动方向移动，如果运动的前方没有空间会给人压迫感。此外，通常被摄体注视的方向也应留有相对较大的空间。</li>
</ol>
<h2 id="7-太阳落山前或者阴天的拍摄。">7.太阳落山前或者阴天的拍摄。</h2><p>白天或者夜晚，都可以得到我们想要的效果，自动白平衡很准确。但只有太阳落山前后那段时间，或者阴云天气下，拍出的片子雾朦朦，很不理想。在这种情况下，需要调节白平衡，先扳到P档开始的手动档，按功能键，选到阴天，按功能键确定。如果还仍然不理想，请设置手动白平衡。</p>
<h1 id="几种现场拍摄技巧">几种现场拍摄技巧</h1><h2 id="1-怎么在室内给孩子拍片。">1.怎么在室内给孩子拍片。</h2><p>首先用光圈优先，将光圈调整到最大；其次布置光线，虽然不能用闪光灯，我们可以将孩子带到窗户旁比较明亮的地方，如果晚上我们可以用台灯等光；孩子常会乱动，可以考虑手动调焦，先将点测光锁定，将焦距调整好后，然后半按住快门移动步伐，等待孩子出现有趣的可爱的表情时快速按下快门。</p>
<h2 id="2-怎么做才能将背景虚化">2.怎么做才能将背景虚化</h2><p><strong>首先光圈优先，光圈调整到最大（即F后面的数值最小，比如F2.8）；焦距调大，越大虚化越好；安排前景的人或物离的背景远一些，越远虚化越好</strong>；如果以上仍然不理想，可以通过后期处理的方法做的直到满意。</p>
<h2 id="3-怎样给婴儿拍片。">3.怎样给婴儿拍片。</h2><p>拍摄婴儿要记住，用婴儿感兴趣的东西吸引他，可以拍摄到更自然的表情。为保护婴儿的眼睛最好不使用闪光灯，可以将调整感光度到200，并在顺光的情况下拍摄。最好把孩子抱到光线好的地方，如果天气不好，可以用台灯布光。如果一定要使用闪光灯，最好在闪光灯上蒙上一块薄纸或纱布。拍摄的距离，50厘米到150厘米为宜，最好用长焦。可以从不同角度观察孩子的脸，力求找到一个更好看的角度。</p>
<h2 id="4-从旅游车中的拍摄。">4.从旅游车中的拍摄。</h2><p>我们旅行的时候，在车内的时间也是旅行的一个重要组成部分，所以也可以成为很好的拍摄时间。同样的风景，从移动的车内拍与在车外拍，往往给人不同的感觉。在行驶的车内向外拍摄的时候，要注意以下几点：</p>
<ol>
<li>在拍摄的时候，不要把手腕架在窗框或者座位的靠背上，因为车辆在行驶中总会有些震颤，这样很容易造成和手颤一样的虚像。</li>
<li>不要在阳光射入的窗口边拍摄，因为这样很容易在窗玻璃上有白衣服等等的反光。你可以要求临时换一下座位，拍完之后再回来。</li>
<li>对于观光大巴来说，进行拍摄最合适的座位是最前面的座位。一是因为视野广，二是因为前面的玻璃经常清洗，所以最干净。而且前面的座位震颤也相对比后面的座位轻微一些。</li>
</ol>
<h2 id="5-为了表现毛的质感，最好使用自然光。">5.为了表现毛的质感，最好使用自然光。</h2><p>直射光和顺光都不容易表现质感，最好是逆光拍摄，质感是最强烈的。当阴影太强的时候，可能会需要补光。在晚上补光的时候，要注意使用红眼消除功能。动物的警戒性很高，所以不能追着撵着拍。在拍摄的时候，动作要慢、要柔和，不能操之过急。如果有时间，要尽量获得动物的信任，以求尽量靠近拍摄。</p>
<h2 id="6-怎样拍好瀑布。">6.怎样拍好瀑布。</h2><ol>
<li>快门速度，一般需要一个比较慢的速度，在1/60――1/10秒之间。具体还需要根据水量的大小，水量大快门可以快些，水量小快门可以慢些。</li>
<li>尽量用广角拍。广角才会拍出气势。</li>
<li>一般由下往上拍，尽量用低角度仰拍。</li>
<li>正确曝光。用点测光来测试拍摄场景中最暗并且我能辨得清细节的地方，然后通过提高快门速度来调整两级光值。举个例子，如果测光显示石头的曝光组合是1/60s以及光圈f/5.6，你可以调到全手动档，其调整为1/15秒与光圈f/5.6。然后重新拍摄，拍出的照片会较黑，但细节部位仍是清楚的。</li>
</ol>
<h2 id="7-花卉拍摄。">7.花卉拍摄。</h2><p>对于拍花要讲究点技巧才能拍得好看，我们以前说过要在拍之前喷点水可以增加花的层次感以及娇翠欲滴的感觉，此外还应注意以下几点：</p>
<ol>
<li>测光方式最好用点测光，测花最亮的部分，使得花整体细节都能表现清楚。</li>
<li>拍摄模式最好光圈优先，可以适当控制背景的虚化或者控制景深。</li>
<li>拍摄角度，不要只拍正面，可同时拍不同角度的7、8张片。从而可以选择最漂亮的角度。</li>
<li>背景。选择背景是深色（如很浓密的树叶、深色墙等）的花作为拍摄的对象。<br>用一大块黑色的布摆在花的背后，离花要远一点，近了要看见布纹。黑布摆的方法，可以直接平放在地上，也可以挂在花的背后，也可以把黑布蒙在一块板上立在花的背后。</li>
</ol>
<h1 id="注意事项">注意事项</h1><h2 id="突出主体。">突出主体。</h2><p>在拍摄之前，心里要像绘画前那样首先“立意”，考虑照片画面中，主要表现什么，被摄主体安排在什么地方。然后通过光线、色彩、线条、形态等造型手段，来达到突出主体的目的。2<br>视觉平衡。一幅构图达到视觉平衡的照片、能给人以稳定、协调的感觉。平衡有对称平衡及非对称平衡两种、非对称平衡的构图，往往比对称平衡的构图更富有动感。景物的大小、形状、重量和方向、以及M8色彩等都对视觉平衡有重要影响。</p>
<h2 id="虚实相映。">虚实相映。</h2><p>虚实是指被摄主WX1体与空间前、后景的清晰、模糊的程度。运用的手法不外乎藏虚露实、虚实相间、虚宾实主、以虚托实。其目的是为了突出主体，渲染气氛，增强空间纵深感。实，主要是表现被摄对象的主体；虚、主要是表现被摄对象的陪体，以衬托主体，它是构成画面意境的重要环节。<br>讲究节奏与旋律摄影构图，被摄对象以相同或近似的形式交替出现，有条理地重复，便形成节奏；节奏如果表现出线条、舒畅、和谐、起伏等动态变化，就成为旋律，从而使画面优美、抒情而流畅。节奏与旋律是深化主题的重要环节，它们包含在线条、色彩、光线的反差与色调中。</p>
<h2 id="线条运用。">线条运用。</h2><p>线条是构图的骨架。任何形象化的作品，都离不开线条。通常起线条作用的有树、草、电线杆、河流、波浪等，不同的线条能给人以不同的视觉形象，如水平线能表示稳定和宁静，垂直线能表示庄重和力量，斜行线则具有生气，活力和动感，曲线和波浪线显得柔弱、悠闲，富有吸引力；浓线重，淡线轻，粗线强，细线弱，实线静，虚线动，构图时可灵活地加以运用。</p>
<h1 id="各种环境拍摄参数设置">各种环境拍摄参数设置</h1><h2 id="1、拍静止的小东西的特写">1、拍静止的小东西的特写</h2><p>用Av档，光圈最好在f5.6或以下，焦距最好50以上，尽量在1m以内拍摄，使背景虚化！光线好的话，iso100，光线不好的话，iso最好400以内。</p>
<h2 id="2、拍人">2、拍人</h2><p><strong>基本都是使用较大的光圈（f5.6以内）、50mm以上的焦距，拍拍摄距离视全身、半身、大头照而定，使背景虚化，使用Av档！光线好的话，iso100，光线不好，iso400以内。</strong></p>
<h2 id="3、拍景">3、拍景</h2><p>Av档，使用适当的光圈，f8以上吧，焦距随便，但是一般广角端都有畸变，酌情使用。</p>
<h2 id="4、拍夜景">4、拍夜景</h2><p>上三角架，Av档，自定义白平衡或白炽灯，f8以上的光圈，小光圈可以使灯光出现星光的效果，使用反光板预升功能，减少按快门后，反光板抬起引起的机震；并用背带上的那个方盖子，盖住取景器，以避免杂光从后面进入影响画质；iso200以内，尽量使曝光时间加长，这样可以使一些无意走过的人从画面消失，不留下痕迹，净化场景！</p>
<h2 id="5、拍烟花">5、拍烟花</h2><p>使用快门线，B快门，可以拍出多烟花重叠的效果！</p>
<h2 id="6、拍运行的东西">6、拍运行的东西</h2><p>光线好的情况：Av档，光圈大小酌情处理；使用f8以上的光圈得到大景深效果，使用小光圈得到浅景深的效果；想拍很有动感的效果，可以使用Tv档，快门1/30左右，对焦按快门的同时，镜头以合适的速度追着对象移动，会出现很动感的效果！<br>       光线不好的话，只能酌情处理了，再加上使用追拍！</p>
<h2 id="7、拍流水或喷泉">7、拍流水或喷泉</h2><p>使用Tv档。1/50左右的快门速度，可以拍出缎子的效果，如果使用太快的快门，喷泉拍出来就都是不连续的水滴了！</p>
<h2 id="8、夜间人像留影">8、夜间人像留影</h2><p>上三角架，调节白平衡，自动或自定义白平衡；iso100-400；Av档，光圈f8左右，使用慢速同步闪光，后帘闪光模式；此时，闪光灯会闪两次，按下快门闪一次，曝光结束前会再闪一次，所以在闪两次前，人不要离开。这样拍出来可以使人物清晰，背景霓虹也很漂亮，不至于背景曝光不足而过暗。</p>
<h1 id="Av光圈优先技巧">Av光圈优先技巧</h1><ol>
<li>不管拍啥，除非要保持安全快门，不然别开最大光圈拍。</li>
<li>拍风景请尽量使用F8~F11的光圈。</li>
<li>拍人物及静物特写可使用最大光圈1~2级之光圈。</li>
<li>安全快门请尽量控制在焦距倒数以上，广角端快门也要在1/30秒以上比较保险，若快门不足请提高光圈或iso。</li>
</ol>
<h1 id="测光方式">测光方式</h1><ol>
<li>测光不要对着天空，不要对着最暗的地方，要去抓中间值。</li>
<li>依照你拍的题材，善用测光模式（权衡测光，点测光，中央重点测光）。</li>
<li>若遇到测光抓不准的时候，请用AE lock 对身边灰色的东西曝光锁定后再来拍摄。</li>
<li>尽量别对白色或黑色物体测光，不然就请记得黑要减EV，白要加EV。</li>
</ol>
<h1 id="EV即曝光补偿">EV即曝光补偿</h1><p>曝光补偿也是一种曝光控制方式，一般常见在正负2-3EV左右，如果环境光源偏暗，即可增加曝光值以突显画面的清晰度。<br>小型数码相机大多通过菜单来调节曝光补偿：数码相机在拍摄的过程中，如果按下半截快门，液晶屏上就会显示和最终效果图差不多的图片，对焦，曝光一切启动。这个时候的曝光，正是最终图片的曝光度。图片如果明显偏亮或偏暗，说明相机的自动测光准确度有较大偏差，要强制进行曝光补偿，不过有的时候，拍摄时显示的亮度与实际拍摄结果有一定的出入。数码相机可以在拍摄后立即浏览画面，此时，可以更加准确的看到拍摄出来的画面的明暗程度，不会再有出入。如果拍摄结果明显偏亮或偏暗，则要重新拍摄，强制进行曝光补偿。拍摄环境比较昏暗，需要增加亮度，而闪光灯无法起作用时，可对曝光进行补偿，适当增加曝光量。进行曝光补偿的时候，如果照片过暗，要增加EV值，EV值每增加1.0，相当于摄入的光线量增加一倍，如果照片过亮，要减少EV值，EV值每减少1.0，相当于摄入的光线量减小一倍。按照不同的相机的补偿间隔可以以1/2或1/3的单位来调节。<br>被拍摄的白色物体在照片里看起来是灰色或不够白的时候，要增加曝光量，简单地说就是“越白越加”，这似乎与曝光的基本原则和习惯是背道而驰的，其实不然，这是因为相机的测光往往以中心的主体为偏重，白色的主体会让相机误以为很环境很明亮，因而曝光不足，这也是多数初学者易犯的通病。<br>由于相机的快门时间或光圈大小是有限的，因此并非总是能达到2EV的调整范围，因此曝光补偿也不是万能的，在过于暗的环境下仍然可能曝光不足，此时要考虑配合闪光灯或增加相机的iso感光灵敏度来提高画面亮度。</p>
<p>注：佳能说明书上的光圈是指F数值，光圈越大，景深越大。<br>一般人们所说的光圈是指光圈孔径，和F数值成反比，光圈（孔径）越大，景深越小。<br>Av–光圈优先自动曝光。<br>Tv–快门优先自动曝光<br>AE-自动曝光<br>AF-自动对焦<br>AF-S–和SAF应该一样，是单次自动对焦。相对的是连续自动对焦。<br>MAF-监控AF，这个模式可以缩短对焦所需的时间。相机在快门按钮按下一半之前就会调整焦点，让您以调整好的焦点进行构图。将快门按钮按下一半，而且af 锁定完成时，焦点会被锁定。<br>EV-曝光值，通常在进行曝光补偿时会用到这个术语。<br>ISO-感光度，感光度每差一档，相当于光圈或者快门相应的一档曝光值。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/04/12/单反拍摄入门/" data-id="cihtworqf00052gfhk7038s4m" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/生活/">生活</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">life</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dataset/">dataset</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face/">face</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mxnet/">mxnet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tricks/">tricks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/caffe/" style="font-size: 20px;">caffe</a> <a href="/tags/dataset/" style="font-size: 10px;">dataset</a> <a href="/tags/face/" style="font-size: 10px;">face</a> <a href="/tags/mxnet/" style="font-size: 10px;">mxnet</a> <a href="/tags/tricks/" style="font-size: 10px;">tricks</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/12/06/adusting-parameter/">深度学习调参技巧笔记</a>
          </li>
        
          <li>
            <a href="/2015/11/05/dataset-cv/">Computer Vision DataSet资源列表</a>
          </li>
        
          <li>
            <a href="/2015/11/04/dlib-face-detect/">基于dlib的人脸检测</a>
          </li>
        
          <li>
            <a href="/2015/10/09/mxnet-install/">mxnet学习（一） mxnet + CentOS 7安装配置</a>
          </li>
        
          <li>
            <a href="/2015/09/15/caffe-fine-tuning/">caffe学习（五）fine-tuning已有模型到新数据</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget tag">
   <h3 class="title">常用链接</h3>
   <ul class="entry">
    <li><a href="http://blog.csdn.net/yang_xian521" title="my CSDN blog">我的CSDN博客</a></li>
    <li><a href="http://www.pythondoc.com/pythontutorial27/index.html" title="pythondoc">Python教程</a></li>
    <li><a href="http://vbird.dic.ksu.edu.tw/linux_basic/linux_basic.php" title="Linuxdoc">Linux教程</a></li> 
   </ul>
</div>
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Xian Yang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>