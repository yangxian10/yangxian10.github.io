<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>杨现的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="迭代的是人，递归的是神">
<meta property="og:type" content="website">
<meta property="og:title" content="杨现的个人博客">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="杨现的个人博客">
<meta property="og:description" content="迭代的是人，递归的是神">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="杨现的个人博客">
<meta name="twitter:description" content="迭代的是人，递归的是神">
  
    <link rel="alternative" href="/atom.xml" title="杨现的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">杨现的个人博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">分享计算机视觉、算法、生活累积的点滴</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-panns-nnsearch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/11/panns-nnsearch/" class="article-date">
  <time datetime="2016-04-11T13:01:36.000Z" itemprop="datePublished">2016-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/11/panns-nnsearch/">高维海量数据快速检索库</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="falconn">falconn</h1><p>这个库使用的是局部敏感哈希构建索引。效率较高。</p>
<h3 id="python实现">python实现</h3><p>官方的api文档<a href="https://falconn-lib.org/pdoc/falconn/" target="_blank" rel="external">https://falconn-lib.org/pdoc/falconn/</a>其实非常详细，这里把其中关键的地方再提炼一下。<br>安装非常简单</p>
<pre><code>pip <span class="keyword">install</span> falconn
</code></pre><p>数据准备，需要将所有的索引特征存储到一个numpy的二维array中，其中每行代表一个数据，行数表示数据点数，列表示特征维度。注意，最好把数据转换为float32数据类型，提高算法性能，并将数据归一化减去均值，提高算法性能。具体操作如下</p>
<pre><code>dataset = dataset.<span class="function"><span class="title">astype</span><span class="params">(numpy.float32)</span></span>
dataset -= numpy.<span class="function"><span class="title">mean</span><span class="params">(dataset, axis=<span class="number">0</span>)</span></span>
</code></pre><p>构建哈希超参数，将数据维度和点数传入<code>get_default_parameters</code>获得合适的超参数，得到的超参数可以通过手动微调或者<code>compute_number_of_hash_functions</code>来对其中细节进行微调。</p>
<pre><code>num_points, dim = dataset<span class="class">.shape</span>
parms = falconn.<span class="function"><span class="title">get_default_parameters</span><span class="params">(num_points, dim)</span></span>
falconn.<span class="function"><span class="title">compute_number_of_hash_functions</span><span class="params">(<span class="number">7</span>, parms)</span></span>
</code></pre><p>创建索引实例<code>LSHIndex</code>，并通过方法<code>setup</code>构建索引。</p>
<pre><code>lsh_index = falconn.<span class="function"><span class="title">LSHIndex</span><span class="params">(parms)</span></span>
lsh_index.<span class="function"><span class="title">setup</span><span class="params">(dataset)</span></span>
</code></pre><p>查询的函数有很多，可以根据需要进行选择</p>
<pre><code><span class="function"><span class="title">find_k_nearest_neighbors</span><span class="params">()</span></span>
<span class="function"><span class="title">find_near_neighbors</span><span class="params">()</span></span>
<span class="function"><span class="title">find_nearest_neighbor</span><span class="params">()</span></span>
<span class="function"><span class="title">get_candidates_with_duplicates</span><span class="params">()</span></span>
<span class="function"><span class="title">get_unique_candidates</span><span class="params">()</span></span>
</code></pre><h3 id="C++实现">C++实现</h3><p>TBD</p>
<h1 id="Panns">Panns</h1><p><a href="https://github.com/ryanrhymes/panns" target="_blank" rel="external">https://github.com/ryanrhymes/panns</a>这是一个用python写的针对高维数据的approximate k-nearest neighbors算法包，目前支持欧式距离和余弦距离两种度量。对500维以上的高维特征进行了优化。虽然性能弱于Annoy，但是更加轻量，比FLANN和scikit-learn更为好用</p>
<h3 id="安装">安装</h3><pre><code>sudo pip <span class="operator"><span class="keyword">install</span> panns <span class="comment">--upgrade</span></span>
</code></pre><h3 id="使用示例">使用示例</h3><pre><code><span class="keyword">from</span> panns import *

# <span class="keyword">create</span> an <span class="keyword">index</span> <span class="keyword">of</span> Euclidean distance
p = PannsIndex(dimension=<span class="number">100</span>, metric=<span class="string">'euclidean'</span>)

# generate a <span class="number">1000</span> x <span class="number">100</span> dataset
<span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1000</span>):
    v = gaussian_vector(<span class="number">100</span>)
    p.add_vector(v)

p.parallelize(<span class="keyword">True</span>)        # 多核并行，默认是<span class="keyword">False</span>
# build an <span class="keyword">index</span> <span class="keyword">of</span> <span class="number">128</span> trees <span class="keyword">and</span> save <span class="keyword">to</span> a file
p.build(<span class="number">128</span>)    # <span class="number">64</span> <span class="keyword">is</span> <span class="keyword">default</span>
</code></pre><p>build之后调用save函数保存生成的索引，会生成两个文件<em>.idx保存索引树和</em>.idx.npy保存数据库向量矩阵，这个向量矩阵可以保存成内存文件或者mmap文件，根据如下注释选取保存类型。这两个文件要放在同一个目录下面，加载模型的时候才不会出错。</p>
<pre><code># save the index as an in-memory file if the raw dataset is small or medium size
# later panns will <span class="operator"><span class="keyword">load</span> the entire .npy <span class="keyword">file</span> <span class="keyword">in</span> <span class="keyword">to</span> the <span class="keyword">physical</span> <span class="keyword">memory</span>
<span class="keyword">p</span>.<span class="keyword">save</span>(<span class="string">'test.idx'</span>, mmap=<span class="literal">False</span>)

# <span class="keyword">save</span> the <span class="keyword">index</span> <span class="keyword">as</span> mmap <span class="keyword">file</span> <span class="keyword">if</span> the <span class="keyword">raw</span> dataset <span class="keyword">is</span> huge
# usually, your OS will handle the dynamic loading
<span class="keyword">p</span>.<span class="keyword">save</span>(<span class="string">'test.idx'</span>, mmap=<span class="literal">True</span>)</span>
</code></pre><p>加载模型，查询索引，返回最近邻的前10个查询结果</p>
<pre><code>p1 = <span class="function"><span class="title">PannsIndex</span><span class="params">(metric=<span class="string">'euclidean'</span>)</span></span>
p1.<span class="function"><span class="title">load</span><span class="params">(<span class="string">'test.idx'</span>)</span></span>
v1 = <span class="function"><span class="title">a_new_vector</span><span class="params">(<span class="number">100</span>)</span></span>
n = p1.<span class="function"><span class="title">query</span><span class="params">(v1, <span class="number">10</span>)</span></span>
</code></pre><h1 id="Annoy">Annoy</h1><p><a href="https://github.com/spotify/annoy" target="_blank" rel="external">https://github.com/spotify/annoy</a>这是一个用C++编写的python打包的最近邻搜索算法包，应该是目前性能最好的算法包。</p>
<h3 id="安装-1">安装</h3><pre><code>pip <span class="keyword">install</span> annoy
</code></pre><h3 id="实例">实例</h3><p>tbd</p>
<h2 id="参考资料">参考资料</h2><p><a href="http://yongyuan.name/blog/index-billion-deep-descriptors.html" target="_blank" rel="external">机器视觉：十亿规模的深度描述子如何有效索引</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/11/panns-nnsearch/" data-id="cj3hb05zt001w3cfh86ht4xos" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nnsearch/">nnsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-data-visualization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/07/data-visualization/" class="article-date">
  <time datetime="2016-04-07T14:39:17.000Z" itemprop="datePublished">2016-04-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/07/data-visualization/">数据可视化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>经常看到网上一些样本分布图画的非常漂亮，不知道是怎么画出来的，在网上找到了一个好资料<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/#raw_mnist" target="_blank" rel="external">http://colah.github.io/posts/2014-10-Visualizing-MNIST/#raw_mnist</a>，代码参考的这个<a href="https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm" target="_blank" rel="external">https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm</a>研究了一番总结一下。</p>
<p>我们经常要分析一些高维特征的表现能力，由于我们人类只能理解二维、三维的东西，所以要把高维数据降到三维以内展示出来。</p>
<h3 id="直观想法">直观想法</h3><p>最直观的想法，比如原数据有1000维，从中任意选择两维，然后画图，结果可想而知。</p>
<h3 id="PCA">PCA</h3><p>一种改进办法就是选择更为合适的两个维度进行展示，于是选择PCA主成分分析，然后选择前两个主成分对应的维度作为可视化的两个维度。</p>
<h2 id="降维优化算法">降维优化算法</h2><p>可视化的目标就是希望两个向量实际的距离能够跟显示的距离接近，本来向量距离远的显示的距离也远。这就变成了一个优化问题，这也是很多流形学习方法的目标。比较常用解决这个优化问题的方法有MDS和t-SNE</p>
<h3 id="MDS">MDS</h3><p>结合代码分析，首先，加载必要模块</p>
<pre><code>from sklearn <span class="preprocessor"><span class="keyword">import</span> manifold</span>
<span class="preprocessor"><span class="keyword">import</span> matplotlib.pyplot as plt</span>
<span class="preprocessor"><span class="keyword">import</span> seaborn</span>
<span class="preprocessor"><span class="keyword">import</span> numpy as np</span>
</code></pre><p>首先加载数据，用array存储数据以及对应标签。这里用scikit-learn中的digits手写字符数据集作为演示数据，加载之后，其data维度为1797<em>64，图片是8</em>8=64，target维度为1797*1，为0~9的整数。同时加载seaborn模块中的调色板，用这个模板生成的颜色比自己设计的要好看一些</p>
<pre><code>from sklearn<span class="class">.datasets</span> import load_digits
digits = <span class="function"><span class="title">load_digits</span><span class="params">()</span></span>
palette = np.<span class="function"><span class="title">array</span><span class="params">(seaborn.color_palette(<span class="string">'hls'</span>, <span class="number">10</span>)</span></span>)
x = digits<span class="class">.data</span>
y = digits.target
</code></pre><p>加载mds模型</p>
<pre><code>mds = manifold.<span class="function"><span class="title">MDS</span><span class="params">(n_components=<span class="number">2</span>, max_iter=<span class="number">300</span>, eps=<span class="number">1</span>e-<span class="number">5</span>)</span></span>
x_mds = mds.<span class="function"><span class="title">fit_transform</span><span class="params">(x)</span></span>
</code></pre><p>画图</p>
<pre><code>fig = plt.<span class="function"><span class="title">figure</span><span class="params">()</span></span>
plt.<span class="function"><span class="title">scatter</span><span class="params">(x_mds[:,<span class="number">0</span>], x_mds[:,<span class="number">1</span>], c=palette[y])</span></span>
plt.<span class="function"><span class="title">show</span><span class="params">()</span></span>
</code></pre><h3 id="t-SNE">t-SNE</h3><p>加载数据与上一种方法相同，加载模型代码如下</p>
<pre><code>tsne = manifold.<span class="function"><span class="title">TSNE</span><span class="params">(n_components=<span class="number">2</span>, learning_rate=<span class="number">1000.0</span>)</span></span>
x_tsne = tsne.<span class="function"><span class="title">fit_transform</span><span class="params">(x)</span></span>
</code></pre><h2 id="显示动态流形变化图像">显示动态流形变化图像</h2><p>TBD</p>
<h2 id="可视化参考资料">可视化参考资料</h2><p><a href="http://distill.pub/2016/misread-tsne/" target="_blank" rel="external">how to use t-SNE effectively</a><a href="https://yq.aliyun.com/articles/62946" target="_blank" rel="external">中文翻译</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/07/data-visualization/" data-id="cj3hb062q002z3cfh6hey2zv0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/visualization/">visualization</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-good-site" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/30/good-site/" class="article-date">
  <time datetime="2016-03-30T11:18:48.000Z" itemprop="datePublished">2016-03-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/30/good-site/">good_site</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在线简历生成网站<a href="https://cvmkr.com/" target="_blank" rel="external">https://cvmkr.com/</a><br>翻墙路由器的原理与实现<a href="http://drops.wooyun.org/papers/10177" target="_blank" rel="external">http://drops.wooyun.org/papers/10177</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/30/good-site/" data-id="cj3hb062a002n3cfhwujshmm3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/生活/">生活</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-darknet-yolo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/25/darknet-yolo/" class="article-date">
  <time datetime="2016-03-25T13:54:01.000Z" itemprop="datePublished">2016-03-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/25/darknet-yolo/">darknet学习（一）YOLO目标检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="darknet安装">darknet安装</h1><p>darknet的安装还是非常简单的，依赖只有cuda和opencv，安装好之后执行以下命令即可安装编译成功</p>
<pre><code>git clone <span class="attribute">https</span>:<span class="regexp">//gi</span>thub.com/pjreddie/darknet.git
cd darknet
vim Makefile
<span class="comment">######</span><span class="comment">######</span><span class="comment">#####[modify Makefile]
GPU=1
OPENCV=1
OPTS=-Ofast  # 如果gcc版本过低，这里可能需要改成-O3
###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">##[close]</span>
make
</code></pre><h1 id="YOLO训练">YOLO训练</h1><h2 id="准备训练数据">准备训练数据</h2><p>检测算法需要对图像中的目标区域进行标注，我这里实验只准备了5个类别的检测数据，我用python基于OpenCV做了一个简单的标注工具，可以得到矩形左上角、右下角的坐标位置，代码如下：</p>
<pre><code><span class="keyword">import</span> os
<span class="keyword">import</span> cv2
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> copy
<span class="keyword">import</span> glob
<span class="keyword">import</span> sys


<span class="comment">#PT1 = (0,0)</span>
<span class="comment">#PT2 = (0,0)</span>
<span class="function"><span class="keyword">def</span> <span class="title">draw_box</span><span class="params">(event, x, y, flags, param)</span>:</span>
    <span class="keyword">global</span> PT1
    <span class="keyword">global</span> PT2
    <span class="keyword">global</span> img_copy
    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDOWN <span class="keyword">and</span> flags == cv2.EVENT_FLAG_LBUTTON:    
        PT1 = (x,y)
        PT2 = (x,y)
    <span class="keyword">if</span> flags == cv2.EVENT_FLAG_LBUTTON:
        PT2 = (x,y)
    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONUP:
        PT2 = (x,y)
    cv2.rectangle(img_copy, PT1, PT2, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)
    cv2.imshow(<span class="string">'image'</span>, img_copy)
    img_copy = copy.deepcopy(img)


<span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:
    img_path = <span class="string">'D:/test'</span>
    img_list = glob.glob(os.path.join(img_path, <span class="string">'*.jpg'</span>))
    img_list = sorted(img_list)
<span class="comment">#    print img_list</span>
    box_result_name = <span class="string">'box_result.txt'</span>
    img_processed = []
    <span class="keyword">try</span>:
        <span class="keyword">with</span> open(os.path.join(img_path, box_result_name), <span class="string">'rb'</span>) <span class="keyword">as</span> f_box:
            <span class="keyword">for</span> line <span class="keyword">in</span> f_box.readlines():
                line = line.strip().split(<span class="string">','</span>)
                img_processed.append(line[<span class="number">0</span>])
    <span class="keyword">except</span> IOError:
        <span class="keyword">pass</span>
    img_processed = set(img_processed)

    cv2.namedWindow(<span class="string">'image'</span>)
    cv2.setMouseCallback(<span class="string">'image'</span>, draw_box)

    f_box = open(os.path.join(img_path, box_result_name), <span class="string">'a'</span>)
    <span class="keyword">for</span> img_name <span class="keyword">in</span> img_list:
        <span class="keyword">print</span> img_name
        <span class="keyword">if</span> img_name <span class="keyword">in</span> img_processed:
            <span class="keyword">continue</span>
        img = cv2.imread(img_name)
        img_copy = copy.deepcopy(img)
        PT1 = (<span class="number">0</span>,<span class="number">0</span>)
        PT2 = (<span class="number">0</span>,<span class="number">0</span>)

        <span class="keyword">while</span> (<span class="number">1</span>):
            key = cv2.waitKey(<span class="number">0</span>)
            <span class="keyword">if</span> key == <span class="number">27</span>:
                cv2.destroyAllWindows()
                f_box.close()
                sys.exit(<span class="number">0</span>)
            <span class="keyword">elif</span> key == <span class="number">32</span>:
                <span class="keyword">if</span> PT1[<span class="number">0</span>]==<span class="number">0</span> <span class="keyword">or</span> PT1[<span class="number">1</span>]==<span class="number">0</span> <span class="keyword">or</span> PT2[<span class="number">0</span>]==<span class="number">0</span> <span class="keyword">or</span> PT2[<span class="number">1</span>]==<span class="number">0</span> <span class="keyword">or</span> abs(PT2[<span class="number">0</span>]-PT1[<span class="number">0</span>])&lt;<span class="number">10</span> <span class="keyword">or</span> abs(PT2[<span class="number">1</span>]-PT1[<span class="number">1</span>])&lt;<span class="number">10</span>:
                    <span class="keyword">continue</span>
                <span class="keyword">if</span> PT1[<span class="number">0</span>] &lt; PT2[<span class="number">0</span>]:
                    x1 = PT1[<span class="number">0</span>]
                    x2 = PT2[<span class="number">0</span>]
                <span class="keyword">else</span>:
                    x1 = PT2[<span class="number">0</span>]
                    x2 = PT1[<span class="number">0</span>]
                <span class="keyword">if</span> PT1[<span class="number">1</span>] &lt; PT2[<span class="number">1</span>]:
                    y1 = PT1[<span class="number">1</span>]
                    y2 = PT2[<span class="number">1</span>]
                <span class="keyword">else</span>:
                    y1 = PT2[<span class="number">1</span>]
                    y2 = PT1[<span class="number">1</span>]
                f_box.write(<span class="string">'%s,%d,%d,%d,%d\n'</span> % (img_name, x1, y1, x2, y2))
                <span class="comment">#print 'next image'</span>
                <span class="keyword">break</span>
            <span class="keyword">elif</span> key == <span class="number">122</span>:
                f_box.close()
                f_box = open(os.path.join(img_path, box_result_name), <span class="string">'rb'</span>)
                lines = f_box.readlines()
                f_box.close()
                curr = lines[:-<span class="number">1</span>]
                f_box = open(os.path.join(img_path, box_result_name), <span class="string">'w'</span>)
                <span class="keyword">for</span> line <span class="keyword">in</span> lines:
                    line = line.strip()
                    f_box.write(<span class="string">'%s'</span> % line)
                <span class="keyword">print</span> <span class="string">'delete last image box'</span>
                cv2.destroyAllWindows()
                f_box.close()
                sys.exit(<span class="number">0</span>)
        <span class="keyword">else</span>:
            <span class="keyword">break</span>
    cv2.destroyAllWindows()
    f_box.close()
</code></pre><p>这个标注工具代码比较繁琐，不过还算鲁棒，可以有效处理误标注并实现自动跳转下一张图的功能。每一个待检测的类别用这个标注工具可以生成一个对应的文本文件说明每一张图的矩形坐标位置。</p>
<h2 id="生成用于darknet的标注">生成用于darknet的标注</h2><p>darknet要求每一张图片<code>a.jpg</code>对应一个<code>a.txt</code>，文本里面一行信息说明groundtruth的类别和图像原始宽高的相对坐标，如下：</p>
<pre><code><span class="preprocessor"># &lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;</span>
<span class="number">1</span> <span class="number">0.526875</span> <span class="number">0.499375</span> <span class="number">0.30875</span> <span class="number">0.80375</span>
</code></pre><p>我基于darknet自带的<code>scripts\voc_label.py</code>写了一个脚本把图像以及标注工具生成的矩形坐标转换成满足darknet的标注信息</p>
<pre><code><span class="keyword">import</span> pickle
<span class="keyword">import</span> os
from os <span class="keyword">import</span> listdir, getcwd
from os.path <span class="keyword">import</span> <span class="built_in">join</span>

sets = [<span class="string">'men_jacket'</span>, <span class="string">'men_bottem'</span>, <span class="string">'underwear'</span>, <span class="string">'women_bottem'</span>, <span class="string">'women_jacket'</span>]
classes = [<span class="string">'men_jacket'</span>, <span class="string">'men_bottem'</span>, <span class="string">'underwear'</span>, <span class="string">'women_bottem'</span>, <span class="string">'women_jacket'</span>]


def convert(<span class="built_in">size</span>, <span class="built_in">box</span>):
    dw = <span class="number">1.</span>/<span class="built_in">size</span>[<span class="number">0</span>]
    dh = <span class="number">1.</span>/<span class="built_in">size</span>[<span class="number">1</span>]
    x = (<span class="built_in">box</span>[<span class="number">0</span>] + <span class="built_in">box</span>[<span class="number">2</span>])/<span class="number">2.0</span>
    y = (<span class="built_in">box</span>[<span class="number">1</span>] + <span class="built_in">box</span>[<span class="number">3</span>])/<span class="number">2.0</span>
    w = <span class="built_in">box</span>[<span class="number">2</span>] - <span class="built_in">box</span>[<span class="number">0</span>]
    h = <span class="built_in">box</span>[<span class="number">3</span>] - <span class="built_in">box</span>[<span class="number">1</span>]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    <span class="keyword">return</span> (x,y,w,h)

def convert_annotation(<span class="built_in">line</span>, image_id, set_id):
    out_file = <span class="built_in">open</span>(<span class="string">'box_labels/%s/%s.txt'</span>%(set_id, image_id), <span class="string">'w'</span>)

    w = <span class="number">800</span>
    h = <span class="number">800</span>
    cls = <span class="built_in">line</span>[<span class="number">0</span>].<span class="built_in">split</span>(<span class="string">'/'</span>)[<span class="number">1</span>]
    <span class="keyword">if</span> cls not in classes:
        <span class="keyword">return</span>
    cls_id = classes.index(cls)

    b = (<span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">1</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">2</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">3</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">4</span>]))
    bb = convert((w,h), b)
    out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">" "</span> + <span class="string">" "</span>.<span class="built_in">join</span>([<span class="built_in">str</span>(a) <span class="keyword">for</span> a in bb]) + <span class="string">'\n'</span>)
    out_file.close

wd = getcwd()
list_file = <span class="built_in">open</span>(<span class="string">'train.txt'</span>, <span class="string">'w'</span>)
<span class="keyword">for</span> set_id in sets:
    <span class="keyword">if</span> not os.path.exists(<span class="string">'box_labels/%s'</span> % (set_id)):
        os.makedirs(<span class="string">'box_labels/%s'</span> % (set_id))
    images_info = <span class="built_in">open</span>(<span class="string">'box_imgs/%s.txt'</span> % (set_id)).readlines()
    <span class="keyword">for</span> <span class="built_in">line</span> in images_info:
        <span class="built_in">line</span> = <span class="built_in">line</span>.strip().<span class="built_in">split</span>(<span class="string">','</span>)
        image_id = <span class="built_in">line</span>[<span class="number">0</span>].<span class="built_in">split</span>(<span class="string">'/'</span>)[<span class="number">2</span>].<span class="built_in">split</span>(<span class="string">'.'</span>)[<span class="number">0</span>]
        list_file.write(<span class="string">'%s/box_imgs/%s/%s.jpg\n'</span> % (wd, set_id, image_id))
        convert_annotation(<span class="built_in">line</span>, image_id, set_id)
list_file.close()
</code></pre><p>执行这个脚本会生成一个<code>box_labels</code>文件夹，并在里面生成对应的darknet标签信息。同时生成一个<code>train.txt</code>说明用于训练的图片的路径。</p>
<h2 id="更改YOLO模型参数">更改YOLO模型参数</h2><p>对<code>cfg/yolo.cfg</code>的配置文件进行调整</p>
<pre><code>subdivisions=<span class="number">2</span> <span class="preprocessor"># 原来为<span class="number">64</span>，改小可以提高训练速度，同时增加显存使用</span>
output= <span class="number">735</span> <span class="preprocessor"># 最后connected层，原来值为<span class="number">1470</span></span>
classes = <span class="number">5</span> <span class="preprocessor"># detection层，这里设置为<span class="number">5</span></span>
</code></pre><p>这个参数的确定由公式<code>output = S x S x (5*B+C)</code>，其中S=7，B=2, C=5（5是我实验使用的类别数）。</p>
<p>改写<code>src/data.c</code>中的<code>fill_truth_region</code>函数，确定图像和标签数据的加载位置</p>
<pre><code>//    char *labelpath = find_replace<span class="list">(<span class="keyword">path</span>, <span class="string">"images"</span>, <span class="string">"labels"</span>)</span><span class="comment">;</span>
    char *labelpath = find_replace<span class="list">(<span class="keyword">path</span>, <span class="string">"box_imgs"</span>, <span class="string">"box_labels"</span>)</span><span class="comment">;</span>
</code></pre><p>改写<code>src/yolo.c</code>：</p>
<pre><code>//<span class="type">char</span> *voc_names[] = {<span class="string">"aeroplane"</span>, <span class="string">"bicycle"</span>, <span class="string">"bird"</span>, <span class="string">"boat"</span>, <span class="string">"bottle"</span>, <span class="string">"bus"</span>, <span class="string">"car"</span>, <span class="string">"cat"</span>, <span class="string">"chair"</span>, <span class="string">"cow"</span>, <span class="string">"diningtable"</span>, <span class="string">"dog"</span>, <span class="string">"horse"</span>, <span class="string">"motorbike"</span>, <span class="string">"person"</span>, <span class="string">"pottedplant"</span>, <span class="string">"sheep"</span>, <span class="string">"sofa"</span>, <span class="string">"train"</span>, <span class="string">"tvmonitor"</span>};
//image voc_labels[<span class="number">20</span>];
<span class="type">char</span> *voc_names[] = {<span class="string">"men_jacket"</span>, <span class="string">"men_bottem"</span>, <span class="string">"underwear"</span>, <span class="string">"women_bottem"</span>, <span class="string">"women_jacket"</span>};
image voc_labels[<span class="number">5</span>];
<span class="type">void</span> train_yolo(<span class="type">char</span> *cfgfile, <span class="type">char</span> *weightfile)
{
//    <span class="type">char</span> *train_images = <span class="string">"/data/voc/train.txt"</span>;
//    <span class="type">char</span> *backup_directory = <span class="string">"/home/pjreddie/backup/"</span>;
    <span class="type">char</span> *train_images = <span class="string">"/home/xixi/darknet/train.txt"</span>;
    <span class="type">char</span> *backup_directory = <span class="string">"/home/xixi/darknet/results/"</span>;

...

<span class="type">void</span> run_yolo(<span class="type">int</span> argc, <span class="type">char</span> **argv)
{
    /*
    <span class="type">int</span> i;
    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i){
        <span class="type">char</span> buff[<span class="number">256</span>];
        sprintf(buff, <span class="string">"data/labels/%s.png"</span>, voc_names[i]);
        voc_labels[i] = load_image_color(buff, <span class="number">0</span>, <span class="number">0</span>);
    }
    */
</code></pre><p>改好之后重新编译代码，下载预训练好的模型参数文件，并开始训练</p>
<pre><code>make
wget http:<span class="comment">//pjreddie.com/media/files/extraction.conv.weights</span>
./darknet -<span class="tag">i</span> <span class="number">2</span> yolo train cfg/yolo<span class="class">.cfg</span> extraction<span class="class">.conv</span><span class="class">.weights</span>
</code></pre><p>在results文件夹下面就好生成训练好的模型文件，当迭代40000次后，会输出最终模型文件yolo_final.weights。这个过程用GPU大概需要3天时间，消耗显存6个G。（-i参数表示使用第二块GPU）</p>
<h1 id="YOLO检测">YOLO检测</h1><pre><code><span class="comment"># 检测单张图片</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt;
<span class="comment"># 检测多张图片</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights
<span class="comment"># 改变检测的阈值</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt; -thresh <span class="number">0</span>
<span class="comment"># 改为CPU模式检测</span>
./darknet -nogpu yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt;
</code></pre><p>经过测试，在GPU环境下，测试一张图片跑完整的YOLO模型需要40ms~100ms，CPU环境下需要5秒以上。</p>
<h1 id="补充">补充</h1><p>YOLO官方后来又出了一个yolo2.cfg，研究了一下，每一卷积层都加了batch_normlization，提高训练速度，破费。同时把最后的一个全连接层改成了一个local层</p>
<h1 id="讨论和思考">讨论和思考</h1><ul>
<li><p>YOLO的核心思想就是利用整张图作为网络的输入，直接在输出层回归bounding box的位置和bounding box所属的类别。</p>
</li>
<li><p>将一副图像经过类似alexnet的特征提取，最后经过一层的全连接层之后又映射回SxS个网格(grid cell)，如果某个object的中心 落在这个网格中，则这个网格就负责预测这个object。</p>
</li>
<li><p>每个网格要预测B个bounding box，每个bounding box除了要回归自身的位置之外，还要附带预测一个confidence值。 这个confidence等于所预测的box中含有object的置信度（object落在其中，取1，否则取0）和这个box和truth的IOU交集的乘积确定。这样每个网格要返回bounding box预测的(x, y, w, h)和confidence5个值，以及object的类别信息C类，所以最后一层的输出应该为<code>S x S x (5*B+C)</code>。</p>
</li>
<li><p>由于xywh取的是相对坐标，归一化为0~1，confidence取值范围为0~1，category的类别取值为0或1，简单实现了归一化的目的，然而由于目标函数使用了均方误差损失函数，位置坐标和类别判别信息维度对损失函数的贡献不应该是一样的，所以文章中采用了如下的方法改进</p>
</li>
</ul>
<ol>
<li>更重视坐标预测，给这些损失前面赋予更大的loss weight, 训练中取5。</li>
<li>对没有object的box的confidence loss，赋予小的loss weight，训练中取0.5。</li>
<li>有object的box的confidence loss和类别的loss的loss weight正常取1。</li>
</ol>
<ul>
<li><p>对于小的box位置偏差对实际的效果影响更为严重，但均方误差对这个没有体现，所以对w和h参数又取了平方根处理，增大的小box的位置偏移对loss函数的影响。</p>
</li>
<li><p>一个网格有多个bounding box的时候，根据IOU值取前B个进行处理。所以对多个物体相互靠近的时候处理的并不是十分理想。</p>
</li>
<li><p>在test一张图片的时候，通过网络得到SxSx(5*B+C)层的值后，每个网格的类别信息Pr1，其对应的bounding box的confidence Pr2以及box和网格的IOU信息的乘积用来预测box属于某一类的概率。根据阈值过滤后，对保留的boxes进行非极大值抑制NMS处理，得到最终结果。</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/25/darknet-yolo/" data-id="cj3hb065g00333cfhfxekidxu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/darknet/">darknet</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-add-layer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/23/caffe-add-layer/" class="article-date">
  <time datetime="2016-03-23T14:06:35.000Z" itemprop="datePublished">2016-03-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/23/caffe-add-layer/">caffe学习（六）创建自己的模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近阅读文章《Supervised Learning of Semantics-Preserving Hashing via Deep Neural Networks for Large-Scale Image Search》，对应的开源代码有两个版本<a href="https://github.com/kevinlin311tw/caffe-cvprw15" target="_blank" rel="external">https://github.com/kevinlin311tw/caffe-cvprw15</a>，<a href="https://github.com/kevinlin311tw/Caffe-DeepBinaryCode" target="_blank" rel="external">https://github.com/kevinlin311tw/Caffe-DeepBinaryCode</a>，<strong>两者之间的主要区别在于后者使用了更为复杂的目标函数，而不是简单的做了一层sigmoid</strong>。由于其在alexnet上进行了微小改动，在fc7和fc8层之间添加了一个latent layer，将原本用于检索的4096特征维度哈希为128维的二值特征，取得了不错的效果，借鉴这篇文章的代码，我实验了一下如何创建自己的模型，添加自己的layer</p>
<h2 id="预训练模型">预训练模型</h2><p>不同于文章使用的alexnet，我的实验使用的是更为复杂的googLeNet。首先要训练好一个模型，对应一个caffemodel文件，和其训练测试对应的prototxt文件，并在此之上进行fine-tune。</p>
<h2 id="准备训练数据">准备训练数据</h2><p>跟普通的分类训练没有区别，也要准备lmdb格式的文件以及均值文件。</p>
<h2 id="修改train-prototxt">修改train.prototxt</h2><p>原本的层级结构是<code>pool5/7x7_s1 --&gt; loss3/classifier --&gt; SoftmaxWithLoss &amp; Accuracy</code>，改动后变成<code>pool5/7x7_s1 --&gt; latent_SSDH --&gt; latent_SSDH_encode --&gt; loss3/classifier_change --&gt; SoftmaxWithLoss &amp; Accuracy</code>。具体就是添加了一层InnerProduct，输出数目为哈希的位数，后面接一层Sigmoid层将其二值化，再接到原本的loss3/classifier层，并对该层进行finetune，调整该层的训练参数。改动代码如下：</p>
<pre><code><span class="preprocessor">#########added by yx followed by layer <span class="string">"pool5/drop_7x7_s1"</span></span>
layer {
  name: <span class="string">"latent_SSDH"</span>
  type: <span class="string">"InnerProduct"</span>
  bottom: <span class="string">"pool5/7x7_s1"</span>
  top: <span class="string">"latent_SSDH"</span>
  param {
    lr_mult: <span class="number">1</span>
    decay_mult: <span class="number">1</span>
  }
  param {
    lr_mult: <span class="number">2</span>
    decay_mult: <span class="number">0</span>
  }
  inner_product_param {
    num_output: <span class="number">128</span>
    weight_filler {
      type: <span class="string">"gaussian"</span>
      <span class="built_in">std</span>: <span class="number">0.005</span>
    }
    bias_filler {
      type: <span class="string">"constant"</span>
      value: <span class="number">1</span>
    }
  }
}
layer {
  name: <span class="string">"latent_SSDH_encode"</span>
  bottom: <span class="string">"latent_SSDH"</span>
  top: <span class="string">"latent_SSDH_encode"</span>
  type: <span class="string">"Sigmoid"</span>
}
<span class="preprocessor">##########################</span>
</code></pre><p>并把loss3/classifier层的名字改为<code>loss3/classifier_change</code>，bottom层改为<code>latent_SSDH_encode</code>，top层改为<code>loss3/classifier_change</code>，把lr_mult参数*10。</p>
<p>最后把SoftmaxWithLoss层以及Accuracy层的bottom改为新层名<code>loss3/classifier_change</code>。</p>
<p>这里详细介绍一下weight_filter的初始化细节，一般有<code>gaussian</code>和<code>xavier</code>两种方式：<br>xavier具体方式是从[-scale, +scale]中进行均匀采样，对卷积层或全连接层中参数进行初始化的方法。<br>其中scale = \sqrt(3 / n), n根据不同实现可设置为n=(num_in + num_out) / 2 (Understanding the difficulty of training deep feedforward neural networks )，或n=num_out (caffe最初实现方法)</p>
<h2 id="修改solver-prototxt">修改solver.prototxt</h2><ul>
<li>将<code>test_initialization</code>屏蔽掉</li>
<li>weight_decay改为0.0005</li>
<li>gamma改为0.1</li>
<li>base_lr参数降低10倍，改为0.001</li>
</ul>
<h2 id="修改deploy-prototxt">修改deploy.prototxt</h2><p>因为原本的deploy是要做分类的任务，而我这里是要做哈希特征提取，所以要把原来的最后两层loss3/classifier_change和Softmax屏蔽掉，并添加如下代码</p>
<pre><code><span class="comment">############## added by yx #########</span>
<span class="name">layer</span> {
  <span class="literal">name</span>: <span class="string">"latent_SSDH"</span>
  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span>
  bottom: <span class="string">"pool5/7x7_s1"</span>
  top: <span class="string">"latent_SSDH"</span>
  inner_product_param {
    num_output: <span class="number">128</span>
  }
}
<span class="name">layer</span> {
  <span class="literal">name</span>: <span class="string">"latent_SSDH_encode"</span>
  <span class="built_in">type</span>: <span class="string">"Sigmoid"</span>
  bottom: <span class="string">"latent_SSDH"</span>
  top: <span class="string">"latent_SSDH_encode"</span>
}
</code></pre><h2 id="训练命令">训练命令</h2><pre><code>nohup ../../build/tools/caffe train --solver=solver<span class="class">.prototxt</span> -weights sku30450_googlenet_quick_iter_500000<span class="class">.caffemodel</span> -gpu <span class="number">1</span> &amp;
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/23/caffe-add-layer/" data-id="cj3hb069k003w3cfh1vngp0fo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-linux-shell-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/19/linux-shell-skill/" class="article-date">
  <time datetime="2016-03-19T05:24:25.000Z" itemprop="datePublished">2016-03-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/19/linux-shell-skill/">linux shell技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="匹配特殊字符空格">匹配特殊字符空格</h3><pre><code>find . -<span class="property">name</span> <span class="string">"*[[:space:]]*"</span>
</code></pre><h3 id="找到指定文件并删除">找到指定文件并删除</h3><pre><code>find . -<span class="property">name</span> <span class="string">"abc*"</span> -exec rm {} \;
</code></pre><h2 id="大文件分割与合并">大文件分割与合并</h2><p>把aaa.tar.gz分割，每卷5G，然后合并</p>
<pre><code><span class="tag">split</span> <span class="tag">-b</span> 5000<span class="tag">m</span> <span class="tag">aaa</span><span class="class">.tar</span><span class="class">.gz</span> <span class="tag">aaa_part</span><span class="class">.tar</span><span class="class">.gz</span>.
<span class="tag">cat</span> <span class="tag">aaa_part</span><span class="class">.tar</span><span class="class">.gz</span>.* &gt; <span class="tag">aaa</span><span class="class">.tar</span><span class="class">.gz</span>
</code></pre><p>大文件夹aaa分卷压缩与合并解压</p>
<pre><code>tar czvf - aaa <span class="string">| split -b 5000m - aaa_part.tar.gz.</span>
cat aaa_part.tar.gz.* <span class="string">| tar xz</span>
</code></pre><h3 id="批量杀死进程">批量杀死进程</h3><pre><code>ps aux | grep <span class="string">"common"</span> | cut –c <span class="number">9</span>-<span class="number">15</span> | xargs kill
</code></pre><h2 id="find_文件查找">find 文件查找</h2><p>查找txt和pdf文件</p>
<pre><code>find . ( -<span class="property">name</span> <span class="string">"*.txt"</span> -o -<span class="property">name</span> <span class="string">"*.pdf"</span> ) -print
</code></pre><p>正则方式查找.txt和pdf，<code>-iregex</code>: 忽略大小写的正则</p>
<pre><code><span class="keyword">find</span> . -regex  <span class="string">".*(.txt|.pdf)$"</span>
</code></pre><p>否定参数，查找所有非txt文本</p>
<pre><code><span class="keyword">find</span> . ! -name <span class="string">"*.txt"</span> -<span class="keyword">print</span>
</code></pre><p>指定搜索深度，打印出当前目录的文件（深度为1）</p>
<pre><code><span class="built_in">find</span> . -maxdepth <span class="number">1</span> -<span class="built_in">type</span> f
</code></pre><p>按类型搜索：-type f 文件 / l 符号链接 / d 目录</p>
<pre><code>find . -<span class="keyword">type</span> <span class="keyword">d</span> -<span class="keyword">print</span>  <span class="comment">//只列出所有目录</span>
</code></pre><p>按时间搜索：<br>  -atime 访问时间 (单位是天，分钟单位则是-amin，以下类似）<br>  -mtime 修改时间（内容被修改）<br>  -ctime 变化时间（元数据或权限变化）<br>最近7天被访问过的所有文件：</p>
<pre><code><span class="built_in">find</span> . -atime <span class="number">7</span> -<span class="built_in">type</span> f -<span class="built_in">print</span>
</code></pre><p>按大小搜索：w字 k M G，寻找大于2k的文件</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -size +<span class="number">2</span>k
</code></pre><p>按权限查找：</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -perm <span class="number">644</span> -<span class="built_in">print</span> //找具有可执行权限的所有文件
</code></pre><p>按用户查找：</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -user weber -<span class="built_in">print</span>// 找用户weber所拥有的文件
</code></pre><h3 id="找到后的后续动作">找到后的后续动作</h3><p>删除：删除当前目录下所有的swp文件：</p>
<pre><code><span class="keyword">find</span> . -<span class="built_in">type</span> <span class="keyword">f</span> -name <span class="string">"*.swp"</span> -<span class="built_in">delete</span>
</code></pre><p>执行动作（强大的exec）</p>
<pre><code><span class="title">find</span> . -<span class="typedef"><span class="keyword">type</span> f -user root -exec chown weber <span class="container">{}</span> ; //将当前目录下的所有权变更为weber</span>
</code></pre><p>注：{}是一个特殊的字符串，对于每一个匹配的文件，{}会被替换成相应的文件名；<br>eg：将找到的文件全都copy到另一个目录：</p>
<pre><code><span class="title">find</span> . -<span class="typedef"><span class="keyword">type</span> f -mtime +10 -name "*.txt" -exec cp <span class="container">{}</span> <span class="type">OLD</span> ;</span>
</code></pre><p>结合多个命令<br>tips: 如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后 -exec 调用时执行脚本即可；</p>
<pre><code><span class="deletion">-exec ./commands.sh {} \;</span>
</code></pre><h3 id="-print的定界符">-print的定界符</h3><p>默认使用’\n’作为文件的定界符；<br>-print0 使用”作为文件的定界符，这样就可以搜索包含空格的文件；</p>
<h2 id="grep_文本搜索">grep 文本搜索</h2><p>常用参数<br>-o 只输出匹配的文本行<br>-v 只输出没有匹配的文本行<br>-c 统计文件中包含文本的次数</p>
<pre><code><span class="keyword">grep</span> -c <span class="string">"text"</span> filename
</code></pre><p>-n 打印匹配的行号<br>-i 搜索时忽略大小写<br>-l 只打印文件名<br>在多级目录中对文本递归搜索(程序员搜代码的最爱）：</p>
<pre><code><span class="keyword">grep</span> <span class="string">"class"</span> . -R -n
</code></pre><p>匹配多个模式</p>
<pre><code>grep -<span class="keyword">e</span> <span class="string">"class"</span> -<span class="keyword">e</span> <span class="string">"vitural"</span> <span class="keyword">file</span>
</code></pre><p>grep输出以作为结尾符的文件名：（-z）</p>
<pre><code>grep <span class="string">"test"</span> file<span class="keyword">*</span> -lZ|<span class="string"> xargs -0 rm</span>
</code></pre><h2 id="xargs_命令行参数转换">xargs 命令行参数转换</h2><p>xargs 能够将输入数据转化为特定命令的命令行参数；这样，可以配合很多命令来组合使用。比如grep，比如find；</p>
<p>将多行输出转化为单行输出</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span>.txt| xargs
</code></pre><p>将单行转化为多行输出，-n：指定每行显示的字段数</p>
<pre><code><span class="keyword">cat</span> single.txt | xargs -<span class="keyword">n</span> 3
</code></pre><h3 id="xargs参数说明">xargs参数说明</h3><p>-d 定义定界符 （默认为空格 多行的定界符为 n）<br>-n 指定输出为多行<br>-I {} 指定替换字符串，这个字符串在xargs扩展时会被替换掉,用于待执行的命令需要多个参数时。eg：</p>
<pre><code>cat <span class="built_in">file</span>.txt | xargs -I {} ./<span class="command"><span class="keyword">command</span>.<span class="title">sh</span> -<span class="title">p</span> {} -<span class="title">1</span></span>
</code></pre><p>-0：指定为输入定界符，eg：统计程序行数</p>
<pre><code>find <span class="built_in">source</span>_dir/ -type f -name <span class="string">"*.cpp"</span> -print0 |xargs -<span class="number">0</span> wc <span class="operator">-l</span>
</code></pre><h2 id="sort_排序">sort 排序</h2><p>字段说明：<br>-n 按数字进行排序 VS -d 按字典序进行排序<br>-r 逆序排序<br>-k N 指定按第N列排序<br>eg：</p>
<pre><code><span class="title">sort</span> -nrk <span class="number">1</span> <span class="typedef"><span class="keyword">data</span>.txt</span>
<span class="title">sort</span> -bd <span class="typedef"><span class="keyword">data</span> // 忽略像空格之类的前导空白字符</span>
</code></pre><h2 id="uniq_消除重复行">uniq 消除重复行</h2><p>消除重复行</p>
<pre><code>sort unsort.txt <span class="string">| uniq</span>
</code></pre><p>统计各行在文件中出现的次数</p>
<pre><code><span class="built_in">sort</span> unsort.txt | uniq -<span class="built_in">c</span>
</code></pre><p>找出重复行，可指定每行中需要比较的重复内容：-s 开始位置 -w 比较字符数</p>
<pre><code><span class="keyword">sort</span> unsort.txt | uniq -<span class="literal">d</span>
</code></pre><h2 id="用tr进行转换">用tr进行转换</h2><p>通用用法</p>
<pre><code><span class="keyword">echo</span> <span class="number">12345</span> | <span class="built_in">tr</span> <span class="string">'0-9'</span> <span class="string">'9876543210'</span> //加解密转换，替换对应字符
<span class="keyword">cat</span> text| <span class="built_in">tr</span> <span class="string">'t'</span> <span class="string">' '</span>  //制表符转空格
</code></pre><p>tr删除字符</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | tr -<span class="keyword">d</span> '0-9' <span class="comment">// 删除所有数字</span>
</code></pre><p>-c 求补集</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | tr -c '0-9' <span class="comment">//获取文件中所有数字</span>
<span class="keyword">cat</span> <span class="keyword">file</span> | tr -<span class="keyword">d</span> -c '0-9 <span class="keyword">n</span>'  <span class="comment">//删除非数字数据</span>
</code></pre><p>tr压缩字符<br>tr -s 压缩文本中出现的重复字符；最常用于压缩多余的空格</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | <span class="built_in">tr</span> -<span class="keyword">s</span> <span class="string">' '</span>
</code></pre><p>字符类<br>tr中可用各种字符类：<br>alnum：字母和数字<br>alpha：字母<br>digit：数字<br>space：空白字符<br>lower：小写<br>upper：大写<br>cntrl：控制（非可打印）字符<br>print：可打印字符<br>使用方法：tr [:class:] [:class:]</p>
<pre><code>eg: <span class="tag">tr</span> <span class="string">'[:lower:]'</span> <span class="string">'[:upper:]'</span>
</code></pre><h2 id="cut_按列切分文本">cut 按列切分文本</h2><p>截取文件的第2列和第4列：</p>
<pre><code><span class="label">cut</span> -<span class="literal">f2</span>,<span class="number">4</span> filename
</code></pre><p>去文件除第3列的所有列：</p>
<pre><code>cut -f3 <span class="comment">--complement filename</span>
</code></pre><p>-d 指定定界符：</p>
<pre><code>cat <span class="operator">-f</span>2 <span class="operator">-d</span><span class="string">";"</span> filename
</code></pre><p>cut 取的范围<br>N- 第N个字段到结尾<br>-M 第1个字段为M<br>N-M N到M个字段</p>
<ul>
<li><p>cut 取的单位<br>-b 以字节为单位<br>-c 以字符为单位<br>-f 以字段为单位（使用定界符）<br>eg:</p>
<p>  cut -c1-5 file //打印第一到5个字符<br>  cut -c-2 file  //打印前2个字符</p>
</li>
</ul>
<h2 id="wc_统计行和字符的工具">wc 统计行和字符的工具</h2><pre><code>wc -<span class="keyword">l</span> <span class="keyword">file</span> <span class="comment">// 统计行数</span>
wc -w <span class="keyword">file</span> <span class="comment">// 统计单词数</span>
wc -c <span class="keyword">file</span> <span class="comment">// 统计字符数</span>
</code></pre><h2 id="sed_文本替换利器">sed 文本替换利器</h2><p>首处替换</p>
<pre><code>seg <span class="string">'s/text/replace_text/'</span> <span class="keyword">file</span>   <span class="comment">//替换每一行的第一处匹配的text</span>
</code></pre><p>全局替换</p>
<pre><code>seg 's/<span class="type">text</span>/replace_text/g' <span class="type">file</span>
</code></pre><p>默认替换后，输出替换后的内容，如果需要直接替换原文件,使用-i：</p>
<pre><code>seg -<span class="tag">i</span> <span class="string">'s/text/repalce_text/g'</span> file
</code></pre><p>移除空白行：</p>
<pre><code>sed <span class="string">'/^$/d'</span> <span class="keyword">file</span>
</code></pre><p>变量转换，已匹配的字符串通过标记&amp;来引用</p>
<pre><code>echo this <span class="keyword">is</span> en example | seg 's/\w+/<span class="comment">[&amp;]</span>/g'
$&gt;<span class="comment">[this]</span>  <span class="comment">[is]</span> <span class="comment">[en]</span> <span class="comment">[example]</span>
</code></pre><p>子串匹配标记<br>第一个匹配的括号内容使用标记1来引用</p>
<pre><code><span class="title">sed</span> <span class="string">'s/hello([0-9])/1/'</span>
</code></pre><p>双引号求值，sed通常用单引号来引用；也可使用双引号，使用双引号后，双引号会对表达式求值：</p>
<pre><code><span class="title">sed</span> <span class="string">'s/<span class="variable">$var</span>/HLLOE/'</span>
</code></pre><p>当使用双引号时，我们可以在sed样式和替换字符串中指定变量；</p>
<pre><code>p=patten
r=replaced
<span class="built_in">echo</span> <span class="string">"line con a patten"</span> | sed <span class="string">"s/<span class="variable">$p</span>/<span class="variable">$r</span>/g"</span>
$&gt;line con a replaced
</code></pre><h2 id="awk_数据流处理工具">awk 数据流处理工具</h2><p>awk脚本结构<br>awk ‘BEGIN{ statements } statements2 END{ statements }’</p>
<ul>
<li>工作方式</li>
</ul>
<ol>
<li>执行begin中语句块；</li>
<li>从文件或stdin中读入一行，然后执行statements2，重复这个过程，直到文件全部被读取完毕；</li>
<li>执行end语句块；</li>
</ol>
<h3 id="print_打印当前行">print 打印当前行</h3><p>使用不带参数的print时，会打印当前行;</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"line1nline2"</span> | awk 'BEGIN{<span class="keyword">print</span> <span class="string">"start"</span>} {<span class="keyword">print</span> } END{ <span class="keyword">print</span> <span class="string">"End"</span> }'
</code></pre><p>print 以逗号分割时，参数以空格定界;</p>
<pre><code>echo <span class="string">| awk ' {var1 = "</span>v1<span class="string">" ; var2 = "</span>V2<span class="string">"; var3="</span>v3<span class="string">"; </span>
print var1, var2 , var3; }'
$&gt;v1 V2 v3
</code></pre><p>使用-拼接符的方式;</p>
<pre><code>echo <span class="string">| awk ' {var1 = "</span>v1<span class="string">" ; var2 = "</span>V2<span class="string">"; var3="</span>v3<span class="string">"; </span>
print var1<span class="string">"-"</span>var2<span class="string">"-"</span>var3; }'
$&gt;v1-V2-v3
</code></pre><h3 id="特殊变量：NR_NF_$0_$1_$2">特殊变量：NR NF $0 $1 $2</h3><p>NR:表示记录数量，在执行过程中对应当前行号；<br>NF:表示字段数量，在执行过程总对应当前行的字段数；<br>$0:这个变量包含执行过程中当前行的文本内容；<br>$1:第一个字段的文本内容；<br>$2:第二个字段的文本内容；</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"line1 f2 f3n line2 n line 3"</span> | awk '{<span class="keyword">print</span> NR<span class="string">":"</span><span class="label">$0</span><span class="string">"-"</span><span class="label">$1</span><span class="string">"-"</span><span class="label">$2}</span>'
</code></pre><p>打印每一行的第二和第三个字段：</p>
<pre><code><span class="title">awk</span> <span class="string">'{print <span class="variable">$2</span>, <span class="variable">$3</span>}'</span> file
</code></pre><p>统计文件的行数：</p>
<pre><code>awk <span class="string">' END {print NR}'</span> <span class="keyword">file</span>
</code></pre><p>累加每一行的第一个字段：</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"1n 2n 3n 4n"</span> | awk 'BEGIN{num = 0 ;
<span class="keyword">print</span> <span class="string">"begin"</span>;} {<span class="keyword">sum</span> += <span class="label">$1</span>;} END {<span class="keyword">print</span> <span class="string">"=="</span>; <span class="keyword">print</span> <span class="keyword">sum</span> }'
</code></pre><h3 id="传递外部变量">传递外部变量</h3><pre><code><span class="keyword">var</span>=<span class="number">1000</span>
echo | awk <span class="string">'{print vara}'</span> vara=$<span class="keyword">var</span> 
<span class="preprocessor">#  输入来自stdin</span>
awk <span class="string">'{print vara}'</span> vara=$<span class="keyword">var</span> file 
<span class="preprocessor"># 输入来自文件</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/19/linux-shell-skill/" data-id="cj3hb061e00283cfhskz459r0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/">shell</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spark-learn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/23/spark-learn/" class="article-date">
  <time datetime="2016-02-23T13:50:37.000Z" itemprop="datePublished">2016-02-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/23/spark-learn/">Spark学习记录</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本笔记主要记录Spark在Hadoop环境中使用python语言进行算法开发过程中遇到的问题</p>
<h3 id="Spark的启动">Spark的启动</h3><p>在Spark的安装路径中的<code>bin</code>路径中有pyspark，这是一种交互式的调用方法，还可以编写好python脚本之后通过</p>
<pre><code><span class="label">spark</span>-<span class="keyword">submit </span>xxx.py
</code></pre><p>的方式来调用。</p>
<h3 id="sc_is_not_defined">sc is not defined</h3><p>任何Spark程序都需要一个SparkContext来开始，其包含了Spark集群配置的各种参数，如果代码报错<code>sc is not defined</code>，需要添加如下代码进行初始化：</p>
<pre><code>from pyspark import SparkContext
sc = <span class="function"><span class="title">SparkContext</span><span class="params">(<span class="string">'local[2]'</span>, <span class="string">'First Spark App'</span>)</span></span>
</code></pre><h3 id="常用HDFS_Shell命令">常用HDFS Shell命令</h3><p>大多数FS Shell命令和对应的Unix Shell命令类似，格式为hadoop fs <args>，如下：</args></p>
<pre><code>hadoop <span class="built_in">fs</span> -cat URI [URI …]
hadoop <span class="built_in">fs</span> -chmod [-R] &lt;<span class="built_in">MODE</span>[,<span class="built_in">MODE</span>]... | OCTALMODE&gt; URI [URI …]
hadoop <span class="built_in">fs</span> -cp URI [URI …] &lt;dest&gt;
hadoop <span class="built_in">fs</span> -du URI [URI …]
hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span> &lt;paths&gt;
hadoop <span class="built_in">fs</span> -ls &lt;args&gt;
hadoop <span class="built_in">fs</span> -rmr URI [URI …]    # rm -rf
</code></pre><p>在HDFS和本地之间复制文件的命令如下：</p>
<pre><code>hadoop fs -get [-ignorecrc] [-crc] <span class="variable">&lt;src&gt;</span> <span class="variable">&lt;localdst&gt;</span>    <span class="comment"># 复制文件到本地文件系统</span>
hadoop fs -put <span class="variable">&lt;localsrc&gt;</span> <span class="variable">&lt;dst&gt;</span>    <span class="comment"># 本地文件复制到HDFS</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/23/spark-learn/" data-id="cj3hb05yf001k3cfhhh7tubay" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ml-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/18/ml-skill/" class="article-date">
  <time datetime="2016-02-18T13:23:36.000Z" itemprop="datePublished">2016-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/18/ml-skill/">机器学习技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="SVM_vs_Logistic_Regression">SVM vs Logistic Regression</h3><ol>
<li>逻辑回归和线性核SVM本质上其实没啥区别；</li>
<li>特征数大于样本数或者二者数量相当时，逻辑回归或者线性核SVM会有比较好的效果；</li>
<li>特征数较少，样本数一般多时，高斯核SVM会有比较好的效果；</li>
<li>特征少，样本特别多时，构建更多的特征，然后用逻辑回归或者线性核SVM</li>
</ol>
<h3 id="调参技巧">调参技巧</h3><p>解决测试误差较大的办法</p>
<ol>
<li>增加训练样本 -&gt; 降低方差</li>
<li>减少特征数量 -&gt; 降低方差</li>
<li>增加新特征 -&gt; 降低偏差</li>
<li>现有特征多项式组合(x1^2, x2^2, x1*x2等等) -&gt; 降低偏差</li>
<li>降低正则λ -&gt; 降低偏差</li>
<li>增加正则λ -&gt; 降低方差</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/18/ml-skill/" data-id="cj3hb060n00243cfh07vj6zvn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/18/python-skill/" class="article-date">
  <time datetime="2016-02-18T13:21:09.000Z" itemprop="datePublished">2016-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/18/python-skill/">python技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="查看运行时间">查看运行时间</h2><p>用ipython的run命令做profiling，找出耗时语句</p>
<pre><code><span class="built_in">run</span> <span class="bash">-p xxx.py</span>
</code></pre><h2 id="ipynb文件">ipynb文件</h2><p>ipynb文件是用浏览器演示python交互的优良插件，可以提供运行代码，插图，文章说明，插入公式等多种功能。<br>只需在含有ipynb文件的的父目录位置执行</p>
<pre><code><span class="title">ipython</span> notebook
</code></pre><p>即可生成shell服务器端，浏览器作为客户端展示出来。</p>
<h2 id="内存优化">内存优化</h2><p>及时释放内存。大数组使用完之后，手动del释放array。注意所有对数组的引用都del之后，数组才会被del。这些引用包括A[2:]这样的view。<br>尽量重用内存，比如：</p>
<pre><code>A = <span class="keyword">B </span>+ C # <span class="keyword">B </span>is neverused later
</code></pre><p>可以改写成</p>
<pre><code><span class="constant">B</span> += C
<span class="constant">A</span> = B
</code></pre><h2 id="py2exe">py2exe</h2><p>windows环境把python脚步打包成可执行程序，安装py2exe。注意使用pip install安装只能支持python3版本，要想在python2.7环境下使用py2exe，要在这里下载<a href="https://sourceforge.net/projects/py2exe/files/py2exe/0.6.9/py2exe-0.6.9.win32-py2.7.exe/download" target="_blank" rel="external">py2exe-0.6.9.win32-py2.7.exe</a></p>
<p>在脚步所在目录下新建一个<code>setup.py</code>文件，加入</p>
<pre><code>from distutils<span class="class">.core</span> import setup
import py2exe

<span class="function"><span class="title">setup</span><span class="params">(windows = [<span class="string">'xxxxxx.py'</span>])</span></span>
</code></pre><p>然后执行</p>
<pre><code>python setup<span class="class">.py</span> py2exe
</code></pre><p>然后可执行程序以及相关依赖都会创建在dist文件夹，打包带走dist即可。</p>
<h2 id="random随机数模块">random随机数模块</h2><h3 id="random-random">random.random</h3><p>用于生成[0, 1.0)的随机浮点数</p>
<h3 id="random-uniform(a,_b)">random.uniform(a, b)</h3><p>生成[a, b]的随机浮点数</p>
<h3 id="random-randint(a,_b)">random.randint(a, b)</h3><p>生成[a, b]的随机整数</p>
<h3 id="random-choice(sequence)">random.choice(sequence)</h3><p>从sequence中随机得到一个元素</p>
<h3 id="random-shuffle(x[,_random])">random.shuffle(x[, random])</h3><p>用于将列表x元素打乱顺序</p>
<h3 id="random-sample(sequence,_k)">random.sample(sequence, k)</h3><p>从指定序列中随机获取长度k的片段，不改变原有序列</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/18/python-skill/" data-id="cj3hb05zf001t3cfhnleg1xu6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-linux-c-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/18/linux-c-skill/" class="article-date">
  <time datetime="2016-01-18T14:07:18.000Z" itemprop="datePublished">2016-01-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/18/linux-c-skill/">Linux c/c++ 技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="遍历目录内文件">遍历目录内文件</h2><p>Linux下的dirent.h头文件是专门为了获取文件夹目录内容而设计的结构体。使用示例如下：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span>

<span class="function"><span class="keyword">void</span> <span class="title">List</span><span class="params">(<span class="keyword">char</span>* path, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; files)</span>
</span>{
    <span class="keyword">struct</span> dirent* ent = <span class="literal">NULL</span>;
    DIR* pDir;
    <span class="keyword">char</span> dir[<span class="number">512</span>];
    <span class="keyword">struct</span> stat statbuf;  
    <span class="keyword">if</span> ( (pDir=opendir(path))==<span class="literal">NULL</span> )
    {
    <span class="built_in">fprintf</span>( <span class="built_in">stderr</span>, <span class="string">"Cannot open directory:%s\n"</span>, path );
        <span class="keyword">return</span>;
    }
    <span class="keyword">while</span>( (ent=readdir(pDir)) != <span class="literal">NULL</span> )
    {
        <span class="comment">//得到读取文件的绝对路径名</span>
        <span class="built_in">snprintf</span>(dir, <span class="number">512</span>, <span class="string">"%s/%s"</span>, path, ent-&gt;d_name);   
        <span class="comment">//得到文件信息</span>
        lstat(dir, &amp;statbuf);
        <span class="comment">//判断是目录还是文件</span>
        <span class="keyword">if</span> ( S_ISDIR(statbuf.st_mode) )
        {
            <span class="comment">//排除当前目录和上级目录</span>
            <span class="keyword">if</span> (<span class="built_in">strcmp</span>(<span class="string">"."</span>,ent-&gt;d_name) == <span class="number">0</span> || <span class="built_in">strcmp</span>( <span class="string">".."</span>,ent-&gt;d_name) == <span class="number">0</span>) 
                <span class="keyword">continue</span>;
            <span class="comment">//如果是子目录,递归调用函数本身,实现子目录中文件遍历</span>
            <span class="built_in">printf</span>( <span class="string">"子目录:%s/\n"</span>, ent-&gt;d_name );
            <span class="comment">//递归调用,遍历子目录中文件</span>
            <span class="comment">//List(dir);</span>
        }
        <span class="keyword">else</span>
        {
            <span class="built_in">printf</span>( <span class="string">"文件:%s\n"</span>, ent-&gt;d_name );
            files.push_back(pathName.assign(path).append(<span class="string">"/"</span>).append(ent-&gt;d_name));
        }       
    }
    closedir(pDir);
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/18/linux-c-skill/" data-id="cj3hb061r002c3cfhhskjssxs" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c-c/">c/c++</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-book-list" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/12/book-list/" class="article-date">
  <time datetime="2016-01-12T13:07:43.000Z" itemprop="datePublished">2016-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/12/book-list/">书单</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="想买的">想买的</h1><h2 id="《Effective_C++中文版》">《Effective C++中文版》</h2><p><img src="http://img13.360buyimg.com/n1/14692/6d94eb5a-75ba-4b73-b38c-e1ceb33532fc.jpg" alt="effective C++"></p>
<h2 id="《numpy攻略》">《numpy攻略》</h2><p><img src="http://img12.360buyimg.com/n1/jfs/t268/69/1040716404/165584/e6ce3de/53f55c58N3719acaa.jpg" alt="numpy攻略"></p>
<h2 id="《Python_Cookbook》">《Python Cookbook》</h2><p><img src="http://img11.360buyimg.com/n1/jfs/t1210/198/742186232/357507/4f64f545/55407ebbNc012ae29.jpg" alt="Python Cookbook"></p>
<h1 id="英文版的">英文版的</h1><h2 id="《OpenCV_3_Blueprints》">《OpenCV 3 Blueprints》</h2><p><img src="http://ww3.sinaimg.cn/bmiddle/5396ee05jw1ezcnc1rnnqj205n06ydgk.jpg" alt="OpenCV 3 Blueprints"></p>
<h2 id="《Raspberry_Pi_Computer_Vision_Programming》">《Raspberry Pi Computer Vision Programming》</h2><p><img src="http://ww1.sinaimg.cn/bmiddle/5396ee05gw1eyy009xemuj206807oq3g.jpg" alt="Raspberry Pi Computer Vision Programming"></p>
<h2 id="《Web_Scraping_with_Python_-_Collecting_Data_from_the_Modern_Web》">《Web Scraping with Python - Collecting Data from the Modern Web》</h2><p><img src="http://ww1.sinaimg.cn/bmiddle/5396ee05jw1euxumch0dfj20ai0dv75n.jpg" alt="Web Scraping with Python - Collecting Data from the Modern Web"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/12/book-list/" data-id="cj3hb069r00423cfh9ahsaiht" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/source/">source</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-adusting-parameter" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/06/adusting-parameter/" class="article-date">
  <time datetime="2015-12-06T02:17:08.000Z" itemprop="datePublished">2015-12-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/06/adusting-parameter/">深度学习调参技巧笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="cnn技巧">cnn技巧</h2><p>南大有个哥们写了一个技巧集合，很不错，推荐给大家<a href="http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html" target="_blank" rel="external">http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html</a></p>
<h2 id="网络训练技巧">网络训练技巧</h2><p>1：准备数据：务必保证有大量、高质量并且带有干净标签的数据，没有如此的数据，学习是不可能的<br>2：预处理：这个不多说，就是0均值和1方差化<br>3：minibatch：建议值128,1最好，但是效率不高，但是千万不要用过大的数值，否则很容易过拟合<br>4：梯度归一化：其实就是计算出来梯度之后，要除以minibatch的数量。这个不多解释<br>5：下面主要集中说下学习率<br>5.1：总的来说是用一个一般的学习率开始，然后逐渐的减小它<br>5.2：一个建议值是0.1，适用于很多NN的问题，一般倾向于小一点。<br>5.3：一个对于调度学习率的建议：如果在验证集上性能不再增加就让学习率除以2或者5，然后继续，学习率会一直变得很小，到最后就可以停止训练了。<br>5.4：很多人用的一个设计学习率的原则就是监测一个比率（每次更新梯度的norm除以当前weight的norm），如果这个比率在10-3附近，如果小于这个值，学习会很慢，如果大于这个值，那么学习很不稳定，由此会带来失败。<br>6：使用验证集，可以知道什么时候开始降低学习率，和什么时候停止训练。<br>7：关于对weight初始化的选择的一些建议：<br>7.1：如果你很懒，直接用0.02*randn(num_params)来初始化，当然别的值你也可以去尝试<br>7.2：如果上面那个不太好使，那么久依次初始化每一个weight矩阵用<code>init_scale / sqrt(layer_width) * randn</code>,init_scale可以被设置为0.1或者1<br>7.3：初始化参数对结果的影响至关重要，要引起重视。<br>7.4：在深度网络中，随机初始化权重，使用SGD的话一般处理的都不好，这是因为初始化的权重太小了。这种情况下对于浅层网络有效，但是当足够深的时候就不行了，因为weight更新的时候，是靠很多weight相乘的，越乘越小，有点类似梯度消失的意思<br>8：如果训练RNN或者LSTM，务必保证gradient的norm被约束在15或者5（前提还是要先归一化gradient），这一点在RNN和LSTM中很重要。<br>9：检查下梯度，如果是你自己计算的梯度。<br>10：如果使用LSTM来解决长时依赖的问题，记得初始化bias的时候要大一点<br>12：尽可能想办法多的扩增训练数据，如果使用的是图像数据，不妨对图像做一点扭转啊之类的，来扩充数据训练集合。<br>13：使用dropout。大的网络使用dropout，小网络使用dropout训练很慢，而且不容易收敛<br>14：评价最终结果的时候，多做几次，然后平均一下他们的结果。</p>
<h2 id="参考资料">参考资料</h2><p><a href="https://www.zhihu.com/question/41631631" target="_blank" rel="external">知乎：你有哪些deep learning（rnn、cnn）调参的经验？</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/12/06/adusting-parameter/" data-id="cj3hb05n500003cfhbb6s6bd3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tricks/">tricks</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-dataset-cv" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/05/dataset-cv/" class="article-date">
  <time datetime="2015-11-05T14:23:30.000Z" itemprop="datePublished">2015-11-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/05/dataset-cv/">Computer Vision DataSet资源列表</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>俗话说，“算法为王，数据为后”。巧妇难为无米之炊，可见再优秀的算法也得有数据支持。这篇就用来记录我用过的数据集，以备不时之需。</p>
<h1 id="数据集汇总">数据集汇总</h1><p><a href="http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm</a><br><a href="http://visionandlanguage.net/" target="_blank" rel="external">http://visionandlanguage.net/</a><br><a href="http://riemenschneider.hayko.at/vision/dataset/" target="_blank" rel="external">http://riemenschneider.hayko.at/vision/dataset/</a></p>
<h1 id="物体">物体</h1><h3 id="INSTRE:_for_INSTance-level_object_REtrieval_and_REcognition">INSTRE: for INSTance-level object REtrieval and REcognition</h3><p><a href="http://vipl.ict.ac.cn/isia/instre/" target="_blank" rel="external">http://vipl.ict.ac.cn/isia/instre/</a><br>(中科院计算所)新的图像数据集（共计28,543幅图像，100个类），用于验证实例级对象检索、识别算法及其他机器视觉算法，如检测、不变特征和特征匹配等</p>
<h1 id="LOGO图">LOGO图</h1><h3 id="Dataset:_FlickrLogos-32">Dataset: FlickrLogos-32</h3><p><a href="http://www.multimedia-computing.de/flickrlogos/" target="_blank" rel="external">http://www.multimedia-computing.de/flickrlogos/</a><br>2011年公布的一个数据集，包含32类知名商标品牌的logo。</p>
<h1 id="动植物图像">动植物图像</h1><h3 id="水果FIDS30:_Fruit_Image_Data_set">水果FIDS30: Fruit Image Data set</h3><p><a href="http://www.vicos.si/Downloads/FIDS30" target="_blank" rel="external">http://www.vicos.si/Downloads/FIDS30</a><br>2014年公布的水果图片集，包含971张图片，覆盖30种不同的水果</p>
<h3 id="鲜花102_Category_Flower_Dataset">鲜花102 Category Flower Dataset</h3><p><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html" target="_blank" rel="external">http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html</a><br>牛津大学vgg组2009年搞的花卉图片，包含102类花卉8189张图片，对应标签<code>imagelabels.mat</code></p>
<h3 id="植物图像库">植物图像库</h3><p><a href="http://www.plantphoto.cn/" target="_blank" rel="external">http://www.plantphoto.cn/</a><br>收录图片208万幅，1.86万种</p>
<h1 id="人脸">人脸</h1><h3 id="CelebA:_Large-scale_CelebFaces_Attributes_(CelebA)_Dataset">CelebA: Large-scale CelebFaces Attributes (CelebA) Dataset</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a><br>香港中文大学组2015年搞的一个最新的目前最大的人脸集，包含10177个人，202599张人脸图片，而且每张图片有5个关键点标注信息以及40个2值属性，属性包括是否带眼睛，是否在笑，是否带帽子，是不是卷发，是否年轻，性别等等，是非常珍贵的人脸数据。</p>
<h3 id="WIDER_FACE:_A_Face_Detection_Benchmark">WIDER FACE: A Face Detection Benchmark</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/</a><br>香港中文大学再放大招，2015年11月又推出人脸检测标注数据库，包含32203张图片，393703张人脸。其中50%的测试数据集并没有公开标注信息。</p>
<h3 id="IMDB-WIKI">IMDB-WIKI</h3><p><a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/" target="_blank" rel="external">https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/</a><br>有人脸位置、性别、年龄的标注信息，共52万的标注图片</p>
<h3 id="CASIA_WebFace_Database">CASIA WebFace Database</h3><p><a href="http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html" target="_blank" rel="external">http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html</a><br>10,575 subjects and 494,414 images</p>
<h3 id="Labeled_Faces_in_the_Wild">Labeled Faces in the Wild</h3><p><a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="external">http://vis-www.cs.umass.edu/lfw/</a><br>13,000 images and 5749 subjects</p>
<h3 id="MSRA-CFW">MSRA-CFW</h3><p><a href="http://research.microsoft.com/en-us/projects/msra-cfw/" target="_blank" rel="external">http://research.microsoft.com/en-us/projects/msra-cfw/</a><br>202,792 images and 1,583 subjects.</p>
<h3 id="MegaFace_Dataset">MegaFace Dataset</h3><p><a href="http://megaface.cs.washington.edu" target="_blank" rel="external">http://megaface.cs.washington.edu</a><br>1 Million Faces for Recognition at Scale 690,572 unique people</p>
<h3 id="FaceScrub">FaceScrub</h3><p><a href="http://vintage.winklerbros.net/facescrub.html" target="_blank" rel="external">http://vintage.winklerbros.net/facescrub.html</a><br>A Dataset With Over 100,000 Face Images of 530 People.</p>
<h3 id="FDDB">FDDB</h3><p><a href="http://vis-www.cs.umass.edu/fddb" target="_blank" rel="external">http://vis-www.cs.umass.edu/fddb</a><br>Face Detection and Data Set Benchmark. 5k images.</p>
<h3 id="AFLW">AFLW</h3><p><a href="https://lrs.icg.tugraz.at/research/aflw/" target="_blank" rel="external">https://lrs.icg.tugraz.at/research/aflw/</a><br>Annotated Facial Landmarks in the Wild: A Large-scale, Real-world Database for Facial Landmark Localization. 25k images.</p>
<h3 id="AFW">AFW</h3><p><a href="http://www.ics.uci.edu/~xzhu/face/" target="_blank" rel="external">http://www.ics.uci.edu/~xzhu/face/</a><br>Annotated Faces in the Wild. ~1k images.</p>
<h3 id="3D_Mask_Attack_Dataset]">3D Mask Attack Dataset]</h3><p><a href="https://www.idiap.ch/dataset/3dmad" target="_blank" rel="external">https://www.idiap.ch/dataset/3dmad</a><br>76500 frames of 17 persons using Kinect RGBD with eye positions (Sebastien Marcel)</p>
<h3 id="Audio-visual_database_for_face_and_speaker_recognition">Audio-visual database for face and speaker recognition</h3><p><a href="https://www.idiap.ch/dataset/mobio" target="_blank" rel="external">https://www.idiap.ch/dataset/mobio</a><br>Mobile Biometry MOBIO <a href="http://www.mobioproject.org/" target="_blank" rel="external">http://www.mobioproject.org/</a></p>
<h3 id="BANCA_face_and_voice_database">BANCA face and voice database</h3><p><a href="http://www.ee.surrey.ac.uk/CVSSP/banca/" target="_blank" rel="external">http://www.ee.surrey.ac.uk/CVSSP/banca/</a><br>Univ of Surrey</p>
<h3 id="Binghampton_Univ_3D_static_and_dynamic_facial_expression_database">Binghampton Univ 3D static and dynamic facial expression database</h3><p><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html" target="_blank" rel="external">http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html</a><br>(Lijun Yin, Peter Gerhardstein and teammates)</p>
<h3 id="The_BioID_Face_Database">The BioID Face Database</h3><p><a href="https://www.bioid.com/About/BioID-Face-Database" target="_blank" rel="external">https://www.bioid.com/About/BioID-Face-Database</a><br>BioID group</p>
<h3 id="Biwi_3D_Audiovisual_Corpus_of_Affective_Communication">Biwi 3D Audiovisual Corpus of Affective Communication</h3><p><a href="http://www.vision.ee.ethz.ch/datasets/b3dac2.en.html" target="_blank" rel="external">http://www.vision.ee.ethz.ch/datasets/b3dac2.en.html</a><br>1000 high quality, dynamic 3D scans of faces, recorded while pronouncing a set of English sentences.</p>
<h3 id="Cohn-Kanade_AU-Coded_Expression_Database">Cohn-Kanade AU-Coded Expression Database</h3><p><a href="http://www.pitt.edu/~emotion/ck-spread.htm" target="_blank" rel="external">http://www.pitt.edu/~emotion/ck-spread.htm</a><br>500+ expression sequences of 100+ subjects, coded by activated Action Units (Affect Analysis Group, Univ. of Pittsburgh.</p>
<h3 id="CMU/MIT_Frontal_Faces">CMU/MIT Frontal Faces</h3><p><a href="http://cbcl.mit.edu/software-datasets/FaceData2.html" target="_blank" rel="external">http://cbcl.mit.edu/software-datasets/FaceData2.html</a><br>Training set:  2,429 faces, 4,548 non-faces; Test set: 472 faces, 23,573 non-faces.</p>
<h3 id="kaggle表情数据">kaggle表情数据</h3><p><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" target="_blank" rel="external">https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data</a><br>人脸表情数据集，7种表情(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)，训练集28709张图片，测试集3589张，像素48*48</p>
<h3 id="人脸素描数据集">人脸素描数据集</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html</a><br>606张人脸的素描和证件照的一一对应图像</p>
<h1 id="汽车">汽车</h1><h3 id="KITTI_Vision_Benchmark">KITTI Vision Benchmark</h3><p><a href="http://www.cvlibs.net/datasets/kitti/index.php" target="_blank" rel="external">http://www.cvlibs.net/datasets/kitti/index.php</a><br>这个就厉害了，包括车载环境的机动车、非机动车、行人以及车道等多方面的标注信息。用于专业的车辆辅助驾驶的检测算法测评。</p>
<h3 id="CompCars:_The_comprehensive_cars_dataset">CompCars: The comprehensive cars dataset</h3><p><a href="http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html" target="_blank" rel="external">http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html</a></p>
<h1 id="图像知识图谱">图像知识图谱</h1><h3 id="Visual_Genome">Visual Genome</h3><p><a href="https://visualgenome.org/" target="_blank" rel="external">https://visualgenome.org/</a><br>100K+图像，400万区域描述，170万图像问答，210万物体，180万的属性和关系，所有都映射到Wordnet Synsets</p>
<h1 id="OCR">OCR</h1><h3 id="COCO-TEXT">COCO-TEXT</h3><p><a href="http://vision.cornell.edu/se3/coco-text/" target="_blank" rel="external">http://vision.cornell.edu/se3/coco-text/</a><br>该数据库含63686张图像，123589个文本区域及标注（位置、手写/印刷等属性、语言、可辨识性、文本）</p>
<h1 id="视频">视频</h1><h3 id="ActivityNet">ActivityNet</h3><p><a href="http://activity-net.org/" target="_blank" rel="external">http://activity-net.org/</a><br>人类活动理解建模，200个类和2万个训练/调试/测试视频</p>
<h3 id="WWW_Crowd">WWW Crowd</h3><p><a href="http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html" target="_blank" rel="external">http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html</a><br>10000个视频、8257种不同场景、超过800万帧图像。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/11/05/dataset-cv/" data-id="cj3hb062g002v3cfhuboh1o9x" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dataset/">dataset</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-dlib-face-detect" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/04/dlib-face-detect/" class="article-date">
  <time datetime="2015-11-04T13:53:46.000Z" itemprop="datePublished">2015-11-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/04/dlib-face-detect/">基于dlib的人脸检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>dlib的人脸检测模块要比OpenCV的效果好一些，归功于其使用的是HOG特征。</p>
<h2 id="dlib安装">dlib安装</h2><p>在windows下我的环境是vs2013和cmake3.2，cmake版本低了会导致编译失败。下载dlib的zip包，然后解压，然后执行如下，就把c++和python的配置好了。注意其中的CMakeLists.txt文件中的OpenCV宏与新版本的OpenCV不相配，需要改成OpenCV REQUIRED，否则<code>webcam_face_pose_ex</code>这个与摄像头有关的模块不会执行成功。</p>
<pre><code>cd examples
vim CMakeLists.txt
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">####[open CMakeList.txt]
# find_package(OpenCV) --&gt;
find_package(OpenCV REQUIRED)
###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">#[close CMakeList.txt]</span>
mkdir build
cd build
cmake .. -DUSE_AVX_INSTRUCTIONS=ON
cmake --build . --config Release
cd ..<span class="regexp">/../</span>
python setup.py install --<span class="literal">yes</span> USE_AVX_INSTRUCTIONS <span class="comment"># AVX为object detector的加速开关</span>
</code></pre><h2 id="人脸检测demo">人脸检测demo</h2><p>在<code>exmaples/faces</code>文件夹下面新建文件<code>face_detector.py</code>，根据官网例程添加代码：</p>
<pre><code>import sys

import dlib
from skimage import io

detector = dlib.get_frontal_face_detector()
<span class="keyword">win</span> = dlib.image_window()

<span class="keyword">for</span> f <span class="keyword">in</span> sys.argv[1:]:
    <span class="keyword">print</span>(<span class="string">"Processing file: {}"</span>.<span class="keyword">format</span>(f))
    img = io.imread(f)
    # The 1 <span class="keyword">in</span> the second argument indicates that we should upsample the image
    # 1 time.  This will make everything bigger and allow <span class="keyword">us</span> to detect <span class="keyword">more</span>
    # faces.
    dets = detector(img, 1)
    <span class="keyword">print</span>(<span class="string">"Number of faces detected: {}"</span>.<span class="keyword">format</span>(len(dets)))
    <span class="keyword">for</span> i, <span class="keyword">d</span> <span class="keyword">in</span> enumerate(dets):
        <span class="keyword">print</span>(<span class="string">"Detection {}: Left: {} Top: {} Right: {} Bottom: {}"</span>.<span class="keyword">format</span>(
            i, <span class="keyword">d</span>.left(), <span class="keyword">d</span>.top(), <span class="keyword">d</span>.right(), <span class="keyword">d</span>.bottom()))

    <span class="keyword">win</span>.clear_overlay()
    <span class="keyword">win</span>.set_image(img)
    <span class="keyword">win</span>.add_overlay(dets)
    dlib.hit_enter_to_continue()


# Finally, <span class="keyword">if</span> you really want to you can ask the detector to tell you the <span class="keyword">score</span>
# <span class="keyword">for</span> each detection.  The <span class="keyword">score</span> is bigger <span class="keyword">for</span> <span class="keyword">more</span> confident detections.
# Also, the idx tells you <span class="keyword">which</span> of the face sub-detectors matched.  This can be
# used to broadly identify faces <span class="keyword">in</span> different orientations.
<span class="keyword">if</span> (len(sys.argv[1:]) &gt; 0):
    img = io.imread(sys.argv[1])
    dets, scores, idx = detector.<span class="keyword">run</span>(img, 1)
    <span class="keyword">for</span> i, <span class="keyword">d</span> <span class="keyword">in</span> enumerate(dets):
        <span class="keyword">print</span>(<span class="string">"Detection {}, score: {}, face_type:{}"</span>.<span class="keyword">format</span>(
            <span class="keyword">d</span>, scores[i], idx[i]))
</code></pre><p>然后执行如下命令即可看到人脸检测效果：</p>
<pre><code><span class="tag">python</span> <span class="tag">face_detector</span><span class="class">.py</span> *<span class="class">.jpg</span>
</code></pre><h2 id="补充">补充</h2><p>C++环境也是一样的，执行<code>cmake build</code>后在<code>examples/build</code>目录下生成可执行文件<code>face_detection_ex</code>，执行</p>
<pre><code><span class="title">face_detection_ex</span> ../faces/<span class="regexp">*.jpg</span>
</code></pre><p>注意<strong>C++接口要想得到矩形框对应的置信度的话也是可以的，也可以根据置信度设置矩形框筛选的阈值，默认阈值为0</strong>，下面为两种接口的函数声明：</p>
<pre><code><span class="keyword">template</span> &lt;
    <span class="keyword">typename</span> image_type
    &gt;
<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;rectangle&gt; <span class="keyword">operator</span>() (
    <span class="keyword">const</span> image_type&amp; img,
    <span class="keyword">double</span> adjust_threshold = <span class="number">0</span>
);

<span class="keyword">template</span> &lt;
    <span class="keyword">typename</span> image_type
    &gt;
<span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(
    <span class="keyword">const</span> image_type&amp; img,
    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">double</span>, rectangle&gt; &gt;&amp; final_dets,
    <span class="keyword">double</span> adjust_threshold = <span class="number">0</span>
)</span></span>;
</code></pre><h2 id="dlib的人脸关键点检测">dlib的人脸关键点检测</h2><p>下载文件<a href="http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" target="_blank" rel="external">http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2</a>解压后将<code>shape_predictor_68_face_landmarks.dat</code>放到<code>examples/build</code>目录，执行</p>
<pre><code><span class="tag">webcam_face_pose_ex</span> <span class="tag">shape_predictor_68_face_landmarks</span><span class="class">.dat</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/11/04/dlib-face-detect/" data-id="cj3hb062d002q3cfh60sikltp" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/face/">face</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-mxnet-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/10/09/mxnet-install/" class="article-date">
  <time datetime="2015-10-09T13:13:36.000Z" itemprop="datePublished">2015-10-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/10/09/mxnet-install/">mxnet学习（一） mxnet + CentOS 7安装配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>mxnet是最近DMLC那群牛人搞的一个开源的深度学习库，可以看作是cxxnet的升级版本，其中到底的美妙还是慢慢专研感受，话不多说，先跑起来看看。整个学习系列都是参考<a href="http://mxnet.readthedocs.org/en/latest/index.html" target="_blank" rel="external">http://mxnet.readthedocs.org/en/latest/index.html</a>学习完成的。</p>
<h2 id="相关开发环境的配置">相关开发环境的配置</h2><p>系统的检测以及python的安装都是基本的，主要依赖软件是CUDA、intel mkl以及OpenCV的安装配置，具体可以参考之前写的<a href="http://yangxian10.github.io/2015/08/18/caffe-setup2/" target="_blank" rel="external">caffe学习（三）caffe + centOS 7 + CUDA 7配置</a>，已经写的很详细了，这里就不再多言。mxnet不像caffe那样依赖众多的google的工具库，这一点还是必须点赞的（caffe安装坑太多了）</p>
<h2 id="安装mxnet">安装mxnet</h2><pre><code>git clone --recursive http<span class="variable">s:</span>//github.<span class="keyword">com</span>/dmlc/mxnet
<span class="keyword">cd</span> mxnet/<span class="keyword">make</span>
<span class="keyword">cp</span> config.<span class="keyword">mk</span> config.<span class="keyword">mk</span>.bak
<span class="keyword">vim</span> config.<span class="keyword">mk</span>
################# <span class="keyword">open</span>[config.<span class="keyword">mk</span>]
USE_CUDA = <span class="number">1</span>
USE_CUDA_PATH = /usr/local/cuda
USE_BLAS = mkl
USE_INTEL_PATH = /<span class="keyword">opt</span>/intel/
################# <span class="keyword">close</span>[config.<span class="keyword">mk</span>]
<span class="keyword">cd</span> ..
<span class="keyword">make</span> -j4
<span class="keyword">cd</span> <span class="keyword">python</span>
<span class="keyword">python</span> setup.<span class="keyword">py</span> install
<span class="keyword">cd</span> ..
</code></pre><p>测试mxnet是否安装ok</p>
<pre><code><span class="keyword">python</span> example/mnist/mlp.<span class="keyword">py</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/10/09/mxnet-install/" data-id="cj3hb060700203cfhflwcraly" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mxnet/">mxnet</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-fine-tuning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/15/caffe-fine-tuning/" class="article-date">
  <time datetime="2015-09-15T14:10:22.000Z" itemprop="datePublished">2015-09-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/15/caffe-fine-tuning/">caffe学习（五）fine-tuning已有模型到新数据</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="概述">概述</h2><p>最近试了一个新的数据集，由于每一类别训练数据较少，算法无法收敛。于是尝试使用fine-tuning，利用已有训练模型权重参数适应到新的数据集。</p>
<p>由于我们新的分类器与之前的分类器都采用googLeNet的框架，只是在最后一层由3000个类别增加到60000类，所以需要更改最后一层的参数，把原来的<code>loss3/classifier</code>层改成新名字<code>loss3/classifier/fn</code>，这样由于在原来的模型中找不到这层的名字，这层在训练的时候会用随机变量赋初始值重新训练。</p>
<p>由于原来模型已经收敛，在fine-tuning时候要把<code>base_lr</code>更新学习率降低，同时增加<code>blobs_lr</code>在新的层上，让其他层的参数在新数据来的时候慢点更新，同时让新的层快速学习。同时<code>stepsize</code>参数也适当减少，从而让学习率下降的更快一些。</p>
<h2 id="具体步骤">具体步骤</h2><h3 id="数据准备">数据准备</h3><p>这个没啥好说的，将新的训练数据分为train和valuation集，然后转换成lmdb格式，然后得到其均值文件，准备完毕。</p>
<h3 id="train_val-prototxt">train_val.prototxt</h3><ul>
<li>data-layer里的train和test均值文件和训练数据源要设置正确</li>
<li>loss1/classifier-layer层的name改为<code>loss1/classifier/fn</code>，top参数<code>loss1/classifier/fn</code>，lr_mult参数乘10倍，由原来的1和2改为10和20，num_output改为60000</li>
<li>loss1/loss的softmax层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>loss1/top-1的accuracy层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>loss1/top-5的accuracy层的bottom参数改为<code>loss1/classifier/fn</code></li>
<li>上述4个步骤的参数修改同时也要应用到loss2和loss3层中</li>
</ul>
<h3 id="solver-prototxt">solver.prototxt</h3><ul>
<li>将<code>test_initialization</code>这句屏蔽掉</li>
<li>gamma改为0.1</li>
<li>weight_decay改为0.0005</li>
<li>base_lr参数降低10倍，改为0.001，这个改动最为重要</li>
</ul>
<h3 id="deploy-prototxt">deploy.prototxt</h3><ul>
<li>loss3/classifier-layer层的name改为<code>loss1/classifier/fn</code>，top参数<code>loss1/classifier/fn</code>，lr_mult参数乘10倍，由原来的1和2改为10和20，num_output改为60000</li>
<li>prob的softmax层的bottom参数改为<code>loss1/classifier/fn</code></li>
</ul>
<h3 id="调用接口">调用接口</h3><pre><code>../../build/tools/caffe train --solver=solver<span class="class">.prototxt</span> -weights sku3081_googlenet_quick_iter_900000<span class="class">.caffemodel</span> -gpu <span class="number">2</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/09/15/caffe-fine-tuning/" data-id="cj3hb068w003q3cfhczrmdp6d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-interface" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/23/caffe-interface/" class="article-date">
  <time datetime="2015-08-23T12:28:12.000Z" itemprop="datePublished">2015-08-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/23/caffe-interface/">caffe学习（四）caffe的接口参数说明</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>caffe接口参数</p>
<h2 id="C接口">C接口</h2><h3 id="train相关参数">train相关参数</h3><ul>
<li>-solver参数（必须有），与<code>solver.prototxt</code>文件一起使用</li>
<li>-snapshot参数（可选），通常用来从之前训练一半的模型<code>xxx.solverstate</code>继续训练使用</li>
<li>-weights参数（选填），与训练好的<code>model.caffemodel</code>一起使用，用来在fine-tuning的时候初始化参数</li>
<li>-gpu参数，用来选择使用GPU，根据<code>nvidia-smi</code>的GPU的ID选择，比如选择第三块GPU就使用<code>-gpu 2</code>的参数，如果想使用所有的GPU一起跑一个程序，就使用<code>-gpu all</code></li>
</ul>
<p>举个例子<br><!-- lang:bash--></p>
<pre><code># train LeNet
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt
# train on GPU <span class="number">2</span>
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt -gpu <span class="number">2</span>
# resume training <span class="keyword">from</span> the half-way point snapshot
caffe train -solver examples<span class="regexp">/mnist/</span>lenet_solver.prototxt -snapshot examples<span class="regexp">/mnist/</span>lenet_iter_5000.solverstate
# fine-tune CaffeNet model weights <span class="keyword">for</span> style recognition
caffe train -solver examples<span class="regexp">/finetuning_on_flickr_style/</span>solver.prototxt -weights models<span class="regexp">/bvlc_reference_caffenet/</span>bvlc_reference_caffenet.caffemodel
</code></pre><h3 id="test、time相关参数">test、time相关参数</h3><ul>
<li>-iterations迭代次数，time的时候测试的次数，默认为50次</li>
<li>-model测试时候选择加载的模型，对应<code>train_val.prototxt</code>或者<code>deploy.prototxt</code>一起使用</li>
</ul>
<p>举个例子<br><!-- lang:bash--></p>
<pre><code># score the learned LeNet model on the validation <span class="operator"><span class="keyword">set</span> <span class="keyword">as</span> defined <span class="keyword">in</span> the
# <span class="keyword">model</span> architeture lenet_train_test.prototxt
caffe <span class="keyword">test</span> -<span class="keyword">model</span> examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu <span class="number">0</span> -iterations <span class="number">100</span>
# <span class="keyword">time</span> a <span class="keyword">model</span> architecture <span class="keyword">with</span> the given weights <span class="keyword">on</span> the <span class="keyword">first</span> GPU <span class="keyword">for</span> <span class="number">10</span> iterations
caffe <span class="keyword">time</span> -<span class="keyword">model</span> examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu <span class="number">0</span> -iterations <span class="number">10</span></span>
</code></pre><h3 id="device_query相关参数">device_query相关参数</h3><p>这个模块用来查看多GPU时候的一些显卡相关信息。举例<br><!-- lang:bash--></p>
<pre><code><span class="comment"># query the first device</span>
<span class="title">caffe</span> device_query -gpu <span class="number">0</span>
</code></pre><h2 id="python接口">python接口</h2><p>通过<code>import caffe</code>来加载caffe模块，几个比较重要的模块caffe.Net, caffe.SDGSolver, caffe.io, caffe.draw</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/23/caffe-interface/" data-id="cj3hb068n003k3cfhbd6526qe" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-setup2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/18/caffe-setup2/" class="article-date">
  <time datetime="2015-08-18T15:22:33.000Z" itemprop="datePublished">2015-08-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/18/caffe-setup2/">caffe学习（三）caffe + centOS 7 + CUDA 7配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次全程记录centOS 7 的配置安装过程</p>
<h2 id="开发环境">开发环境</h2><p>虽然它这么好用，安装它可不是一个省心的事，最好的参考资料还是官网安装资料<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">http://caffe.berkeleyvision.org/installation.html</a>，配置之前先查看一下自己的软硬件环境</p>
<h3 id="dns配置">dns配置</h3><p>google之，不多介绍，注意centos 7的dns设置与之前的版本不同</p>
<h3 id="查看显卡">查看显卡</h3><p>我们的显卡是K40（没显卡也能玩caffe）,可以看到是4个k40m显卡。。。。我口水直流(<em>@ο@</em>) </p>
<pre><code>lspci <span class="string">|grep -i nvidia</span>
</code></pre><h3 id="查看linux版本">查看linux版本</h3><p>Linux服务器版本是centOS 7，查看服务器系统版本命令</p>
<pre><code>cat <span class="regexp">/etc/</span>redhat-release
</code></pre><h3 id="安装python">安装python</h3><p>python2.7升级到Anaconda版本<a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda-2.3.0-Linux-x86_64.sh" target="_blank" rel="external">Anaconda-2.3.0-Linux-x86_64.sh</a>下载后直接运行即可，numpy,scipy,scikit-learn等相关软件就都配置好了。记得生效一下环境变量<code>source ~/.bashrc</code>。Anaconda直接把python升级到2.7版本，同时安装好了所有相关依赖包，简直完美啊，解决了python多版本共存的问题，同时一键安装python和相关插件，并且配置好了相关环境变量，同时还是64位版本的python，强烈推荐。</p>
<h3 id="安装cmake">安装cmake</h3><p>再把cmake升级到2.8.12版本，centos 7 的yum只能升级到2.8.11版本</p>
<pre><code><span class="preprocessor"># 先安装依赖</span>
yum install gcc
yum install gcc-c++
<span class="preprocessor"># 下载安装包</span>
tar xvf cmake-<span class="number">2.8</span><span class="number">.12</span><span class="number">.1</span>.tar.gz
cd cmake-<span class="number">2.8</span><span class="number">.12</span><span class="number">.1</span>/
./configure
make
make install
vim /etc/profile
<span class="preprocessor">###########[profile末尾添加]</span>
PATH=/usr/local/cmake/bin:$PATH
<span class="keyword">export</span> PATH
<span class="preprocessor">#############关闭文件</span>
source /etc/profile
<span class="preprocessor">########查看是否安装好</span>
cmake --version
</code></pre><h2 id="安装CUDA和MKL">安装CUDA和MKL</h2><p>这两个商用软件安装相对容易</p>
<h3 id="CUDA_7">CUDA 7</h3><p>下载CUDA 7<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">https://developer.nvidia.com/cuda-downloads</a></p>
<pre><code>yum install kernel-devel
init <span class="number">3</span>         <span class="comment"># 关闭GUI</span>
./cuda_7.<span class="number">0.28_</span>linux.run
init <span class="number">5</span>         <span class="comment"># 开启GUI</span>
vim /etc/profile
<span class="comment">#############[profile]</span>
export <span class="constant">PATH</span>=<span class="variable">$PATH</span><span class="symbol">:/usr/local/cuda-</span><span class="number">7.0</span>/bin
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="variable">$LD_LIBRARY_PATH</span><span class="symbol">:/usr/local/cuda-</span><span class="number">7.0</span>/lib64
<span class="comment">#############[close profile]</span>
source /etc/profile
</code></pre><p>PS:目前我只在CentOS 7.0配置成功，在7.1和7.2版本会出现如下错误导致CUDA安装失败这里记录一下网上的解决方案：显卡驱动安装不成功，解决方法，先卸载系统已载入的显卡相关模块，同时指定kernel-source-path的路径，如下</p>
<pre><code>lsmod |grep nouveau <span class="preprocessor"># 发现存在相关模块</span>
modprobe -r nouveau <span class="preprocessor"># 卸载相关模块</span>
./cuda_7<span class="number">.0</span><span class="number">.28</span>_linux.run --kernel-source-path=<span class="string">"/usr/src/kernels/03.10.0-xxxxxx"</span>
</code></pre><p>根据caffe的官方最新提示，CUDA和显卡驱动最好分开安装，不然CUDA自带的显卡驱动不是最近版本，可能使用的时候会出问题，先装显卡驱动，去官网下载<a href="http://www.nvidia.com/download/driverResults.aspx/92135/en-us" target="_blank" rel="external">http://www.nvidia.com/download/driverResults.aspx/92135/en-us</a></p>
<pre><code>vim /<span class="class"><span class="keyword">lib</span>/<span class="title">modprobe</span>.<span class="title">d</span>/<span class="title">dist</span>-<span class="title">blacklist</span>.<span class="title">conf</span></span>
<span class="comment">########################[change]</span>
<span class="comment">#blacklist nvidiafb #注释掉nvidiafb，否则cuda安装报错nvidia.ko</span>
<span class="comment">########################[close]</span>
vim /etc/modprobe.d/blacklist-nouveau.conf
<span class="comment">########################[added]</span>
blacklist nouveau
options nouveau modeset=<span class="number">0</span>
<span class="comment">########################[close]</span>
dracut --force
mv /boot/initramfs-<span class="variable">$(</span>uname -r).img /boot/initramfs-<span class="variable">$(</span>uname -r).img.bak
dracut /boot/initramfs-<span class="variable">$(</span>uname -r).img <span class="variable">$(</span>uname -r)
</code></pre><p>init 3和init 5在最新的centOS里并不生效，取而代之的是graphical.target(5)和multi-user.target(3)。</p>
<pre><code>systemctl <span class="keyword">get</span>-default <span class="comment">#查看运行级别</span>
systemctl <span class="keyword">set</span>-default multi-user.target <span class="comment">#切换为文本模式</span>
reboot
./NVIDIA-XXXX.<span class="command">run</span> <span class="comment">--kernel-source-path=/usr/src/kernels/内核号 -k $(uname -r) #最后面的-k参数是可以解决bug: unable to load the kernel module 'nvidia.ko'</span>
</code></pre><p>接下来，验证CUDA是否安装好</p>
<pre><code>nvcc -V     <span class="comment"># 验证nvidia-CUDA-Toolkit是否安装好</span>
<span class="built_in">cd</span> ~/NVIDIA_CUDA-<span class="number">7.0</span>_Samples
make
<span class="built_in">cd</span> bin/x86_64/linux/release
./deviceQuery
</code></pre><p>从输出的信息就可以判断是否安装好CUDA</p>
<h3 id="intel_MKL">intel MKL</h3><p>下载intel MKL，解压后执行</p>
<pre><code>tar xzvf parallel_studio_xe_2015.tgz
cd parallel_studio_xe_2015
./install.sh
<span class="comment"># 偷偷记录一下自己的序列号SGZG-6NRGK57H</span>
vim /etc/ld.so.conf.d/intel_mkl.conf
<span class="comment">###############[intel_mkl.conf]</span>
/opt/intel/mkl/<span class="class"><span class="keyword">lib</span>/<span class="title">intel64</span></span>
<span class="comment">###############[close intel_mkl.conf]</span>
ldconfig
vim /etc/profile
<span class="comment">############[profile]</span>
export <span class="constant">LD_LIBRARY_PATH</span>=<span class="variable">$LD_LIBRARY_PATH</span><span class="symbol">:/opt/intel/mkl/lib</span> 
<span class="comment"># 或者直接把/opt/intel/mkl/lib copy到/usr/local/lib</span>
<span class="comment">############[close profile]</span>
source /etc/profile
</code></pre><h2 id="依赖库安装">依赖库安装</h2><h3 id="Install_protobuf">Install protobuf</h3><p>protobuf是谷歌开发的一种实现内存外存交换的协议接口，在这个统一的通讯协议下不同开发者可以使用自己喜欢的方式进行模型参数的管理。<br>上网下载protobuf2.6.1版本, anaconda的python对应的依赖包要求protobuf是2.6.1版本，弄错了是不行的。解压后，</p>
<pre><code>yum install autoconf automake libtool
tar xzvf protobuf-2.6.1.tar.gz
cd protobuf-2.6.1
<span class="keyword">.</span>/autogen.sh
<span class="keyword">.</span>/configure
make
make<span class="instruction"> check
</span>make install
</code></pre><p>或者直接<code>pip install protobuf</code>，发现版本刚好也是2.6.1</p>
<h3 id="Install_boost">Install boost</h3><p>anaconda没有包含boost，anaconda要求的boost版本为1.57</p>
<pre><code># download <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">tar</span> xvf <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">cd</span> <span class="keyword">boost_1_57_0
</span>./<span class="keyword">bootstrap.sh
</span>./<span class="keyword">b2
</span>./<span class="keyword">b2 </span>install
</code></pre><h3 id="Install_leveldb">Install leveldb</h3><pre><code>pip install leveldb
<span class="preprocessor"># git clone https://github.com/google/leveldb.git</span>
<span class="preprocessor"># cd leveldb/</span>
<span class="preprocessor"># make</span>
<span class="preprocessor"># cp -d out-shared/libleveldb* /usr/lib/</span>
<span class="preprocessor"># cp -r include/leveldb/ /usr/local/include</span>
</code></pre><h3 id="Install_snappy">Install snappy</h3><p><code>yum install snappy</code>发现centos7 已经给安装好了</p>
<h3 id="Install_lmdb">Install lmdb</h3><pre><code>pip <span class="keyword">install</span> lmdb
</code></pre><h3 id="Install_hdf5">Install hdf5</h3><p>下载hdf5</p>
<pre><code>tar xvf hdf5-1.8.5-patch1.tar
cd hdf5-1.8.5-patch
<span class="keyword">.</span>/configure --prefix=/opt/hdf5
make
make<span class="instruction"> check
</span>make install
make<span class="instruction"> check-install
</span>vim /etc/profile
<span class="comment">############[profile]</span>
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/hdf5/lib
<span class="comment"># 或者直接把/opt/hdf5/lib copy到/usr/local/lib</span>
<span class="comment">############[close profile]</span>
source /etc/profile
</code></pre><h3 id="其他依赖库">其他依赖库</h3><p>其他依赖库按照官网说法，先试了一遍</p>
<pre><code>yum <span class="keyword">install</span> snappy-devel opencv-devel boost-devel
yum <span class="keyword">install</span> python-devel
yum <span class="keyword">install</span> protobuf-devel leveldb-devel hdf5-devel <span class="comment"># 这几个包不行</span>
yum <span class="keyword">install</span> gflags-devel glog-devel lmdb-devel <span class="comment"># 这几个包也不行</span>
</code></pre><p>关于gflags, glog, lmdb的解决方案，官网给出了</p>
<pre><code># glog
wget http<span class="variable">s:</span>//google-glog.googlecode.<span class="keyword">com</span>/<span class="keyword">files</span>/glog-<span class="number">0.3</span>.<span class="number">3</span>.tar.gz
tar zxvf glog-<span class="number">0.3</span>.<span class="number">3</span>.tar.gz
<span class="keyword">cd</span> glog-<span class="number">0.3</span>.<span class="number">3</span>
./configure
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
# gflags
wget http<span class="variable">s:</span>//github.<span class="keyword">com</span>/schuhschuh/gflags/archive/master.zip
unzip master.zip
<span class="keyword">cd</span> gflags-master
<span class="built_in">mkdir</span> build &amp;&amp; <span class="keyword">cd</span> build
export CXXFLAGS=<span class="string">"-fPIC"</span> &amp;&amp; cmake .. &amp;&amp; <span class="keyword">make</span> VERBOSE=<span class="number">1</span>
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
# lmdb
git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/LMDB/lmdb
<span class="keyword">cd</span> lmdb/libraries/liblmdb
<span class="keyword">make</span> &amp;&amp; <span class="keyword">make</span> install
</code></pre><p>补充一下，上面的配置有可能编译caffe的时候出现如下报错：<code>error while loading shared libraries: libgflag.so.0</code>，要在gflag的cmake的时候使用如下参数</p>
<pre><code>cmake -DCMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> -DBUILD_SHARED_LIBS=<span class="keyword">ON</span> -DGFLAGS_NAMESPACE=google -<span class="keyword">G</span><span class="string">"Unix Makefiles"</span> ../
</code></pre><p>如果报错为<code>error while loading shared libraries: libglog.so.0</code>，则要增加如下设置</p>
<pre><code>cat /etc/ld<span class="class">.so</span><span class="class">.conf</span>  
echo <span class="string">"/usr/local/lib"</span> &gt;&gt; /etc/ld<span class="class">.so</span><span class="class">.conf</span>
ldconfig
</code></pre><p>但是有几个包是不行的，<code>protobuf-devel</code>, <code>leveldb-devel</code>, <code>hdf5-devel</code>找不到<br>刚才已经下载protobuf, leveldb, hdf5, 暂时先不管这几个devel了</p>
<h2 id="安装OpenCV">安装OpenCV</h2><p>安装了这么多年OpenCV，头一次遇到这么大坑，先尝试了大家推荐的shell一键安装</p>
<pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/jayrambhia/Install-OpenCV
<span class="keyword">cd</span> Install-OpenCV-master/RedHat
./opencv_latest.<span class="keyword">sh</span>
</code></pre><p>要注意downloading ippicv_linux_20140513.tgz的时候耗时很久，要耐心等待。<br>但是在编译caffe的时候还是报错，回来重新安装opencv2.4.11</p>
<pre><code>cd ~/opencv
mkdir <span class="operator"><span class="keyword">release</span>
cd <span class="keyword">release</span>
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=<span class="keyword">RELEASE</span> -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> -<span class="keyword">D</span> CUDA_GENERATION=Kepler ..
make
sudo make <span class="keyword">install</span></span>
</code></pre><p>执行python模块</p>
<pre><code>yum <span class="keyword">install</span> opencv-python
</code></pre><p>测试python下import cv2检测是否安装成功（自带的python已经配置好opencv，anaconda不能import cv2）,解决办法如下:</p>
<pre><code>cp /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv2</span>.<span class="title">so</span> /<span class="title">root</span>/<span class="title">anaconda</span>/<span class="title">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span></span>
cp /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">cv</span>.<span class="title">py</span> /<span class="title">root</span>/<span class="title">anaconda</span>/<span class="title">lib</span>/<span class="title">python2</span>.7/</span>
</code></pre><h2 id="安装caffe">安装caffe</h2><p>进入到caffe的工作目录</p>
<pre><code>git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/</span><span class="constant">BVLC</span>/caffe
cd caffe
cp <span class="constant">Makefile</span>.config.example <span class="constant">Makefile</span>.config
vim <span class="constant">Makefile</span>.config
<span class="comment">###############[Makefile.config]</span>
<span class="constant">BLAS</span> <span class="symbol">:</span>= mkl

<span class="constant">PYTHON_INCLUDE</span> <span class="symbol">:</span>= <span class="regexp">/root/anaconda</span><span class="regexp">/include/python</span>2.<span class="number">7</span> \
    /root/anaconda/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">numpy</span>/<span class="title">core</span>/<span class="title">include</span>/ \</span>
<span class="constant">PYTHON_LIB</span> <span class="symbol">:</span>= <span class="regexp">/root/anaconda</span><span class="regexp">/pkgs/python</span>-<span class="number">2.7</span>.<span class="number">10</span>-<span class="number">0</span>/<span class="class"><span class="keyword">lib</span></span>
<span class="constant">INCLUDE_DIRS</span> <span class="symbol">:</span>= <span class="variable">$(</span><span class="constant">PYTHON_INCLUDE</span>) /usr/local/<span class="keyword">include</span> \
        /opt/hdf5/<span class="keyword">include</span> \
        /opt/intel/mkl/<span class="keyword">include</span> \
<span class="constant">LIBRARY_DIRS</span> <span class="symbol">:</span>= <span class="variable">$(</span><span class="constant">PYTHON_LIB</span>) /usr/local/<span class="class"><span class="keyword">lib</span> /<span class="title">usr</span>/<span class="title">lib</span> \</span>
        /opt/hdf5/<span class="class"><span class="keyword">lib</span> \</span>
        /opt/intel/mkl/<span class="class"><span class="keyword">lib</span> \</span>
<span class="comment">###############[close Makefile.config]</span>
make all -j8
make test -j8
make runtest -j8
</code></pre><p>-j8选项可以提高编译速度，不是必须的，如果在runtest时候一片绿色，没报错，恭喜，说明caffe已经配置好了，可以愉快的使用了。<br>实测solverTest会fail，由于是Test模块，先不理会，估计是caffe的代码版本没统一，不影响使用</p>
<h2 id="测试MNIST">测试MNIST</h2><p>进入到caffe根目录下，执行如下操作</p>
<pre><code>./<span class="keyword">data</span>/mnist/get_mnist.sh               <span class="comment"># 下载minst数据库</span>
./examples/mnist/create_mnist.sh        <span class="comment"># 把数据转成lmdb格式</span>
./examples/mnist/train_lenet.sh         <span class="comment"># 训练mnist</span>
</code></pre><p>从输出结果看到，test集上得到99.2%的正确率，还是很不错的。</p>
<h2 id="其他说明">其他说明</h2><h3 id="pycaffe配置">pycaffe配置</h3><pre><code><span class="built_in">make</span> pycaffe
</code></pre><p>编译成功了，简直酸爽。<br>最后配置一下环境变量,~/.bashrc添加</p>
<pre><code>export PYTHONPATH=/xxxxxxxxx/caffe/python:<span class="variable">$PYTHONPATH</span>
</code></pre><p>python环境下</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> caffe</span>
</code></pre><p>检测caffe-python是否配置好</p>
<h3 id="cuDNN">cuDNN</h3><pre><code>tar xzvf cudnn-<span class="number">7.0</span>-linux-x64-v3.<span class="number">0</span>-rc.tgz
cd cuda
cp <span class="keyword">include</span>/* <span class="regexp">/usr/local</span><span class="regexp">/cuda/include</span>
cp -d lib64/* <span class="regexp">/usr/local</span><span class="regexp">/cuda/lib</span>64        <span class="comment"># -d 保留link file的属性</span>
</code></pre><p>在caffe根目录的<code>Makefile.config</code>中把<code>USE_CUDNN := 1</code>的屏蔽取消，然后<code>make all</code>即可。</p>
<h2 id="Linux多用户管理">Linux多用户管理</h2><p>为了创建一个用户组，并把工作成员都加到这个组，并提升用户sudo权限，提升权限的时候记住最前面的%非常有用，加上才能对组生效，最后设置组内成员能够相互访问彼此目录</p>
<pre><code>groupadd imgergroup
useradd -g imgergroup imger1
passwd imger1
vim /etc/sudoers
<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">####[sudoers]
%imgergroup       ALL=(ALL)       ALL
###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">#[close]</span>
cd /home
chmod -R +r *
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/18/caffe-setup2/" data-id="cj3hb0686003e3cfhalmtre81" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-dataprepare" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/15/caffe-dataprepare/" class="article-date">
  <time datetime="2015-08-15T00:12:16.000Z" itemprop="datePublished">2015-08-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/15/caffe-dataprepare/">caffe学习（二）用自己的数据训练模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="数据准备">数据准备</h2><h3 id="整理、去重">整理、去重</h3><p>将图片文件按照类别放入不同的文件夹下面，同时去掉相同文件夹下的相同图片</p>
<h3 id="打tag">打tag</h3><p>将图片数据按8:1:1的比例分成train，val，test三个子集，并产生“文件路径 标签”的标签数据，如下</p>
<pre><code>../data/train_img/<span class="number">104166241</span>/<span class="number">143088862023832744.</span>jpg <span class="number">0</span>
../data/train_img/<span class="number">104166241</span>/<span class="number">143088862023832435.</span>jpg <span class="number">0</span>
../data/train_img/<span class="number">121391188</span>/<span class="number">142096822616212389.</span>jpg <span class="number">1</span>
</code></pre><h3 id="生成lmdb数据库文件">生成lmdb数据库文件</h3><p>copy一份<code>examples/imagenet/create_imagenet.sh</code>文件并修改其中EXAMPLE、DATA、TOOLS、TRAIN_DATA_ROOT、VAL_DATA_ROOT的对应路径，并且修改<code>RESIZE=true</code>，因为我们的训练图片要归一化到256*256，我的修改如下</p>
<pre><code><span class="setting">EXAMPLE=<span class="value">.</span></span>
<span class="setting">DATA=<span class="value">.</span></span>
<span class="setting">TOOLS=<span class="value">../build/tools</span></span>

<span class="setting">TRAIN_DATA_ROOT=<span class="value">./</span></span>
<span class="setting">VAL_DATA_ROOT=<span class="value">./</span></span>

<span class="setting">RESIZE=<span class="value"><span class="keyword">true</span></span></span>
</code></pre><p>最后把其中的脚本语句中的convert_imageset命令中的标签文件改为自己的文件名(train.txt、val.txt)，然后执行</p>
<pre><code>./create_db.<span class="keyword">sh</span>
</code></pre><h3 id="生成均值文件">生成均值文件</h3><p>copy一份<code>examples/imagenet/make_imagenet_mean.sh</code>文件并修改其中的EXAMPLE、DATA、TOOLS路径位置，以及命令compute_image_mean中的训练数据集的路径和保存的均值文件的路径文件名，然后执行</p>
<pre><code>./make_db_mean.<span class="keyword">sh</span>
</code></pre><h2 id="模型参数调整">模型参数调整</h2><p>选择一个模型，这里选择GoogleNet，将models/bvlc_googlenet中的<code>solver.prototxt</code>和<code>train_val.prototxt</code>复制到新文件夹下。</p>
<h3 id="train_val-prototxt文件">train_val.prototxt文件</h3><ul>
<li>修改输入layer中的TRAIN source和TEST中的source到自己的数据库路径</li>
<li>同时注意一下其中的<code>batch_size</code>参数，决定每次迭代送多少图片去训练</li>
<li>googleNet有3个弱分类器，修改3个最终的loss1/classifier层中的<code>num_output</code>为我们样本的实际类别数，imageNet类别为1000</li>
</ul>
<h3 id="solver-prototxt文件">solver.prototxt文件</h3><ul>
<li>test_iter按照caffe官方的推荐，应该满足<strong>batch_size * test_iter = val子集的数据数</strong>，比如有1万张验证集图片，batch_size是50，那么test_iter应该设置为200左右。</li>
<li>test_interval决定多次训练迭代后测试一次，由于googleNet每次迭代较快，设置为2000比较合适，大概半个小时test一次</li>
<li>display参数决定多少次迭代显示一次，由于googleNet每次迭代较快，这里我设置为100</li>
<li>stepsize决定多次次迭代后减少学习率，应该和max_iter最大迭代次数综合考虑</li>
<li>snapshot决定多次次迭代后保存一次模型</li>
<li>snapshot_prefix是保存的模型文件名</li>
<li>solver_mode是用GPU还是CPU</li>
<li>lr_policy: 这个参数可以选的参数如下：<ul>
<li>fixed : lr永不变</li>
<li>step : lr = baselr * gamma^(iter/stepsize)</li>
<li>exp : lr = baselr * gamma^iter</li>
<li>inv : lr = baselr <em> (1+gamma</em>iter)^(-power)</li>
<li>multistep : 直接写iter在某个范围内时lr应该是多少，自定义学习曲线</li>
<li>poly : lr = baselr * (1 - iter/maxiter)^power</li>
<li>sigmoid : lr = baselr <em> (1 / (1 + e^(-gamma</em>(iter-stepsize))))</li>
</ul>
</li>
<li>iter_size这个参数很有意思，可以控制train的时候，做多少次batch_size才计算一次梯度，也就是<code>iter_size * batch_size</code>。这个参数当网络很大，显存不够用，又想增大batch_size时候就非常给力</li>
</ul>
<p>其他参数都是模型参数学习的相关参数，决定了模型的初始值和收敛速度，暂时先不调节</p>
<h2 id="训练">训练</h2><p>简单，执行</p>
<pre><code>../build/tools/caffe train --<span class="keyword">solver</span><span class="built_in">=</span><span class="keyword">solver</span>.prototxt
</code></pre><p>看到了terminal不停的喷log了，那酸爽，记得看一下log中的test结果，可以看到top-1/top-5的验证结果。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/15/caffe-dataprepare/" data-id="cj3hb0693003t3cfhe26jvt7q" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-setup" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/01/caffe-setup/" class="article-date">
  <time datetime="2015-08-01T10:56:27.000Z" itemprop="datePublished">2015-08-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/01/caffe-setup/">caffe学习（一）caffe + centOS 6.5 + CUDA 6.5配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>caffe应该是当下最火的深度学习开源框架了，其性能强大，每天可以处理60M的图片（K40显卡），测试一张图片只要1ms，而且其模块都已经定义好，不需要写什么代码就能轻松调用，虽然是c++开发的却能很好的支持python，简直不能更赞。</p>
<h2 id="开发环境">开发环境</h2><p>虽然它这么好用，安装它可不是一个省心的事，最好的参考资料还是官网安装资料<a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">http://caffe.berkeleyvision.org/installation.html</a>，配置之前先介绍一下自己的软硬件环境</p>
<ul>
<li><strong>显卡K20c</strong>（没显卡也能玩caffe）</li>
<li><strong>Linux服务器版本centOS6.5</strong>（版本有点低，这有点坑，系统自带的python是2.6版本，cmake是2.6版本，这都给安装带来了不便，由于是服务器没得选，只能硬着头皮上了，而且网上多是基于Ubuntu系统的配置，所以更要把安装过程记录一下）</li>
<li><p><strong>python升级到2.7版本，再把cmake升级到2.8版本</strong>，我都是下载的源代码安装的，要注意的是安装好之后还要将原来版本移除掉并<strong>链接到新版本</strong>，如下</p>
<p>  mv /usr/bin/python /usr/bin/python_old<br>  ln -s  /usr/local/bin/python2.7 /usr/bin/python</p>
</li>
<li><p><strong>安装numpy1.9.2版本</strong>，也是官网源代码</p>
</li>
</ul>
<h2 id="安装CUDA和MKL">安装CUDA和MKL</h2><p>我使用的是CUDA 6.5版本，并且通过edu邮箱申请了一个MKL的student版本。这两个都是商业软件，问题比较少，安照网上的资料很容易就配置好了。</p>
<h2 id="依赖库安装">依赖库安装</h2><p>按照官网说法，先试了一遍</p>
<pre><code><span class="label">sudo</span> yum install protobuf-devel leveldb-devel snappy-devel opencv-devel <span class="keyword">boost-devel </span>hdf5-devel
</code></pre><p>但是有几个包是不行的，protobuf-devel, leveldb-devel, hdf5-devel找不到，由于我服务器版本比较低，boost和boost-devel都只有1.41版本，注意要把boost也升级一下。protobuf是谷歌开发的一种实现内存外存交换的协议接口，再这个统一的通讯协议下不同开发者可以使用自己喜欢的方式进行模型参数的管理。</p>
<p>首先先把protobuf, leveldb, hdf5, boost高级版本的tar包下载下来解压并用make和make install安装起来，然后下载其分别对应的devel的rpm安装，并通过rpm命令安装：</p>
<pre><code>rpm -<span class="tag">i</span> xxx.rpm
</code></pre><h2 id="安装OpenCV">安装OpenCV</h2><p>安装了这么多年OpenCV，头一次遇到这么大坑，先尝试了大家推荐的shell一键安装</p>
<pre><code>git https://github.com/ouxinyu/<span class="operator"><span class="keyword">Install</span>-OpenCV-<span class="keyword">master</span>
cd <span class="keyword">Install</span>-OpenCV-<span class="keyword">master</span>/RedHat
./opencv_latest.sh</span>
</code></pre><p>看上去一切很美，但是执行downloading ippicv_linux_20140513.tgz这个文件的时候就怎么都过不去了，没能解决，于是还是乖乖的安装官网的教程去下载了一个OpenCV 2.4.9的tar解压安装，安装过程也是安装OpenCV官方的教程来的，但是由于要使用其中的GPU模块，原本预想很顺利的安装过程出了error，查了资料发现是OpenCV的bug<a href="http://code.opencv.org/issues/3814" target="_blank" rel="external">http://code.opencv.org/issues/3814</a>，拷贝文件<a href="http://code.opencv.org/projects/opencv/repository/revisions/feb74b125d7923c0bc11054b66863e1e9f753141/raw/modules/gpu/src/nvidia/core/NCVPixelOperations.hpp" target="_blank" rel="external">NCVPixelOperations.hpp</a>替换掉源文件，重新build make，搞定</p>
<pre><code>cd ~/opencv
mkdir <span class="operator"><span class="keyword">release</span>
cd <span class="keyword">release</span>
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=<span class="keyword">RELEASE</span> -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/usr/<span class="keyword">local</span> ..

cd ..
make
sudo make <span class="keyword">install</span></span>
</code></pre><h2 id="安装caffe">安装caffe</h2><p>复制一个配置文件先</p>
<pre><code><span class="tag">cp</span> <span class="tag">Makefile</span><span class="class">.config</span><span class="class">.example</span> <span class="tag">Makefile</span><span class="class">.config</span>
</code></pre><p>把里面的CPU_ONLY，BLAS，PYTHON_DIR目录都按照情况配置好，然后执行</p>
<pre><code><span class="keyword">make</span> <span class="keyword">all</span> -j8
<span class="keyword">make</span> test -j8
<span class="keyword">make</span> runtest -j8
</code></pre><p>-j8选项可以提高编译速度，不是必须的，如果在runtest时候一片绿色，没报错，恭喜，说明caffe已经配置好了，可以愉快的使用了。</p>
<h2 id="测试MNIST">测试MNIST</h2><p>进入到caffe根目录下，执行如下操作</p>
<pre><code>./<span class="keyword">data</span>/mnist/get_mnist.sh               <span class="comment"># 下载minst数据库</span>
./examples/mnist/create_mnist.sh        <span class="comment"># 把数据转成lmdb格式</span>
./examples/mnist/train_lenet.sh         <span class="comment"># 训练mnist</span>
</code></pre><p>从输出结果看到，test集上得到99.2%的正确率，还是很不错的。</p>
<h2 id="其他说明">其他说明</h2><h3 id="pycaffe配置">pycaffe配置</h3><ul>
<li><p>由于我这里python没配置好，所以make pycaffe没能通过，有待解决。<br>解决方案，下载<a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda-2.3.0-Linux-x86_64.sh" target="_blank" rel="external">Anaconda-2.3.0-Linux-x86_64.sh</a>，下载后运行，<br>直接把python升级到2.7版本，同时安装好了所有相关依赖包，简直完美啊，，解决了python2.6和2.7共存的问题，同时一键安装python和相关插件，并且配置好了相关环境变量，同时还是64位版本的python，强烈推荐。<br>修改Makefile.config中和python相关内容</p>
<p>  PYTHON_INCLUDE := /root/anaconda/include/python2.7 /root/anaconda/lib/python2.7/site-packages/numpy/core/include/<br>  PYTHON_LIB := /root/anaconda/pkgs/python-2.7.10-0/lib<br>  INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include<br>  LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib</p>
</li>
</ul>
<p>执行</p>
<pre><code><span class="built_in">make</span> pycaffe
</code></pre><p>编译成功了，简直酸爽。<br>最后配置一下环境变量</p>
<pre><code>export PYTHONPATH=/root/caffe_test/caffe/python:<span class="variable">$PYTHONPATH</span>
</code></pre><p>python环境下</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> caffe</span>
</code></pre><p>报错信息</p>
<pre><code>from ._caffe import <span class="constant">Net</span>, <span class="constant">SGDSolver</span>
<span class="constant">ImportError</span><span class="symbol">:</span> /usr/local/<span class="class"><span class="keyword">lib</span>/<span class="title">libboost_python</span>.<span class="title">so</span>.1.58.0: <span class="title">undefined</span> <span class="title">symbol</span>: <span class="title">PyUnicodeUCS2_FromEncodedObject</span></span>
</code></pre><p>anaconda只差boost没有包含，而是我安装的boost版本1.58跟anaconda要求的1.57版本，重新安装一遍boost 1.57</p>
<pre><code># download <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">tar</span> xvf <span class="keyword">boost_1_57_0.tar.bz2
</span><span class="label">cd</span> <span class="keyword">boost_1_57_0
</span>./<span class="keyword">bootstrap.sh
</span>./<span class="keyword">b2
</span>./<span class="keyword">b2 </span>install /usr
</code></pre><p>记得安装完boost一定要<code>yum install boost-devel</code>一下（血和泪的教训）<br>出现新的错误，说no module name google.portobuf，重新安装protobuf和protobuf-devel并没有解决这个问题，上网上重新下载protobuf2.6.1版本，弄错了是不行的。解压后，</p>
<pre><code><span class="keyword">.</span>/autogen.sh
<span class="keyword">.</span>/configure
make
make<span class="instruction"> check
</span>make install
</code></pre><p>出错loading shared libraries: libprotobuf.so.8: cannot open shared object file: No such file or directory，此时应该是连接出错<br>locate libprotobuf.so.9 看下libprotobuf.so.9的确存在/opt/protobuf/lib下面</p>
<pre><code><span class="keyword">cd</span> /etc/ld.<span class="keyword">so</span>.<span class="keyword">conf</span>.<span class="keyword">d</span>/
<span class="keyword">vi</span> protobuf.<span class="keyword">conf</span>   # protobuf.<span class="keyword">conf</span>中只要加入一行： /<span class="keyword">opt</span>/protobuf/lib
ldconfig
</code></pre><p>安装protobuf的python模块</p>
<pre><code><span class="keyword">cd</span> <span class="keyword">python</span>
<span class="keyword">python</span> setup.<span class="keyword">py</span> build
<span class="keyword">python</span> setup.<span class="keyword">py</span> test
<span class="keyword">python</span> setup.<span class="keyword">py</span> install
</code></pre><p>python setup.py build的过程中可能报几个错，然而没关系，我们并不需要所有的protobuf的模块，配置pycaffe最重要的就是注意anaconda和依赖包版本的对应，boost要求1.57版本，protobuf是2.6.1版本，弄错了是不行的。</p>
<ul>
<li>cuDNN的加速模块也没有安装测试一下，有空再配置一下。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/01/caffe-setup/" data-id="cj3hb068i003h3cfhiqzcxcsv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">life</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/study/">study</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">25</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-c/">c/c++</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/darknet/">darknet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dataset/">dataset</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face/">face</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mxnet/">mxnet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nnsearch/">nnsearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/source/">source</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tricks/">tricks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visualization/">visualization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/c-c/" style="font-size: 12.5px;">c/c++</a> <a href="/tags/caffe/" style="font-size: 17.5px;">caffe</a> <a href="/tags/darknet/" style="font-size: 10px;">darknet</a> <a href="/tags/dataset/" style="font-size: 10px;">dataset</a> <a href="/tags/face/" style="font-size: 10px;">face</a> <a href="/tags/machine-learning/" style="font-size: 12.5px;">machine learning</a> <a href="/tags/mxnet/" style="font-size: 10px;">mxnet</a> <a href="/tags/nnsearch/" style="font-size: 10px;">nnsearch</a> <a href="/tags/python/" style="font-size: 12.5px;">python</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/source/" style="font-size: 10px;">source</a> <a href="/tags/tensorflow/" style="font-size: 20px;">tensorflow</a> <a href="/tags/tricks/" style="font-size: 10px;">tricks</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/06/03/caffe-forward/">caffe学习（九）inference代码优化</a>
          </li>
        
          <li>
            <a href="/2017/06/03/interview/">试题整理</a>
          </li>
        
          <li>
            <a href="/2017/04/22/tensorflow-gpu/">tensorflow学习（十三）GPU使用技巧整理</a>
          </li>
        
          <li>
            <a href="/2017/03/29/tensorflow-mydata/">tensorflow学习（十二）加载自定义图像数据集</a>
          </li>
        
          <li>
            <a href="/2017/03/26/tensorflow-saver/">tensorflow学习（十一）保存和恢复模型</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget tag">
   <h3 class="title">常用链接</h3>
   <ul class="entry">
    <li><a href="http://blog.csdn.net/yang_xian521" title="my CSDN blog">我的CSDN博客</a></li>
    <li><a href="http://www.pythondoc.com/pythontutorial27/index.html" title="pythondoc">Python教程</a></li>
    <li><a href="http://vbird.dic.ksu.edu.tw/linux_basic/linux_basic.php" title="Linuxdoc">Linux教程</a></li> 
   </ul>
</div>
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Xian Yang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>