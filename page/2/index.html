<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>杨现的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="迭代的是人，递归的是神">
<meta property="og:type" content="website">
<meta property="og:title" content="杨现的个人博客">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="杨现的个人博客">
<meta property="og:description" content="迭代的是人，递归的是神">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="杨现的个人博客">
<meta name="twitter:description" content="迭代的是人，递归的是神">
  
    <link rel="alternative" href="/atom.xml" title="杨现的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">杨现的个人博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">分享计算机视觉、算法、生活累积的点滴</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-caffe-yolo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/13/caffe-yolo/" class="article-date">
  <time datetime="2016-07-13T14:29:26.000Z" itemprop="datePublished">2016-07-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/13/caffe-yolo/">caffe学习（七）caffe-YOLO模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原本YOLO是一个darknet的独立代码，网上有些大神把其网络用caffe实现了。贴一个传送门<a href="https://github.com/xingwangsfu/caffe-yolo" target="_blank" rel="external">https://github.com/xingwangsfu/caffe-yolo</a>。这里参考这个代码实现一下，没有训练代码，需要将darknet训练好的参数转换成caffe格式。</p>
<h2 id="修改deploy">修改deploy</h2><p>要把<code>yolo_deploy.prototxt</code>里的<code>fc26</code>层中的<code>num_output</code>参数改为实际需要的。</p>
<h2 id="参数模型格式转换">参数模型格式转换</h2><p>用darknet训练好的网络参数通过<code>create_yolo_caffemodel.py</code>用caffe读进来。darknet的权重保存格式很简单，前4个数是int型，分别表示major、minor、revision和net.seen，第五个参数开始就是一个一维浮点数组，存成二进制文件。读入之后，根据网络结构得到net的各层weights和bias的size大小，并按顺序传入。调用格式如下：</p>
<pre><code>python create_yolo_caffemodel<span class="class">.py</span> -m ./prototxt/yolo_deploy<span class="class">.prototxt</span> -w yolo_final<span class="class">.weights</span> -o yolo.caffemodel
</code></pre><h2 id="YOLO检测">YOLO检测</h2><pre><code>python yolo_main<span class="class">.py</span> -m ./prototxt/yolo_deploy<span class="class">.prototxt</span> -w yolo<span class="class">.caffemodel</span> -<span class="tag">i</span> xxx.jpg
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/13/caffe-yolo/" data-id="cjf3vykeq0042qgfhn0gpxges" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-guides-japan" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/06/guides-japan/" class="article-date">
  <time datetime="2016-07-06T11:54:34.000Z" itemprop="datePublished">2016-07-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/06/guides-japan/">日本攻略</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="调研">调研</h2><p>日本旅游局官网<a href="http://www.welcome2japan.cn/" target="_blank" rel="external">http://www.welcome2japan.cn/</a>，介绍的还挺好的，比天朝的官方网站做的高到不知道哪里去了</p>
<h2 id="出国准备注意事项">出国准备注意事项</h2><ul>
<li>签证：注意单次签证虽然给15天，建议不要排的太满，10天以内即可。</li>
<li>签证申请：<strong>必须通过旅行社</strong>，单次签，年收入10万以上，按旅行社的要求即可。签证搞到后，会给一份<strong>归国报告书</strong>，回国办理登记手续的时候给柜台盖章，寄给旅行社。</li>
<li>免费wifi，下载Japan Connected-Free Wifi的app</li>
</ul>
<h2 id="景点关键词">景点关键词</h2><ul>
<li>京都：寺庙</li>
<li>大阪：环球影城</li>
<li>东京：迪斯尼</li>
</ul>
<h2 id="现金">现金</h2><p>按每日每人1万日元准备吧~</p>
<h2 id="购物">购物</h2><p>超过1万日元消费可以在店内退税，带一张银联卡，便宜，好用</p>
<h1 id="东京攻略">东京攻略</h1><ul>
<li>公交卡：PASMO或者西瓜卡（SUICA）</li>
<li>皇家御所<a href="http://sankan.kunaicho.go.jp/" target="_blank" rel="external">http://sankan.kunaicho.go.jp/</a></li>
<li>宫崎骏吉卜力美术馆<a href="http://www.lawson.co.jp/ghibli/museum/ticket/" target="_blank" rel="external">http://www.lawson.co.jp/ghibli/museum/ticket/</a></li>
<li>公园：新宿御苑、浅草寺、上野公园</li>
<li>周边小镇：镰仓、箱根</li>
<li>地标：东京铁塔、东京天空树</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/06/guides-japan/" data-id="cjf3vykdu002xqgfhlnlc2bu9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/生活/">生活</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-spider" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/22/python-spider/" class="article-date">
  <time datetime="2016-06-22T13:02:36.000Z" itemprop="datePublished">2016-06-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/22/python-spider/">python爬虫入门笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="写在前面">写在前面</h1><p>爬虫其实内容的爬取不是最为困难的地方，真正难点在于如何混在群众之中不被发现。由于我在爬虫界还处于幼儿园水平，所以简单写几个脚本爬点美女图片还勉强，想跟亚一爬谈笑风生就不指望了。</p>
<h1 id="urllib基础">urllib基础</h1><h3 id="html抓取">html抓取</h3><pre><code>import urllib2

request = urllib2.<span class="function"><span class="title">Request</span><span class="params">(<span class="string">"http://www.baidu.com"</span>)</span></span>
response = urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(request)</span></span>
data = response.<span class="function"><span class="title">read</span><span class="params">()</span></span>
</code></pre><p>data就得到了百度主页的html信息。</p>
<h3 id="html解析">html解析</h3><p>主要就是用<code>re</code>模块来正则匹配</p>
<pre><code>import re

#返回pattern对象
re.<span class="function"><span class="title">compile</span><span class="params">(string[,flag])</span></span>  
#以下为匹配所用函数
re.<span class="function"><span class="title">match</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">search</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">split</span><span class="params">(pattern, string[, maxsplit])</span></span>
re.<span class="function"><span class="title">findall</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">finditer</span><span class="params">(pattern, string[, flags])</span></span>
re.<span class="function"><span class="title">sub</span><span class="params">(pattern, repl, string[, count])</span></span>
re.<span class="function"><span class="title">subn</span><span class="params">(pattern, repl, string[, count])</span></span>
</code></pre><p>比较常用的findall，用列表的形式返回全部能匹配的子串。</p>
<h1 id="反爬伪装">反爬伪装</h1><p>现在主流的反爬策略基本基于三个层面：</p>
<ul>
<li>IP层，同一ip访问过多会被封杀</li>
<li>HTTP协议层，判断是否真实的浏览器行为</li>
<li>行为层，判断是否真实用户行为<br>上述的程序通常在<code>response.read()</code>的时候会报错10054、10060之类的错误。</li>
</ul>
<h3 id="伪装浏览器Header">伪装浏览器Header</h3><p>用chrome打开浏览器，调试模式，然后打开Network模块，选择其中一个页面，打开Headers页面，其中最后的agent就是请求的身份，不填写身份的话，很容易被反爬策略封杀掉。</p>
<pre><code>user_agent = <span class="comment">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36'</span>
headers = {<span class="comment">'User-Agent' : user_agent}</span>
#    <span class="built_in">request</span> = urllib2.<span class="built_in">Request</span>(url, headers)
<span class="built_in">request</span> = urllib2.<span class="built_in">Request</span>(url)
<span class="built_in">request</span>.add_header(<span class="comment">'User-Agent', user_agent)</span>
<span class="built_in">response</span> = urllib2.urlopen(<span class="built_in">request</span>)
page = <span class="built_in">response</span>.read()
</code></pre><p>除此之外，有些反爬策略还有反盗链的设计，需要在headers中传入referer</p>
<pre><code>request.<span class="function"><span class="title">add_header</span><span class="params">(<span class="string">'Referer'</span>, <span class="string">'http://www.taobao.com'</span>)</span></span>
</code></pre><h3 id="proxy代理设置">proxy代理设置</h3><p>如果ip访问次数过多也会被封杀，采用代理服务器的方法来定期更换代理。</p>
<pre><code>enable_proxy = True
proxy_handler = urllib2.<span class="function"><span class="title">ProxyHandler</span><span class="params">({<span class="string">"http"</span> : <span class="string">'http://192.168.0.1:8080'</span>})</span></span>
null_proxy_handler = urllib2.<span class="function"><span class="title">ProxyHandler</span><span class="params">({})</span></span>
<span class="keyword">if</span> enable_proxy:
    opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(proxy_handler)</span></span>
<span class="keyword">else</span>:
    opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(null_proxy_handler)</span></span>
urllib2.<span class="function"><span class="title">install_opener</span><span class="params">(opener)</span></span>
</code></pre><h3 id="超时设置Timeout">超时设置Timeout</h3><p>在urlopen的时候可以通过设置timeout参数解决网站相应过慢造成的影响。</p>
<pre><code>response = urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(<span class="string">'http://www.baidu.com'</span>, timeout=<span class="number">10</span>)</span></span>
</code></pre><h3 id="发送数据">发送数据</h3><p>用来实现和浏览器之间的行为交互</p>
<pre><code><span class="keyword">data</span> = urllib.parse.urlencode({<span class="string">"act"</span>: <span class="string">"login"</span>, <span class="string">"email"</span>: <span class="string">"xxxxx@qq.com"</span>, <span class="string">"password"</span>: <span class="string">"123456"</span>}).encode(<span class="string">'utf-8'</span>)
request1 = urllib2.Request(url, <span class="keyword">data</span>=<span class="keyword">data</span>)           <span class="comment"># POST方法</span>
request2 = urllib2.Request(url+<span class="string">"?%s"</span> % <span class="keyword">data</span>)         <span class="comment"># GET方法</span>
response = urllib2.urlopen(request1)
</code></pre><h3 id="常用超时异常">常用超时异常</h3><pre><code>try:
    urllib2.<span class="function"><span class="title">urlopen</span><span class="params">(request)</span></span>
except urllib2<span class="class">.HTTPError</span> as e:
    <span class="function"><span class="title">print</span><span class="params">(e.code, e.reason)</span></span>
except urllib2<span class="class">.URLError</span> as e:
    <span class="function"><span class="title">print</span><span class="params">(e.errno, e.reason)</span></span>
</code></pre><h3 id="服务器cookie检查">服务器cookie检查</h3><pre><code>import <span class="keyword">http</span>.cookiejar
cookie_jar = <span class="keyword">http</span>.cookiejar.CookieJar()
cookie_jar_handler = urllib.request.HTTPCookieProcessor(cookiejar=cookie_jar)
opener = urllib2.build_opener(cookie_jar_handler)        <span class="comment"># add_handler</span>
response = opener.<span class="built_in">open</span>(url)
</code></pre><h3 id="获取cookie">获取cookie</h3><p>两种方式，1）直接贴到headers中</p>
<pre><code>request = urllib2.<span class="function"><span class="title">Request</span><span class="params">(url)</span></span>
request.<span class="function"><span class="title">add_header</span><span class="params">(<span class="string">'Cookie'</span>, <span class="string">"PHPSESSID=btqkg9amjrtoeev8coq0m78396; USERINFO=n6nxTHTY%2BJA39z6CpNB4eKN8f0KsYLjAQTwPe%2BhLHLruEbjaeh4ulhWAS5RysUM%2B; "</span>)</span></span>
</code></pre><p>2）构建cookie</p>
<pre><code>import http<span class="class">.cookiejar</span>
cookie = http<span class="class">.cookiejar</span><span class="class">.Cookie</span>(name=<span class="string">"xx"</span>, value=<span class="string">"xx"</span>, domain=<span class="string">"xx"</span>, ...)
cookie_jar = http<span class="class">.cookiejar</span><span class="class">.CookieJar</span>()
cookie_jar.<span class="function"><span class="title">set_cookie</span><span class="params">(cookie)</span></span>
cookie_jar_handler = urllib<span class="class">.request</span><span class="class">.HTTPCookieProcessor</span>(cookiejar=cookie_jar)
opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(cookie_jar_handler)</span></span>
response = opener.<span class="function"><span class="title">open</span><span class="params">(url)</span></span>
</code></pre><h3 id="HTTP身份认证">HTTP身份认证</h3><pre><code>password_mgr = urllib2.<span class="function"><span class="title">HTTPPasswordMgrWithDefaultRealm</span><span class="params">()</span></span>
password_mgr.<span class="function"><span class="title">add_password</span><span class="params">(realm=None, uri=url, user=<span class="string">'username'</span>, passwd=<span class="string">'password'</span>)</span></span>
handler = urllib2.<span class="function"><span class="title">HTTPBasicAuthHandler</span><span class="params">(password_mgr)</span></span>
opener = urllib2.<span class="function"><span class="title">build_opener</span><span class="params">(handler)</span></span>
response = opener.<span class="function"><span class="title">open</span><span class="params">(url)</span></span>
</code></pre><h1 id="简易图片爬虫">简易图片爬虫</h1><p>关键的就是解析的时候匹配图片内容，得到了图片链接的话，用wget或者其他模块都能保存图片</p>
<pre><code>patternImg = re.<span class="function"><span class="title">compile</span><span class="params">(<span class="string">'&lt;img.*?src="(.*?)"'</span>,re.S)</span></span>
images = re.<span class="function"><span class="title">findall</span><span class="params">(patternImg, url_data)</span></span>
</code></pre><h1 id="参考资料与推荐文章">参考资料与推荐文章</h1><p><a href="http://cuiqingcai.com/" target="_blank" rel="external">http://cuiqingcai.com/</a><br><a href="http://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&amp;mid=402180172&amp;idx=1&amp;sn=1db24327a15cea8fab6907069fbaabbf&amp;scene=0#wechat_redirect" target="_blank" rel="external">数据时代的反爬虫绝技</a><br><a href="https://zhuanlan.zhihu.com/p/22982208" target="_blank" rel="external">一个很“水”的Python爬虫入门代码文件</a><br><a href="https://zhuanlan.zhihu.com/p/23064000" target="_blank" rel="external">“史上最详细”的Python模拟登录新浪微博流程</a><br><a href="https://luzhijun.github.io/2016/10/29/%E5%BE%AE%E5%8D%9A%E8%AF%9D%E9%A2%98%E7%88%AC%E5%8F%96%E4%B8%8E%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/" target="_blank" rel="external">微博话题爬取与存储分析</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/22/python-spider/" data-id="cjf3vykcj001uqgfh4txuhlsf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-caffe2tensorflow" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/14/tensorflow-caffe2tensorflow/" class="article-date">
  <time datetime="2016-06-14T13:28:21.000Z" itemprop="datePublished">2016-06-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/14/tensorflow-caffe2tensorflow/">tensorflow学习（七）caffe模型训练结果转换为tensorflow格式</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>tensorflow官方认定的转换工具为<a href="https://github.com/ethereon/caffe-tensorflow" target="_blank" rel="external">https://github.com/ethereon/caffe-tensorflow</a>。我们尝试一下转换一个caffe训练的图像识别模型</p>
<h2 id="caffe-tensorflow安装">caffe-tensorflow安装</h2><pre><code>git clone <span class="string">https:</span><span class="comment">//github.com/ethereon/caffe-tensorflow</span>
</code></pre><h2 id="生成模型训练代码">生成模型训练代码</h2><p>利用<code>convert.py</code>可以将caffe网络定义的deploy.prototxt文件转换为tensorflow的python实现，不过这种转换之后的模型代码还需要import kaffe模块，虽然<code>kaffe.tensorflow.Network</code>没有其他依赖，可以单独加载到新代码中即可使用，方便移植，我还是更倾向于转换之后参考这个代码重新写一份。调用方式如下：</p>
<pre><code>./convert<span class="class">.py</span> ./deploy<span class="class">.prototxt</span> --code-output-path=./myNetTensorflow.py
</code></pre><h2 id="转换训练好的模型">转换训练好的模型</h2><p>也可以将caffemodel的weights和biases参数读取出来转换为npy的格式，并通过<code>numpy.load()</code>读取数据。转换数据的脚本如下：</p>
<pre><code>./convert<span class="class">.py</span> ./deploy<span class="class">.prototxt</span> --caffemodel=./mynet<span class="class">.caffemodel</span> --data-output-path=./myNetTensorflow.npy
</code></pre><p>由于转换过来的npy数据的类型比奇怪，是0-d array，要将其取出来需要如下读取方式</p>
<pre><code>params = np.<span class="function"><span class="title">load</span><span class="params">()</span></span>
params = params.<span class="function"><span class="title">item</span><span class="params">()</span></span>
</code></pre><h2 id="注意事项">注意事项</h2><ul>
<li><p>caffe的模型应该是较新的版本，才能转换</p>
</li>
<li><p>并不是所有的caffe模型都能转换为tensorflow，比如caffe的padding支持很多方式，tensorflow目前只支持<code>SAME</code>和<code>VALID</code></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/14/tensorflow-caffe2tensorflow/" data-id="cjf3vykce001iqgfh6guq0nzz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-inception" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/13/tensorflow-inception/" class="article-date">
  <time datetime="2016-06-13T11:57:11.000Z" itemprop="datePublished">2016-06-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/13/tensorflow-inception/">tensorflow学习（六）CNN网络Inception</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这次我们来上手一个大型网络,googLeNet。这篇讲一下Inception v3网络的训练和测试以及数据集的加载。</p>
<h2 id="数据准备">数据准备</h2><p>将图片按照类别放入不同的文件夹下。格式如下：</p>
<pre><code>data_dir/train/label_0/<span class="tag">a</span><span class="class">.jpg</span>
data_dir/train/label_0/<span class="tag">b</span><span class="class">.jpg</span>
...
data_dir/train/label_1/f<span class="class">.jpg</span>
...
data_dir/validation/label_0/c<span class="class">.jpg</span>
data_dir/validation/label_0/d<span class="class">.jpg</span>
...
data_dir/labels.txt
</code></pre><p>同时将所有label的类别整理成一个txt放在data_dir/labels.txt文件中，行数代表该类别对应的整数值，从0开始计数，其文本内容如下：</p>
<pre><code>label_0
label_1
label_2
...
label_n
</code></pre><h3 id="转化成为TFRecord格式">转化成为TFRecord格式</h3><p>首先通过<code>_find_iamge_files</code>函数得到全量图片的文件名、标签、标签文本信息的对应关系，并打乱排序。然后按线程数将全量文件分块，分别执行<code>_process_image_files_batch</code>。将数据按分块分别写入对应的TFRecordWriter。这个操作的代码我整理保存在了<a href="https://github.com/yangxian10/tensorflow_code/blob/master/build_image_tfrecord_data.py" target="_blank" rel="external">build_image_tfrecord_data.py</a>。其中两个重要的参数，一个是进程数量的控制参数<code>num_threads</code>和Record数据分块的参数<code>num_shards</code>。我这里有个不同，原来代码是读文件之后直接压入Record，我是用OpenCV解码之后，将解码后数据变成string压入Record。代码调用格式如下：</p>
<pre><code>python build_image_tfrecord_data.py \
  -<span class="ruby">-train_directory=mydata/train \
</span>  -<span class="ruby">-validation_directory=mydata/validation \
</span>  -<span class="ruby">-output_directory=mydata/tf_record \
</span>  -<span class="ruby">-labels_file=mydata/labels.txt</span>
</code></pre><h2 id="网络模型">网络模型</h2><h2 id="单机训练">单机训练</h2><h2 id="分布式训练">分布式训练</h2><h2 id="测试评估">测试评估</h2><h3 id="参考文献">参考文献</h3><p><a href="https://github.com/tensorflow/models/tree/master/inception" target="_blank" rel="external">https://github.com/tensorflow/models/tree/master/inception</a><br><a href="http://arxiv.org/abs/1512.00567" target="_blank" rel="external">http://arxiv.org/abs/1512.00567</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/13/tensorflow-inception/" data-id="cjf3vykbx0013qgfhc5psjrfh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-captcha" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/13/tensorflow-captcha/" class="article-date">
  <time datetime="2016-06-13T11:52:35.000Z" itemprop="datePublished">2016-06-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/13/tensorflow-captcha/">tensorflow学习（五）基于CNN的验证码识别</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>验证码的识别是OCR中的一个重要内容，特别是对于爬虫系统意义重大，传统方法都是单个字符识别，包括二值化处理、字符分割、字符识别的过程。由于现在深度学习的火爆，end-to-end的方法流行起来。这里就用tensorflow实现一个端到端的CNN验证码识别功能。</p>
<p>本文的想法是把验证码看成一个多标签学习的问题，相当于几个有标签的图像识别。这里没有考虑使用LSTM对验证码序列进行学习，因为我个人觉得验证码字符之间的相关性不强，没必要用这种大杀器。</p>
<h2 id="验证码数据集">验证码数据集</h2><p>用<a href="https://pypi.python.org/pypi/captcha/0.1.1" target="_blank" rel="external">python-captcha</a>生成验证码数据集，这个库可以生成声音和图像的验证码，安装过程非常简单</p>
<pre><code>pip <span class="keyword">install</span> captcha
</code></pre><p>使用示例如下：</p>
<pre><code>from captcha<span class="class">.image</span> import ImageCaptcha

image = <span class="function"><span class="title">ImageCaptcha</span><span class="params">(fonts=[<span class="string">'/path/A.ttf'</span>, <span class="string">'/path/B.ttf'</span>])</span></span>
image.<span class="function"><span class="title">write</span><span class="params">(<span class="string">'1234'</span>, <span class="string">'out.png'</span>)</span></span>
</code></pre><h2 id="数据输入">数据输入</h2><p>验证码图片生成后是通过字节流生成的，可以随机生成，所以训练样本量可以无穷大。我们这里使用定长的4位验证码，包含0~9、a~z、A~Z。图像大小缩放到(30, 80, 3)。代码如下：</p>
<pre><code><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> cv2
<span class="keyword">import</span> random
<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="keyword">from</span> captcha.image <span class="keyword">import</span> ImageCaptcha

<span class="class"><span class="keyword">class</span> <span class="title">OCR_data</span><span class="params">(object)</span>:</span>
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num, data_dir, batch_size=<span class="number">50</span>, len_code=<span class="number">4</span>, height=<span class="number">30</span>, width=<span class="number">80</span>)</span>:</span>
        self.num = num
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.len_code = len_code
        self.height = height
        self.width = width
        self.captcha = ImageCaptcha()
        self.index_in_epoch = <span class="number">0</span>
        self._imgs = []
        self._labels = []
        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num):
            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:
                <span class="keyword">print</span> <span class="string">'%s images have been created.'</span> % i
            img, label = self.create_captcha()
            self._imgs.append(img)
            self._labels.append(label)
        self._imgs = np.array(self._imgs)
        self._labels = np.array(self._labels)


    <span class="function"><span class="keyword">def</span> <span class="title">create_captcha</span><span class="params">(self)</span>:</span>
        code, label = self.gen_rand()
        img = self.captcha.generate(code)
        img = np.fromstring(img.getvalue(), dtype=<span class="string">'uint8'</span>)
        img = cv2.imdecode(img, cv2.IMREAD_COLOR)
        img = cv2.resize(img, (self.width, self.height))
        <span class="keyword">return</span> (img, label)

    <span class="function"><span class="keyword">def</span> <span class="title">gen_rand</span><span class="params">(self)</span>:</span>
        buf = <span class="string">''</span>
        label = []
        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.len_code):
            rnd = random.randint(<span class="number">0</span>, <span class="number">61</span>)
            label.append(rnd)
            <span class="keyword">if</span> rnd &lt; <span class="number">10</span>:
                ascii_code = chr(rnd+<span class="number">48</span>)
            <span class="keyword">elif</span> rnd &lt; <span class="number">36</span>:
                ascii_code = chr(rnd+<span class="number">65</span>)
            <span class="keyword">else</span>:
                ascii_code = chr(rnd+<span class="number">97</span>)
            buf += ascii_code
        label_one_hot = self.dense_to_one_hot(label, <span class="number">62</span>)
        <span class="keyword">return</span> buf, label_one_hot

    <span class="function"><span class="keyword">def</span> <span class="title">dense_to_one_hot</span><span class="params">(self, labels_dense, num_classes)</span>:</span>
        num_labels = len(labels_dense)
        index_offest = np.arange(num_labels) * num_classes
        labels_one_hot = np.zeros((num_labels, num_classes))
        labels_one_hot.flat[index_offest + labels_dense] = <span class="number">1</span>
        labels_one_hot = labels_one_hot.reshape(num_labels*num_classes)
        <span class="keyword">return</span> labels_one_hot

    <span class="function"><span class="keyword">def</span> <span class="title">next_batch</span><span class="params">(self, batch_size)</span>:</span>
        start = self.index_in_epoch
        self.index_in_epoch += batch_size
        <span class="keyword">if</span> self.index_in_epoch &gt; self.num:
            perm = np.arange(self.num)
            np.random.shuffle(perm)
            self._imgs = self._imgs[perm]
            self._labels = self._labels[perm]
            start = <span class="number">0</span>
            self.index_in_epoch = batch_size
            <span class="keyword">assert</span> batch_size &lt;= self.num
        end = self.index_in_epoch
        <span class="keyword">return</span> self._imgs[start:end], self._labels[start:end]
</code></pre><h2 id="训练">训练</h2><pre><code><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="keyword">from</span> captcha_data <span class="keyword">import</span> OCR_data
<span class="comment"># Parameters</span>
learning_rate = <span class="number">0.001</span>
training_iters = <span class="number">200000</span>
batch_size = <span class="number">64</span>
display_step = <span class="number">20</span>

<span class="comment"># Network Parameters</span>
<span class="comment"># n_input = 7200  # 30*80*3</span>
n_classes = <span class="number">62</span>  <span class="comment"># 10+26+26</span>

data_train = OCR_data(<span class="number">1000</span>, <span class="string">'/data/captcha_data'</span>)
data_test = OCR_data(<span class="number">500</span>, <span class="string">'/data/captcha_data'</span>)

<span class="comment"># tf Graph input</span>
x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">30</span>, <span class="number">80</span>, <span class="number">3</span>])
y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">4</span>*n_classes])

<span class="function"><span class="keyword">def</span> <span class="title">print_activations</span><span class="params">(t)</span>:</span>
    print(t.op.name, t.get_shape().as_list())

<span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.truncated_normal(shape, dtype=tf.float32, stddev=<span class="number">0.1</span>)
    <span class="keyword">return</span> tf.Variable(initial)

<span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.constant(<span class="number">0.0</span>, shape=shape)
    <span class="keyword">return</span> tf.Variable(initial, trainable=<span class="keyword">True</span>)

<span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W, B, name)</span>:</span>
    <span class="keyword">with</span> tf.name_scope(name) <span class="keyword">as</span> scope:
        conv = tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)
        bias = tf.nn.bias_add(conv, B)
        conv = tf.nn.relu(bias, name=scope)
        <span class="keyword">return</span> conv

<span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">avg_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.avg_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">norm</span><span class="params">(x, lsize, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.lrn(x, lsize, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>, name=name)

weights = {
    <span class="string">'wc1'</span>: weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">32</span>]),
    <span class="string">'wc2'</span>: weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">32</span>]),
    <span class="string">'wc3'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>]),
    <span class="string">'wd1'</span>: weight_variable([<span class="number">4</span>*<span class="number">10</span>*<span class="number">32</span>, <span class="number">512</span>]),
    <span class="string">'out1'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out2'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out3'</span>: weight_variable([<span class="number">512</span>, n_classes]),
    <span class="string">'out4'</span>: weight_variable([<span class="number">512</span>, n_classes])
}
biases = {
    <span class="string">'bc1'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bc2'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bc3'</span>: bias_variable([<span class="number">32</span>]),
    <span class="string">'bd1'</span>: bias_variable([<span class="number">512</span>]),
    <span class="string">'out1'</span>: bias_variable([n_classes]),
    <span class="string">'out2'</span>: bias_variable([n_classes]),
    <span class="string">'out3'</span>: bias_variable([n_classes]),
    <span class="string">'out4'</span>: bias_variable([n_classes]),
}

<span class="function"><span class="keyword">def</span> <span class="title">ocr_net</span><span class="params">(_x, _weights, _biases)</span>:</span>
    _x = tf.reshape(_x, shape=[-<span class="number">1</span>, <span class="number">30</span>, <span class="number">80</span>, <span class="number">3</span>])

    conv1 = conv2d(_x, _weights[<span class="string">'wc1'</span>], _biases[<span class="string">'bc1'</span>], <span class="string">'conv1'</span>)
    print_activations(conv1)
    pool1 = max_pool(conv1, k=<span class="number">2</span>, name=<span class="string">'pool1'</span>)
    print_activations(pool1)

    conv2 = conv2d(pool1, _weights[<span class="string">'wc2'</span>], _biases[<span class="string">'bc2'</span>], <span class="string">'conv2'</span>)
    print_activations(conv2)
    pool2 = avg_pool(conv2, k=<span class="number">2</span>, name=<span class="string">'pool2'</span>)
    print_activations(pool2)

    conv3 = conv2d(pool2, _weights[<span class="string">'wc3'</span>], _biases[<span class="string">'bc3'</span>], <span class="string">'conv3'</span>)
    print_activations(conv3)
    pool3 = avg_pool(conv3, k=<span class="number">2</span>, name=<span class="string">'pool3'</span>)
    print_activations(pool3)

    pool3_flat = tf.reshape(pool3, [-<span class="number">1</span>, _weights[<span class="string">'wd1'</span>].get_shape().as_list()[<span class="number">0</span>]])
    fc1 = tf.nn.relu(tf.matmul(pool3_flat, _weights[<span class="string">'wd1'</span>]) + _biases[<span class="string">'bd1'</span>], name=<span class="string">'fc1'</span>)
    print_activations(fc1)

    fc21 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out1'</span>]) + _biases[<span class="string">'out1'</span>], name=<span class="string">'fc21'</span>)
    print_activations(fc21)

    fc22 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out2'</span>]) + _biases[<span class="string">'out2'</span>], name=<span class="string">'fc22'</span>)
    print_activations(fc22)

    fc23 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out3'</span>]) + _biases[<span class="string">'out3'</span>], name=<span class="string">'fc23'</span>)
    print_activations(fc23)

    fc24 = tf.nn.relu(tf.matmul(fc1, _weights[<span class="string">'out4'</span>]) + _biases[<span class="string">'out4'</span>], name=<span class="string">'fc24'</span>)
    print_activations(fc24)

    out = tf.concat(axis=<span class="number">1</span>, values=[fc21, fc22, fc23, fc24], name=<span class="string">'out'</span>)
    print_activations(out)
    <span class="keyword">return</span> out

<span class="function"><span class="keyword">def</span> <span class="title">accuracy_func</span><span class="params">(_pred, _y)</span>:</span>
    y = tf.reshape(_y, shape=[-<span class="number">1</span>, <span class="number">4</span>, <span class="number">62</span>])
    pred = tf.reshape(_pred, shape=[-<span class="number">1</span>, <span class="number">4</span>, <span class="number">62</span>])
    correct_pred = tf.equal(tf.argmax(pred,<span class="number">2</span>), tf.argmax(y,<span class="number">2</span>))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    <span class="keyword">return</span> accuracy

pred = ocr_net(x, weights, biases)

cost = -tf.reduce_mean(y*tf.log(pred))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

<span class="comment">#correct_pred = tf.equal(tf.argmax(pred,2), tf.argmax(y,2))</span>
<span class="comment">#accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span>
accuracy = accuracy_func(pred, y)

init = tf.global_variables_initializer()

config = tf.ConfigProto()
config.gpu_options.allow_growth = <span class="keyword">True</span>

<span class="keyword">with</span> tf.Session(config=config) <span class="keyword">as</span> sess:
    sess.run(init)
    step = <span class="number">1</span><span class="comment"># Keep training until reach max iterations</span>
    <span class="keyword">while</span> step * batch_size &lt; training_iters:
        batch = data_train.next_batch(batch_size)
        <span class="comment"># Fit training using batch data</span>
        sess.run(optimizer, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
        <span class="keyword">if</span> step % display_step == <span class="number">0</span>:
            <span class="comment"># Calculate batch accuracy</span>
            acc = sess.run(accuracy, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
            <span class="comment"># Calculate batch loss</span>
            loss = sess.run(cost, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>]})
            <span class="keyword">print</span> <span class="string">"Iter "</span> + str(step*batch_size) + <span class="string">", Minibatch Loss= "</span> + <span class="string">"{:.6f}"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + <span class="string">"{:.5f}"</span>.format(acc)
        step += <span class="number">1</span>
    <span class="keyword">print</span> <span class="string">"Optimization Finished!"</span>

    test_batch = data_test.next_batch(<span class="number">500</span>)
    <span class="keyword">print</span> <span class="string">"Testing Accuracy:"</span>, sess.run(accuracy, feed_dict={x: test_batch[<span class="number">0</span>], y: test_batch[<span class="number">1</span>]})
</code></pre><h2 id="预测">预测</h2><p>tbd</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/13/tensorflow-captcha/" data-id="cjf3vykbx001fqgfhw749zirh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-cnn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/05/28/tensorflow-cnn/" class="article-date">
  <time datetime="2016-05-28T09:16:03.000Z" itemprop="datePublished">2016-05-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/28/tensorflow-cnn/">tensorflow学习（四）自己创建CNN网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前已经介绍过数据的加载和可视化的问题，这次该研究模型了。CNN网络应该是深度学习的一个经典了，话不多说，直接介绍核心模块。</p>
<h2 id="权重初始化">权重初始化</h2><pre><code><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.truncated_normal(shape, dtype=tf.float32, stddev=<span class="number">0.1</span>)
    <span class="keyword">return</span> tf.Variable(initial)

<span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.constant(<span class="number">0.1</span>, shape=shape)
    <span class="keyword">return</span> tf.Variable(initial, trainable=<span class="keyword">True</span>)

weights = {
    <span class="string">'wc1'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">64</span>]),
    <span class="string">'wc2'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">128</span>]),
    <span class="string">'wd1'</span>: weight_variable([<span class="number">4</span>*<span class="number">4</span>*<span class="number">12</span>, <span class="number">1024</span>]),
    <span class="string">'wd2'</span>: weight_variable([<span class="number">1024</span>, <span class="number">1024</span>]),
    <span class="string">'out'</span>: weight_variable([<span class="number">1024</span>, <span class="number">10</span>])
}
biases = {
    <span class="string">'bc1'</span>: bias_variable([<span class="number">64</span>]),
    <span class="string">'bc2'</span>: bias_variable([<span class="number">128</span>]),
    <span class="string">'bd1'</span>: bias_variable([<span class="number">1024</span>]),
    <span class="string">'bd2'</span>: bias_variable([<span class="number">1024</span>]),
    <span class="string">'out'</span>: bias_variable([n_classes])
}
</code></pre><h2 id="卷积层">卷积层</h2><p>这里的卷积参数使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。</p>
<pre><code>def <span class="function"><span class="title">conv2d</span><span class="params">(x, W, B, name)</span></span>:
    with tf.<span class="function"><span class="title">name_scope</span><span class="params">(name)</span></span> as scope:
        conv = tf<span class="class">.nn</span><span class="class">.conv2d</span>(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], <span class="attribute">padding</span>=<span class="string">'SAME'</span>)
        bias = tf<span class="class">.nn</span><span class="class">.bias_add</span>(conv, B)
        conv = tf<span class="class">.nn</span><span class="class">.relu</span>(bias, name=scope)
        return conv

conv1 = <span class="function"><span class="title">conv2d</span><span class="params">(images, weights[<span class="string">'wc1'</span>], biases[<span class="string">'bc1'</span>], <span class="string">'conv1'</span>)</span></span>
</code></pre><p>tensorflow里的padding参数支持<code>SAME</code>和<code>VALID</code>两种模式，设输入矩阵大小为<code>W*W</code>，卷积滤波器大小<code>F*F</code>，步长stride大小为<code>S</code>，则</p>
<pre><code><span class="preprocessor"># padding = <span class="string">'VALID'</span></span>
new_height = new_width = (W – F + <span class="number">1</span>) / S (结果向上取整)
<span class="preprocessor"># padding = <span class="string">'SAME'</span></span>
pad_needed_height = (new_height – <span class="number">1</span>) × S + F - W (结果向上取整，并在四周添加像素)
</code></pre><p>当new_height为奇数的时候，在顶部贴两个像素，在底部贴3个像素，而caffe和cuDNN是在两边各贴两个像素。这点不同，导致用caffe训练的模型转tensorflow的时候要慎用‘SAME’模式，切记！</p>
<h2 id="池化">池化</h2><p>池化分为均值池化<code>tf.nn.avg_pool</code>和max池化<code>tf.nn.max_pool</code>。这里的池化用简单传统的2x2大小的模板做max pooling。</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">avg_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.avg_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

pool1 = max_pool(conv1, k=<span class="number">2</span>, <span class="string">'pool1'</span>)
</code></pre><h2 id="归一化">归一化</h2><pre><code><span class="function"><span class="keyword">def</span> <span class="title">norm</span><span class="params">(x, lsize, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.lrn(x, lsize, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>, name=name)

norm1 = norm(pool1, lsize=<span class="number">4</span>, <span class="string">'norm1'</span>)
</code></pre><h2 id="全连接层">全连接层</h2><p>现在加一个1024维的全连接层，在池化层和全连接层连接处要将池化层输出的张量reshape成一向量</p>
<pre><code>pool2_flat = tf.<span class="function"><span class="title">reshape</span><span class="params">(pool2, [-<span class="number">1</span>, weights[<span class="string">'wd1'</span>].get_shape()</span></span>.<span class="function"><span class="title">as_list</span><span class="params">()</span></span>[<span class="number">0</span>]])
</code></pre><p>乘上权重矩阵，加上偏置，然后对其使用ReLU。</p>
<pre><code>fc1 = tf<span class="class">.nn</span><span class="class">.relu</span>(tf.<span class="function"><span class="title">matmul</span><span class="params">(pool2_flat, weights[<span class="string">'wd1'</span>])</span></span> + biases[<span class="string">'bd1'</span>])
</code></pre><h2 id="Dropout">Dropout</h2><p>用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 tensorflow学习（四）创建自己的CNN网络及可视化<code>tf.nn.dropout</code>操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。</p>
<pre><code>keep_prob = tf.<span class="function"><span class="title">placeholder</span><span class="params">(<span class="string">"float"</span>)</span></span>
fc1_drop = tf<span class="class">.nn</span><span class="class">.dropout</span>(fc1, keep_prob)
</code></pre><h2 id="Batch_Normalization">Batch Normalization</h2><p>《Batch Normalization: Accelerating Deep Network Training by  Reducing Internal Covariate Shift》文章中的batch normalization可以提高训练的收敛速度，甚至可以不使用dropout和L2正则就能取得很好的泛化能力，参考中文资料<a href="http://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="external">http://blog.csdn.net/happynear/article/details/44238541</a>。具体需要计算每个batch在该层所有特征图的均值和标准差，然后将上一层的输出归一化之后再送入下一层。</p>
<p>具体在tensorflow中，用<code>tf.nn.moments</code>求出axes对应的特征图维度的均值<code>mean</code>和标准差<code>variance</code>，然后用<code>tf.nn.batch_normalization</code>进行归一化，其中<code>offset</code>一般初始化为0，<code>scale</code>初始化为1，另外offset、scale的shape与mean相同，<code>variance_epsilon</code>这个参数设为一个很小的数就行，比如0.001。<br>需要强调一点的是，BN在神经网络进行training和testing的时候，所用的mean、variance是不一样的！以上的batch_normalization在训练的时候有效，测试阶段，只有一个样本输入，这时候网络参数固定，用之前训练好的均值和标准差作为参数传入即可。类似图片样本测试时候需要先减去均值，而这个均值文件是由训练样本生成的，差不多的道理。有一个不错的代码实现<a href="http://r2rt.com/implementing-batch-normalization-in-tensorflow.html" target="_blank" rel="external">http://r2rt.com/implementing-batch-normalization-in-tensorflow.html</a></p>
<pre><code>def <span class="function"><span class="title">batch_norm_wrapper</span><span class="params">(inputs, is_training, decay = <span class="number">0.999</span>)</span></span>:
    scale = tf.<span class="function"><span class="title">Variable</span><span class="params">(tf.ones([inputs.get_shape()</span></span>[-<span class="number">1</span>]]))
    beta = tf.<span class="function"><span class="title">Variable</span><span class="params">(tf.zeros([inputs.get_shape()</span></span>[-<span class="number">1</span>]]))
    pop_mean = tf.<span class="function"><span class="title">Variable</span><span class="params">(tf.zeros([inputs.get_shape()</span></span>[-<span class="number">1</span>]]), trainable=False)
    pop_var = tf.<span class="function"><span class="title">Variable</span><span class="params">(tf.ones([inputs.get_shape()</span></span>[-<span class="number">1</span>]]), trainable=False)

    <span class="keyword">if</span> is_training:
        batch_mean, batch_var = tf<span class="class">.nn</span><span class="class">.moments</span>(inputs,[<span class="number">0</span>])
        train_mean = tf.<span class="function"><span class="title">assign</span><span class="params">(pop_mean, pop_mean * decay + batch_mean * (<span class="number">1</span> - decay)</span></span>)
        train_var = tf.<span class="function"><span class="title">assign</span><span class="params">(pop_var, pop_var * decay + batch_var * (<span class="number">1</span> - decay)</span></span>)
        with tf.<span class="function"><span class="title">control_dependencies</span><span class="params">([train_mean, train_var])</span></span>:
            return tf<span class="class">.nn</span><span class="class">.batch_normalization</span>(inputs, batch_mean, batch_var, beta, scale, epsilon)
    <span class="keyword">else</span>:
        return tf<span class="class">.nn</span><span class="class">.batch_normalization</span>(inputs, pop_mean, pop_var, beta, scale, epsilon)

bn_z1 = <span class="function"><span class="title">batch_norm_wrapper</span><span class="params">(z1, is_training)</span></span>
</code></pre><h2 id="输出层">输出层</h2><p>普通输出层</p>
<pre><code>out = tf.<span class="function"><span class="title">matmul</span><span class="params">(fc2_drop, _weights[<span class="string">'out'</span>])</span></span> + _biases[<span class="string">'out'</span>]
</code></pre><p>使用softmax层</p>
<pre><code>out = tf<span class="class">.nn</span><span class="class">.softmax</span>(tf.<span class="function"><span class="title">matmul</span><span class="params">(fc2_drop, weights[<span class="string">'out'</span>])</span></span> + biases[<span class="string">'out'</span>])
</code></pre><h2 id="训练">训练</h2><p>定义损失函数，这里要注意在输出层是否使用了softmax，这里不要重复使用。这里使用的损失函数是真实值y与预测值y_pred之间的交叉熵。注意<code>tf.reduce_sum</code>是把minibatch里的每张图的交叉熵都加进来的。</p>
<pre><code>y_pred = tf<span class="class">.nn</span><span class="class">.softmax</span>(pred)
cost = -tf.<span class="function"><span class="title">reduce_sum</span><span class="params">(y * tf.log(y_pred)</span></span>)
</code></pre><p>或者调用系统函数更为方便，如下</p>
<pre><code>cost = tf.<span class="function"><span class="title">reduce_mean</span><span class="params">(tf.nn.softmax_cross_entropy_with_logits(pred, y)</span></span>)
</code></pre><p>tensorflow有大量的微分迭代优化算法，来对交叉熵进行梯度下降。</p>
<pre><code>optimizer = tf<span class="class">.train</span><span class="class">.GradientDescentOptimizer</span>(learning_rate=learning_rate).<span class="function"><span class="title">minimize</span><span class="params">(cost)</span></span>
optimizer = tf<span class="class">.train</span><span class="class">.AdamOptimizer</span>(learning_rate=learning_rate).<span class="function"><span class="title">minimize</span><span class="params">(cost)</span></span>
</code></pre><p>模型训练通过反复执行optimizer来更新参数：</p>
<pre><code>with tf.<span class="function"><span class="title">Session</span><span class="params">()</span></span> as sess:
    sess.<span class="function"><span class="title">run</span><span class="params">(init)</span></span>
    <span class="keyword">for</span> <span class="tag">i</span> <span class="keyword">in</span> <span class="function"><span class="title">range</span><span class="params">(<span class="number">1000</span>)</span></span>:
        batch = mnist<span class="class">.train</span><span class="class">.next_batch</span>(<span class="number">50</span>)
        sess.<span class="function"><span class="title">run</span><span class="params">(optimizer, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: dropout})</span></span>
</code></pre><p>tensorflow的<code>Session</code>和<code>InteractiveSession</code>方式不同。前者是构建完图对象后，通过run()整体执行全部操作，并通过close()释放资源。后者更为方便的进行交互，使用<code>Tensor.eval()</code>和<code>Operation.run()</code>方法代替<code>Session.run()</code>。在DQN这类算法中由于每次迭代都需要交互，所以使用<code>InteractiveSession</code>。</p>
<h2 id="评估模型">评估模型</h2><p>通过<code>tf.argmax</code>函数获得输出层中的最大值的索引位置，并将所有的测试样本的结果取平均值得到测试集上的准确率。注意在测试集中dropout参数设置为1，也就是没有dropout。</p>
<pre><code>correct_pred = tf.<span class="function"><span class="title">equal</span><span class="params">(tf.argmax(pred,<span class="number">1</span>)</span></span>, tf.<span class="function"><span class="title">argmax</span><span class="params">(y,<span class="number">1</span>)</span></span>)
accuracy = tf.<span class="function"><span class="title">reduce_mean</span><span class="params">(tf.cast(correct_pred, tf.float32)</span></span>)
acc = sess.<span class="function"><span class="title">run</span><span class="params">(accuracy, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: <span class="number">1</span>.})</span></span>
</code></pre><h2 id="MyNet网络完整训练代码">MyNet网络完整训练代码</h2><pre><code><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data
mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)

<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="comment"># Parameters</span>
learning_rate = <span class="number">0.001</span>
training_iters = <span class="number">200000</span>
batch_size = <span class="number">64</span>
display_step = <span class="number">20</span>

<span class="comment"># Network Parameters</span>
n_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span>
n_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span>
dropout = <span class="number">0.8</span> <span class="comment"># Dropout, probability to keep units</span>

<span class="comment"># tf Graph input</span>
x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_input])
y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_classes])
keep_prob = tf.placeholder(tf.float32) <span class="comment"># dropout (keep probability)</span>

<span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.truncated_normal(shape, dtype=tf.float32, stddev=<span class="number">0.1</span>)
    <span class="keyword">return</span> tf.Variable(initial)

<span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span>
    initial = tf.constant(<span class="number">0.1</span>, shape=shape)
    <span class="keyword">return</span> tf.Variable(initial, trainable=<span class="keyword">True</span>)

<span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W, B, name)</span>:</span>
    <span class="keyword">with</span> tf.name_scope(name) <span class="keyword">as</span> scope:
        conv = tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)
        bias = tf.nn.bias_add(conv, B)
        conv = tf.nn.relu(bias, name=scope)
        <span class="keyword">return</span> conv

<span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">avg_pool</span><span class="params">(x, k, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.avg_pool(x, ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">norm</span><span class="params">(x, lsize, name)</span>:</span>
    <span class="keyword">return</span> tf.nn.lrn(x, lsize, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span> / <span class="number">9.0</span>, beta=<span class="number">0.75</span>, name=name)

<span class="function"><span class="keyword">def</span> <span class="title">my_net</span><span class="params">(_x, _weights, _biases, _dropout)</span>:</span>
    _x = tf.reshape(_x, shape=[-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])

    conv1 = conv2d(_x, _weights[<span class="string">'wc1'</span>], _biases[<span class="string">'bc1'</span>], <span class="string">'conv1'</span>)
    pool1 = max_pool(conv1, k=<span class="number">2</span>, name=<span class="string">'pool1'</span>)
    norm1 = norm(pool1, lsize=<span class="number">4</span>, name=<span class="string">'norm1'</span>)

    conv2 = conv2d(norm1, _weights[<span class="string">'wc2'</span>], _biases[<span class="string">'bc2'</span>], <span class="string">'conv2'</span>)
    pool2 = max_pool(conv2, k=<span class="number">2</span>, name=<span class="string">'pool2'</span>)
    norm2 = norm(pool2, lsize=<span class="number">4</span>, name=<span class="string">'norm2'</span>)

    pool2_flat = tf.reshape(norm2, [-<span class="number">1</span>, _weights[<span class="string">'wd1'</span>].get_shape().as_list()[<span class="number">0</span>]])
    fc1 = tf.nn.relu(tf.matmul(pool2_flat, _weights[<span class="string">'wd1'</span>]) + _biases[<span class="string">'bd1'</span>])
    fc1_drop = tf.nn.dropout(fc1, _dropout)

    fc2 = tf.nn.relu(tf.matmul(fc1_drop, _weights[<span class="string">'wd2'</span>]) + _biases[<span class="string">'bd2'</span>])
    fc2_drop = tf.nn.dropout(fc2, _dropout)

    out = tf.matmul(fc2_drop, _weights[<span class="string">'out'</span>]) + _biases[<span class="string">'out'</span>]
    <span class="keyword">return</span> out

weights = {
    <span class="string">'wc1'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">64</span>]),
    <span class="string">'wc2'</span>: weight_variable([<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">128</span>]),
    <span class="string">'wd1'</span>: weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">128</span>, <span class="number">1024</span>]),
    <span class="string">'wd2'</span>: weight_variable([<span class="number">1024</span>, <span class="number">1024</span>]),
    <span class="string">'out'</span>: weight_variable([<span class="number">1024</span>, <span class="number">10</span>])
}
biases = {
    <span class="string">'bc1'</span>: bias_variable([<span class="number">64</span>]),
    <span class="string">'bc2'</span>: bias_variable([<span class="number">128</span>]),
    <span class="string">'bd1'</span>: bias_variable([<span class="number">1024</span>]),
    <span class="string">'bd2'</span>: bias_variable([<span class="number">1024</span>]),
    <span class="string">'out'</span>: bias_variable([n_classes])
}

<span class="comment"># Construct model</span>
pred = my_net(x, weights, biases, keep_prob)

<span class="comment"># Define loss and optimizer</span>
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

<span class="comment"># Evaluate model</span>
correct_pred = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

<span class="comment"># Initializing the variables</span>
init = tf.initialize_all_variables()

<span class="comment"># Launch the graph</span>
<span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:
    sess.run(init)
    step = <span class="number">1</span><span class="comment"># Keep training until reach max iterations</span>
    <span class="keyword">while</span> step * batch_size &lt; training_iters:
        batch = mnist.train.next_batch(batch_size)
        <span class="comment"># Fit training using batch data</span>
        sess.run(optimizer, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: dropout})
        <span class="keyword">if</span> step % display_step == <span class="number">0</span>:
            <span class="comment"># Calculate batch accuracy</span>
            acc = sess.run(accuracy, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: <span class="number">1.</span>})
            <span class="comment"># Calculate batch loss</span>
            loss = sess.run(cost, feed_dict={x: batch[<span class="number">0</span>], y: batch[<span class="number">1</span>], keep_prob: <span class="number">1.</span>})
            <span class="keyword">print</span> <span class="string">"Iter "</span> + str(step*batch_size) + <span class="string">", Minibatch Loss= "</span> + <span class="string">"{:.6f}"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + <span class="string">"{:.5f}"</span>.format(acc)
        step += <span class="number">1</span>
    <span class="keyword">print</span> <span class="string">"Optimization Finished!"</span>
    <span class="comment"># Calculate accuracy for 256 mnist test images</span>
    <span class="keyword">print</span> <span class="string">"Testing Accuracy:"</span>, sess.run(accuracy, feed_dict={x: mnist.test.images[:<span class="number">256</span>], y: mnist.test.labels[:<span class="number">256</span>], keep_prob: <span class="number">1.</span>})
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/05/28/tensorflow-cnn/" data-id="cjf3vykbx001cqgfh5q8astg5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-tensorboard" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/05/23/tensorflow-tensorboard/" class="article-date">
  <time datetime="2016-05-23T14:30:31.000Z" itemprop="datePublished">2016-05-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/23/tensorflow-tensorboard/">tensorflow学习（三）TensorBoard可视化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>利用TensorBoard可以更好的了解深度学习训练过程以及参数的变化。思想是将tensorflow中的图的节点通过summary操作汇总到一起，再通过Ssummary.FileWriter写进protobuf，最后通过TensorBoard展示可视化结果。</p>
<h2 id="Summary操作">Summary操作</h2><pre><code>tf<span class="class">.summary</span><span class="class">.scalar</span>(name, values, collections=None)
tf<span class="class">.summary</span><span class="class">.image</span>(name, tensor, max_outputs=None, collections=None)
tf<span class="class">.summary</span><span class="class">.histogram</span>(name, values, collections=None)
tf<span class="class">.summary</span><span class="class">.merge</span>(inputs, collections=None, name=None)
tf<span class="class">.summary</span><span class="class">.merge_all</span>(key=<span class="string">'summaries'</span>)
</code></pre><p>其中<code>summary.scalar</code>显示任意一个向量的数据，比如学习率或者loss。<br>其中<code>summary.image</code>可以显示节点中的4维的ndarray的数据。<br>其中<code>summary.histogram</code>用来显示多个数据的分布情况<br>以上创建的节点通过<code>merge_all</code>进行汇总合并。</p>
<h2 id="SummaryWriter类">SummaryWriter类</h2><p>通过合并汇总后的protobuf对象传递给<code>tf.summary.FileWriter</code>。其参数<code>logdir</code>指定事件存储路径，<code>add_graph</code>方法控制显示的图像。并通过session.run和<code>add_summary</code><br>写入。</p>
<h2 id="Demo">Demo</h2><p>这里我们用一个loss accuracy做一个summary的TensorBoard的demo，代码如下：</p>
<pre><code># normal step
<span class="label">...</span>
<span class="label">init</span> = tf.global_variables_initializer()

<span class="label">tf.summary.scalar</span>(<span class="string">'loss'</span>, cost)
<span class="label">tf.summary.scalar</span>(<span class="string">'accuracy'</span>, accuracy)
<span class="label">merged_summary_op</span> = tf.summary.merge_all()

<span class="label">with</span> tf.Seesion() as sess:
    sess.run(init)

    summary_writer = tf.summary.FileWriter(<span class="string">'/tmp/logs'</span>)
    summary_writer.<span class="keyword">add_graph(sess.graph)
</span>
    <span class="preprocessor">while</span> step * <span class="keyword">batch_size </span>&lt; training_iters:
        <span class="keyword">batch_xs, </span><span class="keyword">batch_ys </span>= mnist.train.next_batch(<span class="keyword">batch_size)
</span>        sess.run(optimizer, feed_dict={x: <span class="keyword">batch_xs, </span>y: <span class="keyword">batch_ys, </span>keep_prob: dropout})
        <span class="preprocessor">if</span> step % display_step == <span class="number">0</span>:
            acc = sess.run(accuracy, feed_dict={x: <span class="keyword">batch_xs, </span>y: <span class="keyword">batch_ys, </span>keep_prob: <span class="number">1</span>.})
            loss = sess.run(cost, feed_dict={x: <span class="keyword">batch_xs, </span>y: <span class="keyword">batch_ys, </span>keep_prob: <span class="number">1</span>.})

            summary_str = sess.run(merged_summary_op, feed_dict={x: <span class="keyword">batch_xs, </span>y: <span class="keyword">batch_ys, </span>keep_prob: <span class="number">1</span>.})
            summary_writer.<span class="keyword">add_summary(summary_str, </span>step)

        step += <span class="number">1</span>
</code></pre><h2 id="启动TensorBoard">启动TensorBoard</h2><p>执行命令：</p>
<pre><code>python tensorflow<span class="regexp">/tensorboard/</span>tensorboard.py --logdir=<span class="regexp">/tmp/</span>logs
</code></pre><p>或者直接执行</p>
<pre><code>tensorboard <span class="comment">--logdir=/tmp/logs</span>
</code></pre><p>然后通过浏览器打开<code>localhost:6006</code>，出来可视化界面后，就简单直观了，enjoy it！</p>
<h2 id="tips">tips</h2><ul>
<li>之前我的cnn代码里有valid_prediction，所以画出来的graph有两条分支，不太清晰，所以只留了train一个分支</li>
<li>多用with，进行包裹，这样才好看，正如官网说的，你的summary代码决定了你的图结构</li>
<li>不是所有的tensor都有必要记录，但是Variable和placeholder最好都用summary记录一下，也是为了好看</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/05/23/tensorflow-tensorboard/" data-id="cjf3vykb2000oqgfh0ghuleww" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-data" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/05/19/tensorflow-data/" class="article-date">
  <time datetime="2016-05-19T12:50:29.000Z" itemprop="datePublished">2016-05-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/05/19/tensorflow-data/">tensorflow学习（二）数据接口</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>网上的教程、官方的资料大多关注的都是如何使用模型，对于数据源的说明都比较简单。基本资料都是用的MNIST数据集做的实验。</p>
<h2 id="供给数据概述">供给数据概述</h2><p>tensorflow的模型数据读取还是非常友好的，最适合大量的数据的变量操作的形式应该是feed机制，利用<code>tf.placeholder()</code>为操作的变量创建占位符，在<code>run()</code>或<code>eval()</code>的时候调用参数，将变量x和其真实标签y_传入模型。代码如下：</p>
<pre><code>mnist = input_data.<span class="function"><span class="title">read_data_sets</span><span class="params">(<span class="string">'MNIST_data'</span>, one_hot=True)</span></span>

...

x = tf.<span class="function"><span class="title">placeholder</span><span class="params">(<span class="string">"float"</span>, shape=[None, <span class="number">784</span>])</span></span>
y_ = tf.<span class="function"><span class="title">placeholder</span><span class="params">(<span class="string">"float"</span>, shape=[None, <span class="number">10</span>])</span></span>

...

<span class="keyword">for</span> <span class="tag">i</span> <span class="keyword">in</span> <span class="function"><span class="title">range</span><span class="params">(<span class="number">1000</span>)</span></span>:
    batch = mnist<span class="class">.train</span><span class="class">.next_batch</span>(<span class="number">50</span>)
    train_step.<span class="function"><span class="title">run</span><span class="params">(feed_dict={x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>]})</span></span>
</code></pre><p>上述代码解析：<br>首先将图像数据转换到4维的uint8的ndarray类型数组<code>[index, y, x, depth]</code>。标签数据根据是否为one_hot，转换为一个uint8的整型数值或者变成一个只有一个数值为1，其他维度为0的向量。然后将这样的数据标签对保存为tensorflow的DataSet类中。本例中这样的操作通过<code>mnist = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True)</code>实现。然后将这样的数据通过占位符feed进模型。</p>
<h2 id="读取文件列表">读取文件列表</h2><p>我们可以通过一个文件列表来读入数据，之前都是通过python的glob来读取文件列表，也可以通过<code>tf.train.match_filenames_once</code>产生文件列表，然后交给<code>tf.train.string_input_producer</code>产生合适大小和是否乱序的文件名队列。</p>
<h2 id="读取文件">读取文件</h2><h3 id="图片文件">图片文件</h3><p>读入后为numpy的<code>array</code>格式，范围<code>[-1,1]</code>，通道为<code>[H,W,channels]</code>，代码如下</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">imread</span><span class="params">(self, file_name)</span>:</span>
    <span class="comment">#    image : an image with type np.float32 in range [-1, 1]</span>
    <span class="comment">#    of size (H x W x 3) in RGB or</span>
    <span class="comment">#    of size (H x W x 1) in grayscale.</span>
    img = skimage.img_as_float(skimage.io.imread(file_name, as_grey=<span class="keyword">False</span>)).astype(np.float32)
    img = img*<span class="number">2.0</span> - <span class="number">1.0</span>
    img_resize = skimage.transform.resize(img, (width, height, <span class="number">3</span>))
    img_resize = img_resize[:, :, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>)]
    <span class="keyword">return</span> img_resize
</code></pre><h3 id="csv文件">csv文件</h3><p>使用<code>tf.TextLineReader</code>读取文件的一行内容，然后通过<code>tf.decode_csv</code>来解析这一行内容并将其转为张量列表</p>
<h3 id="二进制文件读取固定长度">二进制文件读取固定长度</h3><p>从二进制文件中读取固定长度纪录， 可以使用<code>tf.FixedLengthRecordReader</code>的<code>tf.decode_raw</code>操作。<code>decode_raw</code>操作可以讲一个字符串转换为一个uint8的张量。例程中的cifar-10的数据集的读入就是通过这个方式。</p>
<h3 id="标准TensorFlow格式TFRecords文件">标准TensorFlow格式TFRecords文件</h3><p>将数据填入到Example协议内存块(protocol buffer)，将协议内存块序列化为一个字符串，并且通过<code>tf.python_io.TFRecordWriter</code>写入到TFRecords文件。通过传参images和labels将数据和标签数据保存到tfrecords中，代码如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">_int64_feature</span><span class="params">(value)</span>:</span>
    <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

<span class="function"><span class="keyword">def</span> <span class="title">_bytes_feature</span><span class="params">(value)</span>:</span>
    <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

<span class="function"><span class="keyword">def</span> <span class="title">convert_to</span><span class="params">(images, labels, name)</span>:</span>
    num_examples = labels.shape[<span class="number">0</span>]
    <span class="keyword">if</span> images.shape[<span class="number">0</span>] != num_examples:
        <span class="keyword">raise</span> ValueError(<span class="string">"Images size %d does not match label size %d."</span> % (images.shape[<span class="number">0</span>], num_examples))
    rows = images.shape[<span class="number">1</span>]
    cols = images.shape[<span class="number">2</span>]
    depth = images.shape[<span class="number">3</span>]

    filename = os.path.join(FLAGS.directory, name + <span class="string">'.tfrecords'</span>)
    print(<span class="string">'Writing'</span>, filename)
    writer = tf.python_io.TFRecordWriter(filename)
    <span class="keyword">for</span> index <span class="keyword">in</span> range(num_examples):
        image_raw = images[index].tostring()
        example = tf.train.Example(features=tf.train.Features(feature={
            <span class="string">'height'</span>: _int64_feature(rows),
            <span class="string">'width'</span>: _int64_feature(cols),
            <span class="string">'depth'</span>: _int64_feature(depth),
            <span class="string">'label'</span>: _int64_feature(int(labels[index])),
            <span class="string">'image_raw'</span>: _bytes_feature(image_raw)}))
        writer.write(example.SerializeToString())
    writer.close()
</code></pre><p>从TFRecords文件中读取数据，可以使用<code>tf.TFRecordReader</code>的<code>tf.parse_single_example</code>解析器。这个<code>parse_single_example</code>操作可以将Example协议内存块(protocol buffer)解析为张量。通过train参数传入TFRecords文件返回值是图像标签对。代码如下：</p>
<pre><code><span class="function"><span class="keyword">def</span> <span class="title">read_and_decode</span><span class="params">(filename_queue)</span>:</span>
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example,
        <span class="comment"># Defaults are not specified since both keys are required.</span>
        features={
            <span class="string">'image_raw'</span>: tf.FixedLenFeature([], tf.string),
            <span class="string">'label'</span>: tf.FixedLenFeature([], tf.int64),
        })

    <span class="comment"># Convert from a scalar string tensor (whose single string has</span>
    <span class="comment"># length mnist.IMAGE_PIXELS) to a uint8 tensor with shape</span>
    <span class="comment"># [mnist.IMAGE_PIXELS].</span>
    image = tf.decode_raw(features[<span class="string">'image_raw'</span>], tf.uint8)
    image.set_shape([mnist.IMAGE_PIXELS])

    <span class="comment"># Convert from [0, 255] -&gt; [-0.5, 0.5] floats.</span>
    image = tf.cast(image, tf.float32) * (<span class="number">1.</span> / <span class="number">255</span>) - <span class="number">0.5</span>
    <span class="comment"># Convert label from a scalar uint8 tensor to an int32 scalar.</span>
    label = tf.cast(features[<span class="string">'label'</span>], tf.int32)

    <span class="keyword">return</span> image, label


<span class="function"><span class="keyword">def</span> <span class="title">inputs</span><span class="params">(train, batch_size, num_epochs)</span>:</span>
    <span class="keyword">if</span> <span class="keyword">not</span> num_epochs: num_epochs = <span class="keyword">None</span>
    filename = os.path.join(FLAGS.train_dir, TRAIN_FILE <span class="keyword">if</span> train <span class="keyword">else</span> VALIDATION_FILE)

    <span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):
        filename_queue = tf.train.string_input_producer([filename], num_epochs=num_epochs)
        image, label = read_and_decode(filename_queue)

        <span class="keyword">return</span> image, label
</code></pre><h2 id="批处理">批处理</h2><p>TBD</p>
<h2 id="创建线程并使用QueueRunner对象来预取">创建线程并使用QueueRunner对象来预取</h2><p>TBD</p>
<h2 id="训练模型保存和恢复">训练模型保存和恢复</h2><p>通过实例化一个<code>tf.train.Saver</code>来实现模型的保存。</p>
<pre><code>saver = tf<span class="class">.train</span><span class="class">.Saver</span>()
saver.<span class="function"><span class="title">save</span><span class="params">(sess, FLAGS.train_dir, global_step=step)</span></span>
</code></pre><p>在训练循环中，将定期调用<code>saver.save()</code>方法，向训练文件夹中写入包含了当前所有可训练参数的检查点文件。<br>恢复检查点的时候使用<code>saver.restore()</code>方法，重载模型的参数，继续训练。</p>
<pre><code>saver.<span class="function"><span class="title">restore</span><span class="params">(sess, FLAGS.train_dir)</span></span>
</code></pre><h2 id="参考资料">参考资料</h2><p><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/05/19/tensorflow-data/" data-id="cjf3vykbx0019qgfh5kdg8tdv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-tensorflow-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/20/tensorflow-install/" class="article-date">
  <time datetime="2016-04-20T12:46:00.000Z" itemprop="datePublished">2016-04-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/20/tensorflow-install/">tensorflow学习（一）安装配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>tensorflow是google开源的深度学习平台，由于其性能比较差，一开始我是拒绝的，不过由于google强大的影响力和执行力，版本迭代更新很快，现在性能已经很快了，而且最新的版本也支持了分布式。而且tensorflow的中文文档也是所有开源框架里最完善的，所以近期抽空学习一下。还是先从安装搞起。<br>虽然其有比较完善的官方文档<a href="https://www.tensorflow.org/" target="_blank" rel="external">https://www.tensorflow.org/</a>以及其中文版本<a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/</a>，但使用的时候还是发现存在一些坑，还是记录一下学习过程中遇到的问题。<br>tensorflow支持pip、virtualenv、Docker三种安装方式。我这里只尝试了最简单方便的pip安装。</p>
<h2 id="安装环境">安装环境</h2><p>我的电脑是centOS 7.0，k40双卡</p>
<h2 id="CUDA和cudnn">CUDA和cudnn</h2><p>参考之前教程，安装CUDA和cudnn。我这里的CUDA版本是7.0，cudnn版本是v3。<br>再安装six和protobuf到对应版本，tensorflow要求’six &gt;= 1.10.0, protobuf &gt;= 3.0.0b2’，网上下载对应的whl包，执行</p>
<pre><code><span class="tag">pip</span> <span class="tag">install</span> <span class="tag">six-1</span><span class="class">.10</span><span class="class">.0-py2</span><span class="class">.py3-none-any</span><span class="class">.whl</span>
<span class="tag">pip</span> <span class="tag">install</span> <span class="tag">protobuf</span>
</code></pre><h2 id="pip安装tensorflow">pip安装tensorflow</h2><p>根据官方教程，应该执行如下命令</p>
<pre><code><span class="comment"># 仅使用 CPU 的版本</span>
pip install <span class="symbol">https:</span>/<span class="regexp">/storage.googleapis.com/tensorflow</span><span class="regexp">/linux/cpu</span><span class="regexp">/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
# 开启 GPU 支持的版本 (安装该版本的前提是已经安装了 CUDA sdk)
pip install https:/</span><span class="regexp">/storage.googleapis.com/tensorflow</span><span class="regexp">/linux/gpu</span><span class="regexp">/tensorflow-0.7.1-cp27-none-linux_x86_64.whl</span>
</code></pre><p>但是由于GFW原因，上述命令可能会超时失败，于是寻找其他whl包的位置。<br>在官方的github上很容易找到其对应的安装版本。<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">https://github.com/tensorflow/tensorflow</a>，我这里使用的版本是python2的GPU版本。</p>
<pre><code># 开启 GPU 支持的版本 (安装该版本的前提是已经安装了 CUDA sdk)
pip <span class="operator"><span class="keyword">install</span> <span class="keyword">http</span>://ci.tensorflow.org/<span class="keyword">view</span>/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-<span class="keyword">slave</span>/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-<span class="number">0.7</span><span class="number">.1</span>-cp27-<span class="keyword">none</span>-linux_x86_64.whl</span>
</code></pre><p>安装成功。<br>但是在<code>import tensorflow</code>的时候会报错说ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory，可恶，我明明装的是CUDA7.0，竟然报错找不到7.5，解决这个问题也很简单，只需要把7.0做个软链接弄个名7.5骗过tensorflow就行，代码如下：</p>
<pre><code>sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64<span class="regexp">/libcudart.so.7.0 /u</span>sr<span class="regexp">/local/</span>cuda<span class="regexp">/lib64/</span>libcudart.so.<span class="number">7.5</span>
sudo ln -s <span class="regexp">/usr/</span>local<span class="regexp">/cuda/</span>lib64<span class="regexp">/libcublas.so.7.0 /u</span>sr<span class="regexp">/local/</span>cuda<span class="regexp">/lib64/</span>libcublas.so.<span class="number">7.5</span>
</code></pre><h2 id="运行tensorflow">运行tensorflow</h2><p>在python终端执行如下代码：</p>
<pre><code>import tensorflow as tf
hello = tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="string">'Hello, TensorFlow!'</span>)</span></span>
sess = tf.<span class="function"><span class="title">Session</span><span class="params">()</span></span>
print sess.<span class="function"><span class="title">run</span><span class="params">(hello)</span></span>
<span class="tag">a</span> = tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="number">10</span>)</span></span>
<span class="tag">b</span> = tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="number">32</span>)</span></span>
print sess.<span class="function"><span class="title">run</span><span class="params">(a+b)</span></span>
</code></pre><p>顺利运行表明tensorflow安装完成。</p>
<h2 id="源码路径以及示例">源码路径以及示例</h2><p>由于我的python是anaconda版本，所以tensorflow会安装在’$HOME/anaconda/lib/python2.7/site-packages/tensorflow’。<br>运行第一个示例，如下：</p>
<pre><code>cd <span class="variable">$HOME</span>/anaconda/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">tensorflow</span></span>
python ./models/image/mnist/convolutional.py
</code></pre><p>程序会下载mnist数据集，迭代训练，显示当前loss、学习率以及误差。</p>
<h2 id="GLIBC的版本问题解决方案">GLIBC的版本问题解决方案</h2><p>在CentOS/RHEL 6的操作系统中，GLIBC的版本可能不满足tensorflow的要求，在<code>import tensorflow</code>的时候会报错</p>
<pre><code>ImportError: /lib64/libc.<span class="keyword">so</span>.6: <span class="keyword">version</span> `GLIBC_2.15' not found (required <span class="keyword">by</span> /home/15072585/anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.<span class="keyword">so</span>)
</code></pre><p>通过命令查看<code>/lib64/libc.so.6</code>的GLIBC版本：</p>
<pre><code>strings <span class="regexp">/lib64/</span>libc.so.<span class="number">6</span> |<span class="keyword">grep</span> GLIBC
</code></pre><p>可以看到其只支持到2.12，不能支持高版本。解决方案：</p>
<pre><code>mkdir ~/my_libc_env
cd ~/my_libc_env
wget http:<span class="comment">//launchpadlibrarian.net/137699828/libc6_2.17-0ubuntu5_amd64.deb</span>
wget http:<span class="comment">//launchpadlibrarian.net/137699829/libc6-dev_2.17-0ubuntu5_amd64.deb</span>
wget ftp:<span class="comment">//rpmfind.net/linux/sourceforge/m/ma/magicspecs/apt/3.0/x86_64/RPMS.lib/libstdc++-4.8.2-7mgc30.x86_64.rpm</span>
ar p libc6_2<span class="number">.17</span>-<span class="number">0u</span>buntu5_amd64.deb data.tar.gz | tar zx
ar p libc6-dev_2<span class="number">.17</span>-<span class="number">0u</span>buntu5_amd64.deb data.tar.gz | tar zx
rpm2cpio libstdc++-<span class="number">4.8</span><span class="number">.2</span>-<span class="number">7</span>mgc30.x86_64.rpm| cpio -idmv
</code></pre><p>以后想执行支持tensorflow的python版本的时候需要执行命令：</p>
<pre><code><span class="constant">LD_LIBRARY_PATH</span>=<span class="string">"$HOME/my_libc_env/lib/x86_64-linux-gnu/:$HOME/my_libc_env/usr/lib64/"</span> <span class="variable">$HOME</span>/my_libc_env/<span class="class"><span class="keyword">lib</span>/<span class="title">x86_64</span>-<span class="title">linux</span>-<span class="title">gnu</span>/<span class="title">ld</span>-2.17.<span class="title">so</span> `<span class="title">which</span> <span class="title">python</span>`</span>
</code></pre><h3 id="GLIBC版本升级注意事项">GLIBC版本升级注意事项</h3><p>注意GLIBC这是一个根本的库，不能轻易升级。非要升级的话，首先查看当前的libc的指向</p>
<pre><code>ll /lib64/libc<span class="class">.so</span>.<span class="number">6</span>
</code></pre><p>获取高级版本的libc.so，比如/lib64/libc-2.15.so，这个步骤非常繁琐，编译生成很麻烦。我是通过从另外高级版本的机器copy过来使用的，所以没有生成，过程隐去。<br>接下来就是将软链接指向新的libc，实际操作注意rm原来的链接之后，系统的大部分命令都无法使用了，要用<code>LD_PRELOAD=/lib64/libc-2.15.so</code>指定所使用的libc才能运行shell命令。代码如下：</p>
<pre><code>rm -rf /lib64/libc.so.<span class="number">6</span>
LD_PRELOAD=<span class="regexp">/lib64/libc</span>-<span class="number">2.15</span>.so ln -<span class="regexp">s/lib64/libc-2.15.so  lib64/libc</span>.so.<span class="number">6</span>
</code></pre><h1 id="基于源码安装(不建议)">基于源码安装(不建议)</h1><h2 id="安装jdk">安装jdk</h2><p>bazel依赖于jdk，网上都是安装JDK 8，由于centos默认是JDK 7，并且我们项目用的java版本也是1.7，所以去bazel官网看了一下，也是支持JDK 7的。所以这里没安装java</p>
<h2 id="安装bazel">安装bazel</h2><pre><code>git clone http<span class="variable">s:</span>//github.<span class="keyword">com</span>/bazelbuild/bazel.git
<span class="keyword">cd</span> bazel
./compile.<span class="keyword">sh</span>
sudo
<span class="keyword">cp</span> output/bazel /usr/local/bin/
</code></pre><h2 id="编译tensorflow">编译tensorflow</h2><pre><code>git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/tensorflow</span><span class="regexp">/tensorflow
cd tensorflow
./configure</span>
<span class="comment"># choose with Google Cloud Platform / with GPU</span>
bazel build -c opt --config=cuda /<span class="regexp">/tensorflow/tools</span><span class="regexp">/pip_package:build_pip_package
bazel-bin/tensorflow</span><span class="regexp">/tools/pip</span>_package/build_pip_package /tmp/tensorflow_pkg
pip install /tmp/tensorflow_pkg/tensorflow-<span class="number">0.10</span>.<span class="number">0</span>-py2-none-any.whl
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/20/tensorflow-install/" data-id="cjf3vykbi0010qgfhi7kj4go8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-panns-nnsearch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/11/panns-nnsearch/" class="article-date">
  <time datetime="2016-04-11T13:01:36.000Z" itemprop="datePublished">2016-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/11/panns-nnsearch/">高维海量数据快速检索库</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="falconn">falconn</h1><p>这个库使用的是局部敏感哈希构建索引。效率较高。</p>
<h3 id="python实现">python实现</h3><p>官方的api文档<a href="https://falconn-lib.org/pdoc/falconn/" target="_blank" rel="external">https://falconn-lib.org/pdoc/falconn/</a>其实非常详细，这里把其中关键的地方再提炼一下。<br>安装非常简单</p>
<pre><code>pip <span class="keyword">install</span> falconn
</code></pre><p>数据准备，需要将所有的索引特征存储到一个numpy的二维array中，其中每行代表一个数据，行数表示数据点数，列表示特征维度。注意，最好把数据转换为float32数据类型，提高算法性能，并将数据归一化减去均值，提高算法性能。具体操作如下</p>
<pre><code>dataset = dataset.<span class="function"><span class="title">astype</span><span class="params">(numpy.float32)</span></span>
dataset -= numpy.<span class="function"><span class="title">mean</span><span class="params">(dataset, axis=<span class="number">0</span>)</span></span>
</code></pre><p>构建哈希超参数，将数据维度和点数传入<code>get_default_parameters</code>获得合适的超参数，得到的超参数可以通过手动微调或者<code>compute_number_of_hash_functions</code>来对其中细节进行微调。</p>
<pre><code>num_points, dim = dataset<span class="class">.shape</span>
parms = falconn.<span class="function"><span class="title">get_default_parameters</span><span class="params">(num_points, dim)</span></span>
falconn.<span class="function"><span class="title">compute_number_of_hash_functions</span><span class="params">(<span class="number">7</span>, parms)</span></span>
</code></pre><p>创建索引实例<code>LSHIndex</code>，并通过方法<code>setup</code>构建索引。</p>
<pre><code>lsh_index = falconn.<span class="function"><span class="title">LSHIndex</span><span class="params">(parms)</span></span>
lsh_index.<span class="function"><span class="title">setup</span><span class="params">(dataset)</span></span>
</code></pre><p>查询的函数有很多，可以根据需要进行选择</p>
<pre><code><span class="function"><span class="title">find_k_nearest_neighbors</span><span class="params">()</span></span>
<span class="function"><span class="title">find_near_neighbors</span><span class="params">()</span></span>
<span class="function"><span class="title">find_nearest_neighbor</span><span class="params">()</span></span>
<span class="function"><span class="title">get_candidates_with_duplicates</span><span class="params">()</span></span>
<span class="function"><span class="title">get_unique_candidates</span><span class="params">()</span></span>
</code></pre><h3 id="C++实现">C++实现</h3><p>TBD</p>
<h1 id="Panns">Panns</h1><p><a href="https://github.com/ryanrhymes/panns" target="_blank" rel="external">https://github.com/ryanrhymes/panns</a>这是一个用python写的针对高维数据的approximate k-nearest neighbors算法包，目前支持欧式距离和余弦距离两种度量。对500维以上的高维特征进行了优化。虽然性能弱于Annoy，但是更加轻量，比FLANN和scikit-learn更为好用</p>
<h3 id="安装">安装</h3><pre><code>sudo pip <span class="operator"><span class="keyword">install</span> panns <span class="comment">--upgrade</span></span>
</code></pre><h3 id="使用示例">使用示例</h3><pre><code><span class="keyword">from</span> panns import *

# <span class="keyword">create</span> an <span class="keyword">index</span> <span class="keyword">of</span> Euclidean distance
p = PannsIndex(dimension=<span class="number">100</span>, metric=<span class="string">'euclidean'</span>)

# generate a <span class="number">1000</span> x <span class="number">100</span> dataset
<span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1000</span>):
    v = gaussian_vector(<span class="number">100</span>)
    p.add_vector(v)

p.parallelize(<span class="keyword">True</span>)        # 多核并行，默认是<span class="keyword">False</span>
# build an <span class="keyword">index</span> <span class="keyword">of</span> <span class="number">128</span> trees <span class="keyword">and</span> save <span class="keyword">to</span> a file
p.build(<span class="number">128</span>)    # <span class="number">64</span> <span class="keyword">is</span> <span class="keyword">default</span>
</code></pre><p>build之后调用save函数保存生成的索引，会生成两个文件<em>.idx保存索引树和</em>.idx.npy保存数据库向量矩阵，这个向量矩阵可以保存成内存文件或者mmap文件，根据如下注释选取保存类型。这两个文件要放在同一个目录下面，加载模型的时候才不会出错。</p>
<pre><code># save the index as an in-memory file if the raw dataset is small or medium size
# later panns will <span class="operator"><span class="keyword">load</span> the entire .npy <span class="keyword">file</span> <span class="keyword">in</span> <span class="keyword">to</span> the <span class="keyword">physical</span> <span class="keyword">memory</span>
<span class="keyword">p</span>.<span class="keyword">save</span>(<span class="string">'test.idx'</span>, mmap=<span class="literal">False</span>)

# <span class="keyword">save</span> the <span class="keyword">index</span> <span class="keyword">as</span> mmap <span class="keyword">file</span> <span class="keyword">if</span> the <span class="keyword">raw</span> dataset <span class="keyword">is</span> huge
# usually, your OS will handle the dynamic loading
<span class="keyword">p</span>.<span class="keyword">save</span>(<span class="string">'test.idx'</span>, mmap=<span class="literal">True</span>)</span>
</code></pre><p>加载模型，查询索引，返回最近邻的前10个查询结果</p>
<pre><code>p1 = <span class="function"><span class="title">PannsIndex</span><span class="params">(metric=<span class="string">'euclidean'</span>)</span></span>
p1.<span class="function"><span class="title">load</span><span class="params">(<span class="string">'test.idx'</span>)</span></span>
v1 = <span class="function"><span class="title">a_new_vector</span><span class="params">(<span class="number">100</span>)</span></span>
n = p1.<span class="function"><span class="title">query</span><span class="params">(v1, <span class="number">10</span>)</span></span>
</code></pre><h1 id="Annoy">Annoy</h1><p><a href="https://github.com/spotify/annoy" target="_blank" rel="external">https://github.com/spotify/annoy</a>这是一个用C++编写的python打包的最近邻搜索算法包，应该是目前性能最好的算法包。</p>
<h3 id="安装-1">安装</h3><pre><code>pip <span class="keyword">install</span> annoy
</code></pre><h3 id="实例">实例</h3><p>tbd</p>
<h2 id="参考资料">参考资料</h2><p><a href="http://yongyuan.name/blog/index-billion-deep-descriptors.html" target="_blank" rel="external">机器视觉：十亿规模的深度描述子如何有效索引</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/11/panns-nnsearch/" data-id="cjf3vykcz0025qgfhmyaodxrv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nnsearch/">nnsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-data-visualization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/07/data-visualization/" class="article-date">
  <time datetime="2016-04-07T14:39:17.000Z" itemprop="datePublished">2016-04-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/07/data-visualization/">数据可视化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>经常看到网上一些样本分布图画的非常漂亮，不知道是怎么画出来的，在网上找到了一个好资料<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/#raw_mnist" target="_blank" rel="external">http://colah.github.io/posts/2014-10-Visualizing-MNIST/#raw_mnist</a>，代码参考的这个<a href="https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm" target="_blank" rel="external">https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm</a>研究了一番总结一下。</p>
<p>我们经常要分析一些高维特征的表现能力，由于我们人类只能理解二维、三维的东西，所以要把高维数据降到三维以内展示出来。</p>
<h3 id="直观想法">直观想法</h3><p>最直观的想法，比如原数据有1000维，从中任意选择两维，然后画图，结果可想而知。</p>
<h3 id="PCA">PCA</h3><p>一种改进办法就是选择更为合适的两个维度进行展示，于是选择PCA主成分分析，然后选择前两个主成分对应的维度作为可视化的两个维度。</p>
<h2 id="降维优化算法">降维优化算法</h2><p>可视化的目标就是希望两个向量实际的距离能够跟显示的距离接近，本来向量距离远的显示的距离也远。这就变成了一个优化问题，这也是很多流形学习方法的目标。比较常用解决这个优化问题的方法有MDS和t-SNE</p>
<h3 id="MDS">MDS</h3><p>结合代码分析，首先，加载必要模块</p>
<pre><code>from sklearn <span class="preprocessor"><span class="keyword">import</span> manifold</span>
<span class="preprocessor"><span class="keyword">import</span> matplotlib.pyplot as plt</span>
<span class="preprocessor"><span class="keyword">import</span> seaborn</span>
<span class="preprocessor"><span class="keyword">import</span> numpy as np</span>
</code></pre><p>首先加载数据，用array存储数据以及对应标签。这里用scikit-learn中的digits手写字符数据集作为演示数据，加载之后，其data维度为1797<em>64，图片是8</em>8=64，target维度为1797*1，为0~9的整数。同时加载seaborn模块中的调色板，用这个模板生成的颜色比自己设计的要好看一些</p>
<pre><code>from sklearn<span class="class">.datasets</span> import load_digits
digits = <span class="function"><span class="title">load_digits</span><span class="params">()</span></span>
palette = np.<span class="function"><span class="title">array</span><span class="params">(seaborn.color_palette(<span class="string">'hls'</span>, <span class="number">10</span>)</span></span>)
x = digits<span class="class">.data</span>
y = digits.target
</code></pre><p>加载mds模型</p>
<pre><code>mds = manifold.<span class="function"><span class="title">MDS</span><span class="params">(n_components=<span class="number">2</span>, max_iter=<span class="number">300</span>, eps=<span class="number">1</span>e-<span class="number">5</span>)</span></span>
x_mds = mds.<span class="function"><span class="title">fit_transform</span><span class="params">(x)</span></span>
</code></pre><p>画图</p>
<pre><code>fig = plt.<span class="function"><span class="title">figure</span><span class="params">()</span></span>
plt.<span class="function"><span class="title">scatter</span><span class="params">(x_mds[:,<span class="number">0</span>], x_mds[:,<span class="number">1</span>], c=palette[y])</span></span>
plt.<span class="function"><span class="title">show</span><span class="params">()</span></span>
</code></pre><h3 id="t-SNE">t-SNE</h3><p>加载数据与上一种方法相同，加载模型代码如下</p>
<pre><code>tsne = manifold.<span class="function"><span class="title">TSNE</span><span class="params">(n_components=<span class="number">2</span>, learning_rate=<span class="number">1000.0</span>)</span></span>
x_tsne = tsne.<span class="function"><span class="title">fit_transform</span><span class="params">(x)</span></span>
</code></pre><h2 id="显示动态流形变化图像">显示动态流形变化图像</h2><p>TBD</p>
<h2 id="可视化参考资料">可视化参考资料</h2><p><a href="http://distill.pub/2016/misread-tsne/" target="_blank" rel="external">how to use t-SNE effectively</a><a href="https://yq.aliyun.com/articles/62946" target="_blank" rel="external">中文翻译</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/07/data-visualization/" data-id="cjf3vykea003hqgfhb3d81xiv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/visualization/">visualization</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-good-site" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/30/good-site/" class="article-date">
  <time datetime="2016-03-30T11:18:48.000Z" itemprop="datePublished">2016-03-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/life/">life</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/30/good-site/">good_site</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在线简历生成网站<a href="https://cvmkr.com/" target="_blank" rel="external">https://cvmkr.com/</a><br>翻墙路由器的原理与实现<a href="http://drops.wooyun.org/papers/10177" target="_blank" rel="external">http://drops.wooyun.org/papers/10177</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/30/good-site/" data-id="cjf3vykdu0030qgfh4p6okeku" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/生活/">生活</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-darknet-yolo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/25/darknet-yolo/" class="article-date">
  <time datetime="2016-03-25T13:54:01.000Z" itemprop="datePublished">2016-03-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/25/darknet-yolo/">darknet学习（一）YOLO目标检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="darknet安装">darknet安装</h1><p>darknet的安装还是非常简单的，依赖只有cuda和opencv，安装好之后执行以下命令即可安装编译成功</p>
<pre><code>git clone <span class="attribute">https</span>:<span class="regexp">//gi</span>thub.com/pjreddie/darknet.git
cd darknet
vim Makefile
<span class="comment">######</span><span class="comment">######</span><span class="comment">#####[modify Makefile]
GPU=1
OPENCV=1
OPTS=-Ofast  # 如果gcc版本过低，这里可能需要改成-O3
###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">##[close]</span>
make
</code></pre><h1 id="YOLO训练">YOLO训练</h1><h2 id="准备训练数据">准备训练数据</h2><p>检测算法需要对图像中的目标区域进行标注，我这里实验只准备了5个类别的检测数据，我用python基于OpenCV做了一个简单的标注工具，可以得到矩形左上角、右下角的坐标位置，代码如下：</p>
<pre><code><span class="keyword">import</span> os
<span class="keyword">import</span> cv2
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> copy
<span class="keyword">import</span> glob
<span class="keyword">import</span> sys


<span class="comment">#PT1 = (0,0)</span>
<span class="comment">#PT2 = (0,0)</span>
<span class="function"><span class="keyword">def</span> <span class="title">draw_box</span><span class="params">(event, x, y, flags, param)</span>:</span>
    <span class="keyword">global</span> PT1
    <span class="keyword">global</span> PT2
    <span class="keyword">global</span> img_copy
    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONDOWN <span class="keyword">and</span> flags == cv2.EVENT_FLAG_LBUTTON:    
        PT1 = (x,y)
        PT2 = (x,y)
    <span class="keyword">if</span> flags == cv2.EVENT_FLAG_LBUTTON:
        PT2 = (x,y)
    <span class="keyword">if</span> event == cv2.EVENT_LBUTTONUP:
        PT2 = (x,y)
    cv2.rectangle(img_copy, PT1, PT2, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)
    cv2.imshow(<span class="string">'image'</span>, img_copy)
    img_copy = copy.deepcopy(img)


<span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:
    img_path = <span class="string">'D:/test'</span>
    img_list = glob.glob(os.path.join(img_path, <span class="string">'*.jpg'</span>))
    img_list = sorted(img_list)
<span class="comment">#    print img_list</span>
    box_result_name = <span class="string">'box_result.txt'</span>
    img_processed = []
    <span class="keyword">try</span>:
        <span class="keyword">with</span> open(os.path.join(img_path, box_result_name), <span class="string">'rb'</span>) <span class="keyword">as</span> f_box:
            <span class="keyword">for</span> line <span class="keyword">in</span> f_box.readlines():
                line = line.strip().split(<span class="string">','</span>)
                img_processed.append(line[<span class="number">0</span>])
    <span class="keyword">except</span> IOError:
        <span class="keyword">pass</span>
    img_processed = set(img_processed)

    cv2.namedWindow(<span class="string">'image'</span>)
    cv2.setMouseCallback(<span class="string">'image'</span>, draw_box)

    f_box = open(os.path.join(img_path, box_result_name), <span class="string">'a'</span>)
    <span class="keyword">for</span> img_name <span class="keyword">in</span> img_list:
        <span class="keyword">print</span> img_name
        <span class="keyword">if</span> img_name <span class="keyword">in</span> img_processed:
            <span class="keyword">continue</span>
        img = cv2.imread(img_name)
        img_copy = copy.deepcopy(img)
        PT1 = (<span class="number">0</span>,<span class="number">0</span>)
        PT2 = (<span class="number">0</span>,<span class="number">0</span>)

        <span class="keyword">while</span> (<span class="number">1</span>):
            key = cv2.waitKey(<span class="number">0</span>)
            <span class="keyword">if</span> key == <span class="number">27</span>:
                cv2.destroyAllWindows()
                f_box.close()
                sys.exit(<span class="number">0</span>)
            <span class="keyword">elif</span> key == <span class="number">32</span>:
                <span class="keyword">if</span> PT1[<span class="number">0</span>]==<span class="number">0</span> <span class="keyword">or</span> PT1[<span class="number">1</span>]==<span class="number">0</span> <span class="keyword">or</span> PT2[<span class="number">0</span>]==<span class="number">0</span> <span class="keyword">or</span> PT2[<span class="number">1</span>]==<span class="number">0</span> <span class="keyword">or</span> abs(PT2[<span class="number">0</span>]-PT1[<span class="number">0</span>])&lt;<span class="number">10</span> <span class="keyword">or</span> abs(PT2[<span class="number">1</span>]-PT1[<span class="number">1</span>])&lt;<span class="number">10</span>:
                    <span class="keyword">continue</span>
                <span class="keyword">if</span> PT1[<span class="number">0</span>] &lt; PT2[<span class="number">0</span>]:
                    x1 = PT1[<span class="number">0</span>]
                    x2 = PT2[<span class="number">0</span>]
                <span class="keyword">else</span>:
                    x1 = PT2[<span class="number">0</span>]
                    x2 = PT1[<span class="number">0</span>]
                <span class="keyword">if</span> PT1[<span class="number">1</span>] &lt; PT2[<span class="number">1</span>]:
                    y1 = PT1[<span class="number">1</span>]
                    y2 = PT2[<span class="number">1</span>]
                <span class="keyword">else</span>:
                    y1 = PT2[<span class="number">1</span>]
                    y2 = PT1[<span class="number">1</span>]
                f_box.write(<span class="string">'%s,%d,%d,%d,%d\n'</span> % (img_name, x1, y1, x2, y2))
                <span class="comment">#print 'next image'</span>
                <span class="keyword">break</span>
            <span class="keyword">elif</span> key == <span class="number">122</span>:
                f_box.close()
                f_box = open(os.path.join(img_path, box_result_name), <span class="string">'rb'</span>)
                lines = f_box.readlines()
                f_box.close()
                curr = lines[:-<span class="number">1</span>]
                f_box = open(os.path.join(img_path, box_result_name), <span class="string">'w'</span>)
                <span class="keyword">for</span> line <span class="keyword">in</span> lines:
                    line = line.strip()
                    f_box.write(<span class="string">'%s'</span> % line)
                <span class="keyword">print</span> <span class="string">'delete last image box'</span>
                cv2.destroyAllWindows()
                f_box.close()
                sys.exit(<span class="number">0</span>)
        <span class="keyword">else</span>:
            <span class="keyword">break</span>
    cv2.destroyAllWindows()
    f_box.close()
</code></pre><p>这个标注工具代码比较繁琐，不过还算鲁棒，可以有效处理误标注并实现自动跳转下一张图的功能。每一个待检测的类别用这个标注工具可以生成一个对应的文本文件说明每一张图的矩形坐标位置。</p>
<h2 id="生成用于darknet的标注">生成用于darknet的标注</h2><p>darknet要求每一张图片<code>a.jpg</code>对应一个<code>a.txt</code>，文本里面一行信息说明groundtruth的类别和图像原始宽高的相对坐标，如下：</p>
<pre><code><span class="preprocessor"># &lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;</span>
<span class="number">1</span> <span class="number">0.526875</span> <span class="number">0.499375</span> <span class="number">0.30875</span> <span class="number">0.80375</span>
</code></pre><p>我基于darknet自带的<code>scripts\voc_label.py</code>写了一个脚本把图像以及标注工具生成的矩形坐标转换成满足darknet的标注信息</p>
<pre><code><span class="keyword">import</span> pickle
<span class="keyword">import</span> os
from os <span class="keyword">import</span> listdir, getcwd
from os.path <span class="keyword">import</span> <span class="built_in">join</span>

sets = [<span class="string">'men_jacket'</span>, <span class="string">'men_bottem'</span>, <span class="string">'underwear'</span>, <span class="string">'women_bottem'</span>, <span class="string">'women_jacket'</span>]
classes = [<span class="string">'men_jacket'</span>, <span class="string">'men_bottem'</span>, <span class="string">'underwear'</span>, <span class="string">'women_bottem'</span>, <span class="string">'women_jacket'</span>]


def convert(<span class="built_in">size</span>, <span class="built_in">box</span>):
    dw = <span class="number">1.</span>/<span class="built_in">size</span>[<span class="number">0</span>]
    dh = <span class="number">1.</span>/<span class="built_in">size</span>[<span class="number">1</span>]
    x = (<span class="built_in">box</span>[<span class="number">0</span>] + <span class="built_in">box</span>[<span class="number">2</span>])/<span class="number">2.0</span>
    y = (<span class="built_in">box</span>[<span class="number">1</span>] + <span class="built_in">box</span>[<span class="number">3</span>])/<span class="number">2.0</span>
    w = <span class="built_in">box</span>[<span class="number">2</span>] - <span class="built_in">box</span>[<span class="number">0</span>]
    h = <span class="built_in">box</span>[<span class="number">3</span>] - <span class="built_in">box</span>[<span class="number">1</span>]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    <span class="keyword">return</span> (x,y,w,h)

def convert_annotation(<span class="built_in">line</span>, image_id, set_id):
    out_file = <span class="built_in">open</span>(<span class="string">'box_labels/%s/%s.txt'</span>%(set_id, image_id), <span class="string">'w'</span>)

    w = <span class="number">800</span>
    h = <span class="number">800</span>
    cls = <span class="built_in">line</span>[<span class="number">0</span>].<span class="built_in">split</span>(<span class="string">'/'</span>)[<span class="number">1</span>]
    <span class="keyword">if</span> cls not in classes:
        <span class="keyword">return</span>
    cls_id = classes.index(cls)

    b = (<span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">1</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">2</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">3</span>]), <span class="built_in">float</span>(<span class="built_in">line</span>[<span class="number">4</span>]))
    bb = convert((w,h), b)
    out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">" "</span> + <span class="string">" "</span>.<span class="built_in">join</span>([<span class="built_in">str</span>(a) <span class="keyword">for</span> a in bb]) + <span class="string">'\n'</span>)
    out_file.close

wd = getcwd()
list_file = <span class="built_in">open</span>(<span class="string">'train.txt'</span>, <span class="string">'w'</span>)
<span class="keyword">for</span> set_id in sets:
    <span class="keyword">if</span> not os.path.exists(<span class="string">'box_labels/%s'</span> % (set_id)):
        os.makedirs(<span class="string">'box_labels/%s'</span> % (set_id))
    images_info = <span class="built_in">open</span>(<span class="string">'box_imgs/%s.txt'</span> % (set_id)).readlines()
    <span class="keyword">for</span> <span class="built_in">line</span> in images_info:
        <span class="built_in">line</span> = <span class="built_in">line</span>.strip().<span class="built_in">split</span>(<span class="string">','</span>)
        image_id = <span class="built_in">line</span>[<span class="number">0</span>].<span class="built_in">split</span>(<span class="string">'/'</span>)[<span class="number">2</span>].<span class="built_in">split</span>(<span class="string">'.'</span>)[<span class="number">0</span>]
        list_file.write(<span class="string">'%s/box_imgs/%s/%s.jpg\n'</span> % (wd, set_id, image_id))
        convert_annotation(<span class="built_in">line</span>, image_id, set_id)
list_file.close()
</code></pre><p>执行这个脚本会生成一个<code>box_labels</code>文件夹，并在里面生成对应的darknet标签信息。同时生成一个<code>train.txt</code>说明用于训练的图片的路径。</p>
<h2 id="更改YOLO模型参数">更改YOLO模型参数</h2><p>对<code>cfg/yolo.cfg</code>的配置文件进行调整</p>
<pre><code>subdivisions=<span class="number">2</span> <span class="preprocessor"># 原来为<span class="number">64</span>，改小可以提高训练速度，同时增加显存使用</span>
output= <span class="number">735</span> <span class="preprocessor"># 最后connected层，原来值为<span class="number">1470</span></span>
classes = <span class="number">5</span> <span class="preprocessor"># detection层，这里设置为<span class="number">5</span></span>
</code></pre><p>这个参数的确定由公式<code>output = S x S x (5*B+C)</code>，其中S=7，B=2, C=5（5是我实验使用的类别数）。</p>
<p>改写<code>src/data.c</code>中的<code>fill_truth_region</code>函数，确定图像和标签数据的加载位置</p>
<pre><code>//    char *labelpath = find_replace<span class="list">(<span class="keyword">path</span>, <span class="string">"images"</span>, <span class="string">"labels"</span>)</span><span class="comment">;</span>
    char *labelpath = find_replace<span class="list">(<span class="keyword">path</span>, <span class="string">"box_imgs"</span>, <span class="string">"box_labels"</span>)</span><span class="comment">;</span>
</code></pre><p>改写<code>src/yolo.c</code>：</p>
<pre><code>//<span class="type">char</span> *voc_names[] = {<span class="string">"aeroplane"</span>, <span class="string">"bicycle"</span>, <span class="string">"bird"</span>, <span class="string">"boat"</span>, <span class="string">"bottle"</span>, <span class="string">"bus"</span>, <span class="string">"car"</span>, <span class="string">"cat"</span>, <span class="string">"chair"</span>, <span class="string">"cow"</span>, <span class="string">"diningtable"</span>, <span class="string">"dog"</span>, <span class="string">"horse"</span>, <span class="string">"motorbike"</span>, <span class="string">"person"</span>, <span class="string">"pottedplant"</span>, <span class="string">"sheep"</span>, <span class="string">"sofa"</span>, <span class="string">"train"</span>, <span class="string">"tvmonitor"</span>};
//image voc_labels[<span class="number">20</span>];
<span class="type">char</span> *voc_names[] = {<span class="string">"men_jacket"</span>, <span class="string">"men_bottem"</span>, <span class="string">"underwear"</span>, <span class="string">"women_bottem"</span>, <span class="string">"women_jacket"</span>};
image voc_labels[<span class="number">5</span>];
<span class="type">void</span> train_yolo(<span class="type">char</span> *cfgfile, <span class="type">char</span> *weightfile)
{
//    <span class="type">char</span> *train_images = <span class="string">"/data/voc/train.txt"</span>;
//    <span class="type">char</span> *backup_directory = <span class="string">"/home/pjreddie/backup/"</span>;
    <span class="type">char</span> *train_images = <span class="string">"/home/xixi/darknet/train.txt"</span>;
    <span class="type">char</span> *backup_directory = <span class="string">"/home/xixi/darknet/results/"</span>;

...

<span class="type">void</span> run_yolo(<span class="type">int</span> argc, <span class="type">char</span> **argv)
{
    /*
    <span class="type">int</span> i;
    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i){
        <span class="type">char</span> buff[<span class="number">256</span>];
        sprintf(buff, <span class="string">"data/labels/%s.png"</span>, voc_names[i]);
        voc_labels[i] = load_image_color(buff, <span class="number">0</span>, <span class="number">0</span>);
    }
    */
</code></pre><p>改好之后重新编译代码，下载预训练好的模型参数文件，并开始训练</p>
<pre><code>make
wget http:<span class="comment">//pjreddie.com/media/files/extraction.conv.weights</span>
./darknet -<span class="tag">i</span> <span class="number">2</span> yolo train cfg/yolo<span class="class">.cfg</span> extraction<span class="class">.conv</span><span class="class">.weights</span>
</code></pre><p>在results文件夹下面就好生成训练好的模型文件，当迭代40000次后，会输出最终模型文件yolo_final.weights。这个过程用GPU大概需要3天时间，消耗显存6个G。（-i参数表示使用第二块GPU）</p>
<h1 id="YOLO检测">YOLO检测</h1><pre><code><span class="comment"># 检测单张图片</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt;
<span class="comment"># 检测多张图片</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights
<span class="comment"># 改变检测的阈值</span>
./darknet yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt; -thresh <span class="number">0</span>
<span class="comment"># 改为CPU模式检测</span>
./darknet -nogpu yolo <span class="built_in">test</span> cfg/yolo.cfg results/yolo_final.weights &lt;image&gt;
</code></pre><p>经过测试，在GPU环境下，测试一张图片跑完整的YOLO模型需要40ms~100ms，CPU环境下需要5秒以上。</p>
<h1 id="补充">补充</h1><p>YOLO官方后来又出了一个yolo2.cfg，研究了一下，每一卷积层都加了batch_normlization，提高训练速度，破费。同时把最后的一个全连接层改成了一个local层</p>
<h1 id="讨论和思考">讨论和思考</h1><ul>
<li><p>YOLO的核心思想就是利用整张图作为网络的输入，直接在输出层回归bounding box的位置和bounding box所属的类别。</p>
</li>
<li><p>将一副图像经过类似alexnet的特征提取，最后经过一层的全连接层之后又映射回SxS个网格(grid cell)，如果某个object的中心 落在这个网格中，则这个网格就负责预测这个object。</p>
</li>
<li><p>每个网格要预测B个bounding box，每个bounding box除了要回归自身的位置之外，还要附带预测一个confidence值。 这个confidence等于所预测的box中含有object的置信度（object落在其中，取1，否则取0）和这个box和truth的IOU交集的乘积确定。这样每个网格要返回bounding box预测的(x, y, w, h)和confidence5个值，以及object的类别信息C类，所以最后一层的输出应该为<code>S x S x (5*B+C)</code>。</p>
</li>
<li><p>由于xywh取的是相对坐标，归一化为0~1，confidence取值范围为0~1，category的类别取值为0或1，简单实现了归一化的目的，然而由于目标函数使用了均方误差损失函数，位置坐标和类别判别信息维度对损失函数的贡献不应该是一样的，所以文章中采用了如下的方法改进</p>
</li>
</ul>
<ol>
<li>更重视坐标预测，给这些损失前面赋予更大的loss weight, 训练中取5。</li>
<li>对没有object的box的confidence loss，赋予小的loss weight，训练中取0.5。</li>
<li>有object的box的confidence loss和类别的loss的loss weight正常取1。</li>
</ol>
<ul>
<li><p>对于小的box位置偏差对实际的效果影响更为严重，但均方误差对这个没有体现，所以对w和h参数又取了平方根处理，增大的小box的位置偏移对loss函数的影响。</p>
</li>
<li><p>一个网格有多个bounding box的时候，根据IOU值取前B个进行处理。所以对多个物体相互靠近的时候处理的并不是十分理想。</p>
</li>
<li><p>在test一张图片的时候，通过网络得到SxSx(5*B+C)层的值后，每个网格的类别信息Pr1，其对应的bounding box的confidence Pr2以及box和网格的IOU信息的乘积用来预测box属于某一类的概率。根据阈值过滤后，对保留的boxes进行非极大值抑制NMS处理，得到最终结果。</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/25/darknet-yolo/" data-id="cjf3vykea003lqgfhvfi7okzc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/darknet/">darknet</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-caffe-add-layer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/23/caffe-add-layer/" class="article-date">
  <time datetime="2016-03-23T14:06:35.000Z" itemprop="datePublished">2016-03-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/23/caffe-add-layer/">caffe学习（六）创建自己的模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近阅读文章《Supervised Learning of Semantics-Preserving Hashing via Deep Neural Networks for Large-Scale Image Search》，对应的开源代码有两个版本<a href="https://github.com/kevinlin311tw/caffe-cvprw15" target="_blank" rel="external">https://github.com/kevinlin311tw/caffe-cvprw15</a>，<a href="https://github.com/kevinlin311tw/Caffe-DeepBinaryCode" target="_blank" rel="external">https://github.com/kevinlin311tw/Caffe-DeepBinaryCode</a>，<strong>两者之间的主要区别在于后者使用了更为复杂的目标函数，而不是简单的做了一层sigmoid</strong>。由于其在alexnet上进行了微小改动，在fc7和fc8层之间添加了一个latent layer，将原本用于检索的4096特征维度哈希为128维的二值特征，取得了不错的效果，借鉴这篇文章的代码，我实验了一下如何创建自己的模型，添加自己的layer</p>
<h2 id="预训练模型">预训练模型</h2><p>不同于文章使用的alexnet，我的实验使用的是更为复杂的googLeNet。首先要训练好一个模型，对应一个caffemodel文件，和其训练测试对应的prototxt文件，并在此之上进行fine-tune。</p>
<h2 id="准备训练数据">准备训练数据</h2><p>跟普通的分类训练没有区别，也要准备lmdb格式的文件以及均值文件。</p>
<h2 id="修改train-prototxt">修改train.prototxt</h2><p>原本的层级结构是<code>pool5/7x7_s1 --&gt; loss3/classifier --&gt; SoftmaxWithLoss &amp; Accuracy</code>，改动后变成<code>pool5/7x7_s1 --&gt; latent_SSDH --&gt; latent_SSDH_encode --&gt; loss3/classifier_change --&gt; SoftmaxWithLoss &amp; Accuracy</code>。具体就是添加了一层InnerProduct，输出数目为哈希的位数，后面接一层Sigmoid层将其二值化，再接到原本的loss3/classifier层，并对该层进行finetune，调整该层的训练参数。改动代码如下：</p>
<pre><code><span class="preprocessor">#########added by yx followed by layer <span class="string">"pool5/drop_7x7_s1"</span></span>
layer {
  name: <span class="string">"latent_SSDH"</span>
  type: <span class="string">"InnerProduct"</span>
  bottom: <span class="string">"pool5/7x7_s1"</span>
  top: <span class="string">"latent_SSDH"</span>
  param {
    lr_mult: <span class="number">1</span>
    decay_mult: <span class="number">1</span>
  }
  param {
    lr_mult: <span class="number">2</span>
    decay_mult: <span class="number">0</span>
  }
  inner_product_param {
    num_output: <span class="number">128</span>
    weight_filler {
      type: <span class="string">"gaussian"</span>
      <span class="built_in">std</span>: <span class="number">0.005</span>
    }
    bias_filler {
      type: <span class="string">"constant"</span>
      value: <span class="number">1</span>
    }
  }
}
layer {
  name: <span class="string">"latent_SSDH_encode"</span>
  bottom: <span class="string">"latent_SSDH"</span>
  top: <span class="string">"latent_SSDH_encode"</span>
  type: <span class="string">"Sigmoid"</span>
}
<span class="preprocessor">##########################</span>
</code></pre><p>并把loss3/classifier层的名字改为<code>loss3/classifier_change</code>，bottom层改为<code>latent_SSDH_encode</code>，top层改为<code>loss3/classifier_change</code>，把lr_mult参数*10。</p>
<p>最后把SoftmaxWithLoss层以及Accuracy层的bottom改为新层名<code>loss3/classifier_change</code>。</p>
<p>这里详细介绍一下weight_filter的初始化细节，一般有<code>gaussian</code>和<code>xavier</code>两种方式：<br>xavier具体方式是从[-scale, +scale]中进行均匀采样，对卷积层或全连接层中参数进行初始化的方法。<br>其中scale = \sqrt(3 / n), n根据不同实现可设置为n=(num_in + num_out) / 2 (Understanding the difficulty of training deep feedforward neural networks )，或n=num_out (caffe最初实现方法)</p>
<h2 id="修改solver-prototxt">修改solver.prototxt</h2><ul>
<li>将<code>test_initialization</code>屏蔽掉</li>
<li>weight_decay改为0.0005</li>
<li>gamma改为0.1</li>
<li>base_lr参数降低10倍，改为0.001</li>
</ul>
<h2 id="修改deploy-prototxt">修改deploy.prototxt</h2><p>因为原本的deploy是要做分类的任务，而我这里是要做哈希特征提取，所以要把原来的最后两层loss3/classifier_change和Softmax屏蔽掉，并添加如下代码</p>
<pre><code><span class="comment">############## added by yx #########</span>
<span class="name">layer</span> {
  <span class="literal">name</span>: <span class="string">"latent_SSDH"</span>
  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span>
  bottom: <span class="string">"pool5/7x7_s1"</span>
  top: <span class="string">"latent_SSDH"</span>
  inner_product_param {
    num_output: <span class="number">128</span>
  }
}
<span class="name">layer</span> {
  <span class="literal">name</span>: <span class="string">"latent_SSDH_encode"</span>
  <span class="built_in">type</span>: <span class="string">"Sigmoid"</span>
  bottom: <span class="string">"latent_SSDH"</span>
  top: <span class="string">"latent_SSDH_encode"</span>
}
</code></pre><h2 id="训练命令">训练命令</h2><pre><code>nohup ../../build/tools/caffe train --solver=solver<span class="class">.prototxt</span> -weights sku30450_googlenet_quick_iter_500000<span class="class">.caffemodel</span> -gpu <span class="number">1</span> &amp;
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/23/caffe-add-layer/" data-id="cjf3vykfc004oqgfh3fct7rbd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-linux-shell-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/03/19/linux-shell-skill/" class="article-date">
  <time datetime="2016-03-19T05:24:25.000Z" itemprop="datePublished">2016-03-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/03/19/linux-shell-skill/">linux shell技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="匹配特殊字符空格">匹配特殊字符空格</h3><pre><code>find . -<span class="property">name</span> <span class="string">"*[[:space:]]*"</span>
</code></pre><h3 id="找到指定文件并删除">找到指定文件并删除</h3><pre><code>find . -<span class="property">name</span> <span class="string">"abc*"</span> -exec rm {} \;
</code></pre><h2 id="大文件分割与合并">大文件分割与合并</h2><p>把aaa.tar.gz分割，每卷5G，然后合并</p>
<pre><code><span class="tag">split</span> <span class="tag">-b</span> 5000<span class="tag">m</span> <span class="tag">aaa</span><span class="class">.tar</span><span class="class">.gz</span> <span class="tag">aaa_part</span><span class="class">.tar</span><span class="class">.gz</span>.
<span class="tag">cat</span> <span class="tag">aaa_part</span><span class="class">.tar</span><span class="class">.gz</span>.* &gt; <span class="tag">aaa</span><span class="class">.tar</span><span class="class">.gz</span>
</code></pre><p>大文件夹aaa分卷压缩与合并解压</p>
<pre><code>tar czvf - aaa <span class="string">| split -b 5000m - aaa_part.tar.gz.</span>
cat aaa_part.tar.gz.* <span class="string">| tar xz</span>
</code></pre><h3 id="批量杀死进程">批量杀死进程</h3><pre><code>ps aux | grep <span class="string">"common"</span> | cut –c <span class="number">9</span>-<span class="number">15</span> | xargs kill
</code></pre><h2 id="find_文件查找">find 文件查找</h2><p>查找txt和pdf文件</p>
<pre><code>find . ( -<span class="property">name</span> <span class="string">"*.txt"</span> -o -<span class="property">name</span> <span class="string">"*.pdf"</span> ) -print
</code></pre><p>正则方式查找.txt和pdf，<code>-iregex</code>: 忽略大小写的正则</p>
<pre><code><span class="keyword">find</span> . -regex  <span class="string">".*(.txt|.pdf)$"</span>
</code></pre><p>否定参数，查找所有非txt文本</p>
<pre><code><span class="keyword">find</span> . ! -name <span class="string">"*.txt"</span> -<span class="keyword">print</span>
</code></pre><p>指定搜索深度，打印出当前目录的文件（深度为1）</p>
<pre><code><span class="built_in">find</span> . -maxdepth <span class="number">1</span> -<span class="built_in">type</span> f
</code></pre><p>按类型搜索：-type f 文件 / l 符号链接 / d 目录</p>
<pre><code>find . -<span class="keyword">type</span> <span class="keyword">d</span> -<span class="keyword">print</span>  <span class="comment">//只列出所有目录</span>
</code></pre><p>按时间搜索：<br>  -atime 访问时间 (单位是天，分钟单位则是-amin，以下类似）<br>  -mtime 修改时间（内容被修改）<br>  -ctime 变化时间（元数据或权限变化）<br>最近7天被访问过的所有文件：</p>
<pre><code><span class="built_in">find</span> . -atime <span class="number">7</span> -<span class="built_in">type</span> f -<span class="built_in">print</span>
</code></pre><p>按大小搜索：w字 k M G，寻找大于2k的文件</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -size +<span class="number">2</span>k
</code></pre><p>按权限查找：</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -perm <span class="number">644</span> -<span class="built_in">print</span> //找具有可执行权限的所有文件
</code></pre><p>按用户查找：</p>
<pre><code><span class="built_in">find</span> . -<span class="built_in">type</span> f -user weber -<span class="built_in">print</span>// 找用户weber所拥有的文件
</code></pre><h3 id="找到后的后续动作">找到后的后续动作</h3><p>删除：删除当前目录下所有的swp文件：</p>
<pre><code><span class="keyword">find</span> . -<span class="built_in">type</span> <span class="keyword">f</span> -name <span class="string">"*.swp"</span> -<span class="built_in">delete</span>
</code></pre><p>执行动作（强大的exec）</p>
<pre><code><span class="title">find</span> . -<span class="typedef"><span class="keyword">type</span> f -user root -exec chown weber <span class="container">{}</span> ; //将当前目录下的所有权变更为weber</span>
</code></pre><p>注：{}是一个特殊的字符串，对于每一个匹配的文件，{}会被替换成相应的文件名；<br>eg：将找到的文件全都copy到另一个目录：</p>
<pre><code><span class="title">find</span> . -<span class="typedef"><span class="keyword">type</span> f -mtime +10 -name "*.txt" -exec cp <span class="container">{}</span> <span class="type">OLD</span> ;</span>
</code></pre><p>结合多个命令<br>tips: 如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后 -exec 调用时执行脚本即可；</p>
<pre><code><span class="deletion">-exec ./commands.sh {} \;</span>
</code></pre><h3 id="-print的定界符">-print的定界符</h3><p>默认使用’\n’作为文件的定界符；<br>-print0 使用”作为文件的定界符，这样就可以搜索包含空格的文件；</p>
<h2 id="grep_文本搜索">grep 文本搜索</h2><p>常用参数<br>-o 只输出匹配的文本行<br>-v 只输出没有匹配的文本行<br>-c 统计文件中包含文本的次数</p>
<pre><code><span class="keyword">grep</span> -c <span class="string">"text"</span> filename
</code></pre><p>-n 打印匹配的行号<br>-i 搜索时忽略大小写<br>-l 只打印文件名<br>在多级目录中对文本递归搜索(程序员搜代码的最爱）：</p>
<pre><code><span class="keyword">grep</span> <span class="string">"class"</span> . -R -n
</code></pre><p>匹配多个模式</p>
<pre><code>grep -<span class="keyword">e</span> <span class="string">"class"</span> -<span class="keyword">e</span> <span class="string">"vitural"</span> <span class="keyword">file</span>
</code></pre><p>grep输出以作为结尾符的文件名：（-z）</p>
<pre><code>grep <span class="string">"test"</span> file<span class="keyword">*</span> -lZ|<span class="string"> xargs -0 rm</span>
</code></pre><h2 id="xargs_命令行参数转换">xargs 命令行参数转换</h2><p>xargs 能够将输入数据转化为特定命令的命令行参数；这样，可以配合很多命令来组合使用。比如grep，比如find；</p>
<p>将多行输出转化为单行输出</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span>.txt| xargs
</code></pre><p>将单行转化为多行输出，-n：指定每行显示的字段数</p>
<pre><code><span class="keyword">cat</span> single.txt | xargs -<span class="keyword">n</span> 3
</code></pre><h3 id="xargs参数说明">xargs参数说明</h3><p>-d 定义定界符 （默认为空格 多行的定界符为 n）<br>-n 指定输出为多行<br>-I {} 指定替换字符串，这个字符串在xargs扩展时会被替换掉,用于待执行的命令需要多个参数时。eg：</p>
<pre><code>cat <span class="built_in">file</span>.txt | xargs -I {} ./<span class="command"><span class="keyword">command</span>.<span class="title">sh</span> -<span class="title">p</span> {} -<span class="title">1</span></span>
</code></pre><p>-0：指定为输入定界符，eg：统计程序行数</p>
<pre><code>find <span class="built_in">source</span>_dir/ -type f -name <span class="string">"*.cpp"</span> -print0 |xargs -<span class="number">0</span> wc <span class="operator">-l</span>
</code></pre><h2 id="sort_排序">sort 排序</h2><p>字段说明：<br>-n 按数字进行排序 VS -d 按字典序进行排序<br>-r 逆序排序<br>-k N 指定按第N列排序<br>eg：</p>
<pre><code><span class="title">sort</span> -nrk <span class="number">1</span> <span class="typedef"><span class="keyword">data</span>.txt</span>
<span class="title">sort</span> -bd <span class="typedef"><span class="keyword">data</span> // 忽略像空格之类的前导空白字符</span>
</code></pre><h2 id="uniq_消除重复行">uniq 消除重复行</h2><p>消除重复行</p>
<pre><code>sort unsort.txt <span class="string">| uniq</span>
</code></pre><p>统计各行在文件中出现的次数</p>
<pre><code><span class="built_in">sort</span> unsort.txt | uniq -<span class="built_in">c</span>
</code></pre><p>找出重复行，可指定每行中需要比较的重复内容：-s 开始位置 -w 比较字符数</p>
<pre><code><span class="keyword">sort</span> unsort.txt | uniq -<span class="literal">d</span>
</code></pre><h2 id="用tr进行转换">用tr进行转换</h2><p>通用用法</p>
<pre><code><span class="keyword">echo</span> <span class="number">12345</span> | <span class="built_in">tr</span> <span class="string">'0-9'</span> <span class="string">'9876543210'</span> //加解密转换，替换对应字符
<span class="keyword">cat</span> text| <span class="built_in">tr</span> <span class="string">'t'</span> <span class="string">' '</span>  //制表符转空格
</code></pre><p>tr删除字符</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | tr -<span class="keyword">d</span> '0-9' <span class="comment">// 删除所有数字</span>
</code></pre><p>-c 求补集</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | tr -c '0-9' <span class="comment">//获取文件中所有数字</span>
<span class="keyword">cat</span> <span class="keyword">file</span> | tr -<span class="keyword">d</span> -c '0-9 <span class="keyword">n</span>'  <span class="comment">//删除非数字数据</span>
</code></pre><p>tr压缩字符<br>tr -s 压缩文本中出现的重复字符；最常用于压缩多余的空格</p>
<pre><code><span class="keyword">cat</span> <span class="keyword">file</span> | <span class="built_in">tr</span> -<span class="keyword">s</span> <span class="string">' '</span>
</code></pre><p>字符类<br>tr中可用各种字符类：<br>alnum：字母和数字<br>alpha：字母<br>digit：数字<br>space：空白字符<br>lower：小写<br>upper：大写<br>cntrl：控制（非可打印）字符<br>print：可打印字符<br>使用方法：tr [:class:] [:class:]</p>
<pre><code>eg: <span class="tag">tr</span> <span class="string">'[:lower:]'</span> <span class="string">'[:upper:]'</span>
</code></pre><h2 id="cut_按列切分文本">cut 按列切分文本</h2><p>截取文件的第2列和第4列：</p>
<pre><code><span class="label">cut</span> -<span class="literal">f2</span>,<span class="number">4</span> filename
</code></pre><p>去文件除第3列的所有列：</p>
<pre><code>cut -f3 <span class="comment">--complement filename</span>
</code></pre><p>-d 指定定界符：</p>
<pre><code>cat <span class="operator">-f</span>2 <span class="operator">-d</span><span class="string">";"</span> filename
</code></pre><p>cut 取的范围<br>N- 第N个字段到结尾<br>-M 第1个字段为M<br>N-M N到M个字段</p>
<ul>
<li><p>cut 取的单位<br>-b 以字节为单位<br>-c 以字符为单位<br>-f 以字段为单位（使用定界符）<br>eg:</p>
<p>  cut -c1-5 file //打印第一到5个字符<br>  cut -c-2 file  //打印前2个字符</p>
</li>
</ul>
<h2 id="wc_统计行和字符的工具">wc 统计行和字符的工具</h2><pre><code>wc -<span class="keyword">l</span> <span class="keyword">file</span> <span class="comment">// 统计行数</span>
wc -w <span class="keyword">file</span> <span class="comment">// 统计单词数</span>
wc -c <span class="keyword">file</span> <span class="comment">// 统计字符数</span>
</code></pre><h2 id="sed_文本替换利器">sed 文本替换利器</h2><p>首处替换</p>
<pre><code>seg <span class="string">'s/text/replace_text/'</span> <span class="keyword">file</span>   <span class="comment">//替换每一行的第一处匹配的text</span>
</code></pre><p>全局替换</p>
<pre><code>seg 's/<span class="type">text</span>/replace_text/g' <span class="type">file</span>
</code></pre><p>默认替换后，输出替换后的内容，如果需要直接替换原文件,使用-i：</p>
<pre><code>seg -<span class="tag">i</span> <span class="string">'s/text/repalce_text/g'</span> file
</code></pre><p>移除空白行：</p>
<pre><code>sed <span class="string">'/^$/d'</span> <span class="keyword">file</span>
</code></pre><p>变量转换，已匹配的字符串通过标记&amp;来引用</p>
<pre><code>echo this <span class="keyword">is</span> en example | seg 's/\w+/<span class="comment">[&amp;]</span>/g'
$&gt;<span class="comment">[this]</span>  <span class="comment">[is]</span> <span class="comment">[en]</span> <span class="comment">[example]</span>
</code></pre><p>子串匹配标记<br>第一个匹配的括号内容使用标记1来引用</p>
<pre><code><span class="title">sed</span> <span class="string">'s/hello([0-9])/1/'</span>
</code></pre><p>双引号求值，sed通常用单引号来引用；也可使用双引号，使用双引号后，双引号会对表达式求值：</p>
<pre><code><span class="title">sed</span> <span class="string">'s/<span class="variable">$var</span>/HLLOE/'</span>
</code></pre><p>当使用双引号时，我们可以在sed样式和替换字符串中指定变量；</p>
<pre><code>p=patten
r=replaced
<span class="built_in">echo</span> <span class="string">"line con a patten"</span> | sed <span class="string">"s/<span class="variable">$p</span>/<span class="variable">$r</span>/g"</span>
$&gt;line con a replaced
</code></pre><h2 id="awk_数据流处理工具">awk 数据流处理工具</h2><p>awk脚本结构<br>awk ‘BEGIN{ statements } statements2 END{ statements }’</p>
<ul>
<li>工作方式</li>
</ul>
<ol>
<li>执行begin中语句块；</li>
<li>从文件或stdin中读入一行，然后执行statements2，重复这个过程，直到文件全部被读取完毕；</li>
<li>执行end语句块；</li>
</ol>
<h3 id="print_打印当前行">print 打印当前行</h3><p>使用不带参数的print时，会打印当前行;</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"line1nline2"</span> | awk 'BEGIN{<span class="keyword">print</span> <span class="string">"start"</span>} {<span class="keyword">print</span> } END{ <span class="keyword">print</span> <span class="string">"End"</span> }'
</code></pre><p>print 以逗号分割时，参数以空格定界;</p>
<pre><code>echo <span class="string">| awk ' {var1 = "</span>v1<span class="string">" ; var2 = "</span>V2<span class="string">"; var3="</span>v3<span class="string">"; </span>
print var1, var2 , var3; }'
$&gt;v1 V2 v3
</code></pre><p>使用-拼接符的方式;</p>
<pre><code>echo <span class="string">| awk ' {var1 = "</span>v1<span class="string">" ; var2 = "</span>V2<span class="string">"; var3="</span>v3<span class="string">"; </span>
print var1<span class="string">"-"</span>var2<span class="string">"-"</span>var3; }'
$&gt;v1-V2-v3
</code></pre><h3 id="特殊变量：NR_NF_$0_$1_$2">特殊变量：NR NF $0 $1 $2</h3><p>NR:表示记录数量，在执行过程中对应当前行号；<br>NF:表示字段数量，在执行过程总对应当前行的字段数；<br>$0:这个变量包含执行过程中当前行的文本内容；<br>$1:第一个字段的文本内容；<br>$2:第二个字段的文本内容；</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"line1 f2 f3n line2 n line 3"</span> | awk '{<span class="keyword">print</span> NR<span class="string">":"</span><span class="label">$0</span><span class="string">"-"</span><span class="label">$1</span><span class="string">"-"</span><span class="label">$2}</span>'
</code></pre><p>打印每一行的第二和第三个字段：</p>
<pre><code><span class="title">awk</span> <span class="string">'{print <span class="variable">$2</span>, <span class="variable">$3</span>}'</span> file
</code></pre><p>统计文件的行数：</p>
<pre><code>awk <span class="string">' END {print NR}'</span> <span class="keyword">file</span>
</code></pre><p>累加每一行的第一个字段：</p>
<pre><code>echo -<span class="keyword">e</span> <span class="string">"1n 2n 3n 4n"</span> | awk 'BEGIN{num = 0 ;
<span class="keyword">print</span> <span class="string">"begin"</span>;} {<span class="keyword">sum</span> += <span class="label">$1</span>;} END {<span class="keyword">print</span> <span class="string">"=="</span>; <span class="keyword">print</span> <span class="keyword">sum</span> }'
</code></pre><h3 id="传递外部变量">传递外部变量</h3><pre><code><span class="keyword">var</span>=<span class="number">1000</span>
echo | awk <span class="string">'{print vara}'</span> vara=$<span class="keyword">var</span> 
<span class="preprocessor">#  输入来自stdin</span>
awk <span class="string">'{print vara}'</span> vara=$<span class="keyword">var</span> file 
<span class="preprocessor"># 输入来自文件</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/03/19/linux-shell-skill/" data-id="cjf3vykdf002lqgfhe18wuvqo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell/">shell</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spark-learn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/23/spark-learn/" class="article-date">
  <time datetime="2016-02-23T13:50:37.000Z" itemprop="datePublished">2016-02-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/23/spark-learn/">Spark学习记录</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本笔记主要记录Spark在Hadoop环境中使用python语言进行算法开发过程中遇到的问题</p>
<h3 id="Spark的启动">Spark的启动</h3><p>在Spark的安装路径中的<code>bin</code>路径中有pyspark，这是一种交互式的调用方法，还可以编写好python脚本之后通过</p>
<pre><code><span class="label">spark</span>-<span class="keyword">submit </span>xxx.py
</code></pre><p>的方式来调用。</p>
<h3 id="sc_is_not_defined">sc is not defined</h3><p>任何Spark程序都需要一个SparkContext来开始，其包含了Spark集群配置的各种参数，如果代码报错<code>sc is not defined</code>，需要添加如下代码进行初始化：</p>
<pre><code>from pyspark import SparkContext
sc = <span class="function"><span class="title">SparkContext</span><span class="params">(<span class="string">'local[2]'</span>, <span class="string">'First Spark App'</span>)</span></span>
</code></pre><h3 id="常用HDFS_Shell命令">常用HDFS Shell命令</h3><p>大多数FS Shell命令和对应的Unix Shell命令类似，格式为hadoop fs <args>，如下：</args></p>
<pre><code>hadoop <span class="built_in">fs</span> -cat URI [URI …]
hadoop <span class="built_in">fs</span> -chmod [-R] &lt;<span class="built_in">MODE</span>[,<span class="built_in">MODE</span>]... | OCTALMODE&gt; URI [URI …]
hadoop <span class="built_in">fs</span> -cp URI [URI …] &lt;dest&gt;
hadoop <span class="built_in">fs</span> -du URI [URI …]
hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span> &lt;paths&gt;
hadoop <span class="built_in">fs</span> -ls &lt;args&gt;
hadoop <span class="built_in">fs</span> -rmr URI [URI …]    # rm -rf
</code></pre><p>在HDFS和本地之间复制文件的命令如下：</p>
<pre><code>hadoop fs -get [-ignorecrc] [-crc] <span class="variable">&lt;src&gt;</span> <span class="variable">&lt;localdst&gt;</span>    <span class="comment"># 复制文件到本地文件系统</span>
hadoop fs -put <span class="variable">&lt;localsrc&gt;</span> <span class="variable">&lt;dst&gt;</span>    <span class="comment"># 本地文件复制到HDFS</span>
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/23/spark-learn/" data-id="cjf3vykch001lqgfhl1k38y7a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ml-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/18/ml-skill/" class="article-date">
  <time datetime="2016-02-18T13:23:36.000Z" itemprop="datePublished">2016-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/18/ml-skill/">机器学习技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="SVM_vs_Logistic_Regression">SVM vs Logistic Regression</h3><ol>
<li>逻辑回归和线性核SVM本质上其实没啥区别；</li>
<li>特征数大于样本数或者二者数量相当时，逻辑回归或者线性核SVM会有比较好的效果；</li>
<li>特征数较少，样本数一般多时，高斯核SVM会有比较好的效果；</li>
<li>特征少，样本特别多时，构建更多的特征，然后用逻辑回归或者线性核SVM</li>
</ol>
<h3 id="调参技巧">调参技巧</h3><p>解决测试误差较大的办法</p>
<ol>
<li>增加训练样本 -&gt; 降低方差</li>
<li>减少特征数量 -&gt; 降低方差</li>
<li>增加新特征 -&gt; 降低偏差</li>
<li>现有特征多项式组合(x1^2, x2^2, x1*x2等等) -&gt; 降低偏差</li>
<li>降低正则λ -&gt; 降低偏差</li>
<li>增加正则λ -&gt; 降低方差</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/18/ml-skill/" data-id="cjf3vykcz002dqgfhb20y2wq8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/18/python-skill/" class="article-date">
  <time datetime="2016-02-18T13:21:09.000Z" itemprop="datePublished">2016-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/18/python-skill/">python技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="查看运行时间">查看运行时间</h2><p>用ipython的run命令做profiling，找出耗时语句</p>
<pre><code><span class="built_in">run</span> <span class="bash">-p xxx.py</span>
</code></pre><h2 id="ipynb文件">ipynb文件</h2><p>ipynb文件是用浏览器演示python交互的优良插件，可以提供运行代码，插图，文章说明，插入公式等多种功能。<br>只需在含有ipynb文件的的父目录位置执行</p>
<pre><code><span class="title">ipython</span> notebook
</code></pre><p>即可生成shell服务器端，浏览器作为客户端展示出来。</p>
<h2 id="内存优化">内存优化</h2><p>及时释放内存。大数组使用完之后，手动del释放array。注意所有对数组的引用都del之后，数组才会被del。这些引用包括A[2:]这样的view。<br>尽量重用内存，比如：</p>
<pre><code>A = <span class="keyword">B </span>+ C # <span class="keyword">B </span>is neverused later
</code></pre><p>可以改写成</p>
<pre><code><span class="constant">B</span> += C
<span class="constant">A</span> = B
</code></pre><h2 id="py2exe">py2exe</h2><p>windows环境把python脚步打包成可执行程序，安装py2exe。注意使用pip install安装只能支持python3版本，要想在python2.7环境下使用py2exe，要在这里下载<a href="https://sourceforge.net/projects/py2exe/files/py2exe/0.6.9/py2exe-0.6.9.win32-py2.7.exe/download" target="_blank" rel="external">py2exe-0.6.9.win32-py2.7.exe</a></p>
<p>在脚步所在目录下新建一个<code>setup.py</code>文件，加入</p>
<pre><code>from distutils<span class="class">.core</span> import setup
import py2exe

<span class="function"><span class="title">setup</span><span class="params">(windows = [<span class="string">'xxxxxx.py'</span>])</span></span>
</code></pre><p>然后执行</p>
<pre><code>python setup<span class="class">.py</span> py2exe
</code></pre><p>然后可执行程序以及相关依赖都会创建在dist文件夹，打包带走dist即可。</p>
<h2 id="random随机数模块">random随机数模块</h2><h3 id="random-random">random.random</h3><p>用于生成[0, 1.0)的随机浮点数</p>
<h3 id="random-uniform(a,_b)">random.uniform(a, b)</h3><p>生成[a, b]的随机浮点数</p>
<h3 id="random-randint(a,_b)">random.randint(a, b)</h3><p>生成[a, b]的随机整数</p>
<h3 id="random-choice(sequence)">random.choice(sequence)</h3><p>从sequence中随机得到一个元素</p>
<h3 id="random-shuffle(x[,_random])">random.shuffle(x[, random])</h3><p>用于将列表x元素打乱顺序</p>
<h3 id="random-sample(sequence,_k)">random.sample(sequence, k)</h3><p>从指定序列中随机获取长度k的片段，不改变原有序列</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/18/python-skill/" data-id="cjf3vykcj001yqgfhxep6g9x0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-linux-c-skill" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/18/linux-c-skill/" class="article-date">
  <time datetime="2016-01-18T14:07:18.000Z" itemprop="datePublished">2016-01-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/study/">study</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/18/linux-c-skill/">Linux c/c++ 技巧总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="遍历目录内文件">遍历目录内文件</h2><p>Linux下的dirent.h头文件是专门为了获取文件夹目录内容而设计的结构体。使用示例如下：</p>
<pre><code><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span>

<span class="function"><span class="keyword">void</span> <span class="title">List</span><span class="params">(<span class="keyword">char</span>* path, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; files)</span>
</span>{
    <span class="keyword">struct</span> dirent* ent = <span class="literal">NULL</span>;
    DIR* pDir;
    <span class="keyword">char</span> dir[<span class="number">512</span>];
    <span class="keyword">struct</span> stat statbuf;  
    <span class="keyword">if</span> ( (pDir=opendir(path))==<span class="literal">NULL</span> )
    {
    <span class="built_in">fprintf</span>( <span class="built_in">stderr</span>, <span class="string">"Cannot open directory:%s\n"</span>, path );
        <span class="keyword">return</span>;
    }
    <span class="keyword">while</span>( (ent=readdir(pDir)) != <span class="literal">NULL</span> )
    {
        <span class="comment">//得到读取文件的绝对路径名</span>
        <span class="built_in">snprintf</span>(dir, <span class="number">512</span>, <span class="string">"%s/%s"</span>, path, ent-&gt;d_name);   
        <span class="comment">//得到文件信息</span>
        lstat(dir, &amp;statbuf);
        <span class="comment">//判断是目录还是文件</span>
        <span class="keyword">if</span> ( S_ISDIR(statbuf.st_mode) )
        {
            <span class="comment">//排除当前目录和上级目录</span>
            <span class="keyword">if</span> (<span class="built_in">strcmp</span>(<span class="string">"."</span>,ent-&gt;d_name) == <span class="number">0</span> || <span class="built_in">strcmp</span>( <span class="string">".."</span>,ent-&gt;d_name) == <span class="number">0</span>) 
                <span class="keyword">continue</span>;
            <span class="comment">//如果是子目录,递归调用函数本身,实现子目录中文件遍历</span>
            <span class="built_in">printf</span>( <span class="string">"子目录:%s/\n"</span>, ent-&gt;d_name );
            <span class="comment">//递归调用,遍历子目录中文件</span>
            <span class="comment">//List(dir);</span>
        }
        <span class="keyword">else</span>
        {
            <span class="built_in">printf</span>( <span class="string">"文件:%s\n"</span>, ent-&gt;d_name );
            files.push_back(pathName.assign(path).append(<span class="string">"/"</span>).append(ent-&gt;d_name));
        }       
    }
    closedir(pDir);
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/18/linux-c-skill/" data-id="cjf3vykdf002pqgfhes522bz1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c-c/">c/c++</a></li></ul>

    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">life</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/study/">study</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">28</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReID/">ReID</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-c/">c/c++</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe2/">caffe2</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/darknet/">darknet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dataset/">dataset</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face/">face</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mxnet/">mxnet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nnsearch/">nnsearch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/product-recognition/">product recognition</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/slam/">slam</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/source/">source</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tricks/">tricks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visualization/">visualization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ReID/" style="font-size: 10px;">ReID</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/c-c/" style="font-size: 12px;">c/c++</a> <a href="/tags/caffe/" style="font-size: 18px;">caffe</a> <a href="/tags/caffe2/" style="font-size: 14px;">caffe2</a> <a href="/tags/darknet/" style="font-size: 10px;">darknet</a> <a href="/tags/dataset/" style="font-size: 10px;">dataset</a> <a href="/tags/face/" style="font-size: 14px;">face</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/tags/mxnet/" style="font-size: 10px;">mxnet</a> <a href="/tags/nnsearch/" style="font-size: 10px;">nnsearch</a> <a href="/tags/product-recognition/" style="font-size: 10px;">product recognition</a> <a href="/tags/python/" style="font-size: 12px;">python</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/slam/" style="font-size: 10px;">slam</a> <a href="/tags/source/" style="font-size: 10px;">source</a> <a href="/tags/tensorflow/" style="font-size: 20px;">tensorflow</a> <a href="/tags/tricks/" style="font-size: 10px;">tricks</a> <a href="/tags/visualization/" style="font-size: 10px;">visualization</a> <a href="/tags/生活/" style="font-size: 16px;">生活</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">六月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">四月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">八月 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/03/23/caffe2-c-inference/">caffe2学习（三）推理预测C++</a>
          </li>
        
          <li>
            <a href="/2018/03/04/slam-resource/">slam资料</a>
          </li>
        
          <li>
            <a href="/2018/03/04/product-recognition-resource/">商品识别拍照购资料</a>
          </li>
        
          <li>
            <a href="/2018/03/04/buy-list/">长草清单</a>
          </li>
        
          <li>
            <a href="/2018/01/21/linux-tips/">linux-tips</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget tag">
   <h3 class="title">常用链接</h3>
   <ul class="entry">
    <li><a href="http://blog.csdn.net/yang_xian521" title="my CSDN blog">我的CSDN博客</a></li>
    <li><a href="http://www.pythondoc.com/pythontutorial27/index.html" title="pythondoc">Python教程</a></li>
    <li><a href="http://vbird.dic.ksu.edu.tw/linux_basic/linux_basic.php" title="Linuxdoc">Linux教程</a></li> 
   </ul>
</div>
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Xian Yang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>